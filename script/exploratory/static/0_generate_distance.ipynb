{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Glove Embeddings for pairwise keywords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import spacy \n",
    "import scipy\n",
    "from spacy import displacy\n",
    "import gensim.downloader as api\n",
    "\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "output_folder = \"../../../output/embedding_static/glove\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe embeddings...\n",
      "Tokenizing and filtering speeches...\n",
      "Computing document embeddings...\n",
      "Computing distances for keyword pairs...\n",
      "Keywords 'rights' or 'interven' not found in the GloVe vocabulary.\n",
      "Distances for all keyword pairs saved in long format as '../../../output/embedding_glove/liwc_meta_keyword_distances_long_format.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Load the input data\n",
    "df = pd.read_csv('~/Downloads/liwc_meta.csv')\n",
    "\n",
    "# Load GloVe embeddings\n",
    "print(\"Loading GloVe embeddings...\")\n",
    "glove = api.load(\"glove-wiki-gigaword-100\")\n",
    "\n",
    "# Tokenize and filter speeches\n",
    "speeches = df['text'].tolist()\n",
    "print(\"Tokenizing and filtering speeches...\")\n",
    "filtered_speeches = [[word for word in speech.lower().split() if word in glove] for speech in speeches]\n",
    "\n",
    "# Compute embeddings\n",
    "print(\"Computing document embeddings...\")\n",
    "embeddings = []\n",
    "for speech in filtered_speeches:\n",
    "    if speech:  # Avoid empty speeches\n",
    "        emb = np.mean([glove[word] for word in speech], axis=0)\n",
    "    else:\n",
    "        emb = np.zeros(glove.vector_size)  # Handle empty speeches with zero vector\n",
    "    embeddings.append(emb)\n",
    "\n",
    "# Define keyword pairs\n",
    "keyword_pairs = [\n",
    "    (\"sovereignty\", \"territory\"),\n",
    "    (\"sovereignty\", \"responsibility\"),\n",
    "    (\"rights\", \"responsibility\"),\n",
    "    (\"rights\", \"interven\"),\n",
    "    (\"rights\", \"sovereignty\"),\n",
    "    (\"sovereignty\", \"colonial\"),\n",
    "    (\"sovereignty\", \"westphalia\"),\n",
    "    (\"liberal\", \"sovereignty\"),\n",
    "    (\"war\", \"sovereignty\"),\n",
    "    (\"war\", \"peace\")\n",
    "]\n",
    "\n",
    "# Prepare output DataFrame\n",
    "output_rows = []\n",
    "\n",
    "# Compute distances\n",
    "print(\"Computing distances for keyword pairs...\")\n",
    "for keyword1, keyword2 in keyword_pairs:\n",
    "    if keyword1 in glove.key_to_index and keyword2 in glove.key_to_index:\n",
    "        embedding1 = glove[keyword1].reshape(1, -1)\n",
    "        embedding2 = glove[keyword2].reshape(1, -1)\n",
    "\n",
    "        for emb, dd_regime, year in zip(embeddings, df['dd_regime'], df['year']):\n",
    "            if not np.isnan(dd_regime):  # Exclude rows with NaN in dd_democracy\n",
    "                similarity = cosine_similarity(embedding1, emb.reshape(1, -1))[0][0]\n",
    "                distance = 1 - similarity\n",
    "\n",
    "                # Append results to output\n",
    "                output_rows.append({\n",
    "                    'year': year,\n",
    "                    'dd_regime': dd_regime,\n",
    "                    'keyword1': keyword1,\n",
    "                    'keyword2': keyword2,\n",
    "                    'distance': distance\n",
    "                })\n",
    "    else:\n",
    "        print(f\"Keywords '{keyword1}' or '{keyword2}' not found in the GloVe vocabulary.\")\n",
    "\n",
    "# Convert output rows to DataFrame\n",
    "output_df = pd.DataFrame(output_rows)\n",
    "\n",
    "# Save the updated DataFrame\n",
    "output_folder = \"../../../output/embedding_glove/\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_path = os.path.join(output_folder, \"liwc_meta_keyword_distances_long_format.csv\")\n",
    "output_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Distances for all keyword pairs saved in long format as '{output_path}'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
