{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a724a1b9-40ff-4419-8e77-fc727d7bf699",
   "metadata": {},
   "source": [
    "# Comparing embeddings across documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eca93ea8-2eda-4f47-8ed0-63d871e4bbc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer, AutoTokenizer\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "import torch\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4156376e-5a82-4198-bc4d-8b67dfd51564",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b094ffc-e9bd-4b51-a0bf-8301d7fa54dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input is \"light.csv\" which does not include stop words. \n",
    "df = pd.read_csv('../../../data/processed/light.csv')\n",
    "# Filter\n",
    "timestamps = df.year.to_list()\n",
    "texts = df.text.to_list()\n",
    "text = texts[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dfa216-ec78-49c9-b4d4-e2c07de99bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "\n",
    "# Extract texts from different documents\n",
    "text_document_1 = texts[2]\n",
    "text_document_2 = texts[3]\n",
    "\n",
    "# Specify keywords of interest\n",
    "keywords = ['state', 'economy', 'security']\n",
    "\n",
    "# Tokenize and compute embeddings for each word in the texts\n",
    "tokens_document_1 = nlp(text_document_1)\n",
    "tokens_document_2 = nlp(text_document_2)\n",
    "\n",
    "# Extract words and their embeddings for the specified keywords\n",
    "words_embeddings_document_1 = [(token.text, token.vector) for token in tokens_document_1 if token.is_alpha and token.text in keywords]\n",
    "words_embeddings_document_2 = [(token.text, token.vector) for token in tokens_document_2 if token.is_alpha and token.text in keywords]\n",
    "\n",
    "# Create DataFrames for each document\n",
    "df_document_1 = pd.DataFrame(words_embeddings_document_1, columns=['word', 'embedding'])\n",
    "df_document_2 = pd.DataFrame(words_embeddings_document_2, columns=['word', 'embedding'])\n",
    "\n",
    "# Merge DataFrames based on the words\n",
    "merged_df = pd.merge(df_document_1, df_document_2, on='word', how='inner', suffixes=('_doc1', '_doc2'))\n",
    "\n",
    "# Compute cosine similarities between word embeddings\n",
    "merged_df['cosine_similarity'] = merged_df.apply(lambda row: cosine_similarity([row['embedding_doc1']], [row['embedding_doc2']])[0][0], axis=1)\n",
    "\n",
    "# Print the resulting DataFrame with cosine similarities\n",
    "print(merged_df[['word', 'cosine_similarity']])\n",
    "\n",
    "# Merge DataFrames based on the words\n",
    "merged_df = pd.merge(df_document_1, df_document_2, on='word', how='inner', suffixes=('_doc1', '_doc2'))\n",
    "\n",
    "# Compute cosine similarities between word embeddings\n",
    "merged_df['cosine_similarity'] = merged_df.apply(lambda row: cosine_similarity([row['embedding_doc1']], [row['embedding_doc2']])[0][0], axis=1)\n",
    "\n",
    "# Visualize word embeddings in a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(merged_df['embedding_doc1'].apply(lambda x: x[0]), merged_df['embedding_doc1'].apply(lambda x: x[1]), label='Document 1', marker='o')\n",
    "plt.scatter(merged_df['embedding_doc2'].apply(lambda x: x[0]), merged_df['embedding_doc2'].apply(lambda x: x[1]), label='Document 2', marker='x')\n",
    "\n",
    "# Annotate points with words\n",
    "for i, row in merged_df.iterrows():\n",
    "    plt.annotate(row['word'], (row['embedding_doc1'][0], row['embedding_doc1'][1]), color='blue')\n",
    "    plt.annotate(row['word'], (row['embedding_doc2'][0], row['embedding_doc2'][1]), color='orange')\n",
    "\n",
    "# Add labels and legend\n",
    "plt.title('Word Embeddings - Document Comparison')\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.legend()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
