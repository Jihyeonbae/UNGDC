[
  {
    "objectID": "jupyter_notebook/functions_for_bert.html",
    "href": "jupyter_notebook/functions_for_bert.html",
    "title": "BERT Functions",
    "section": "",
    "text": "BERT Functions\nI define two functions to run Bert models. First part processes a single text document into a format that is recognizable by BERT. The second part uses the tokenized text to generate embedding values using pre-trained BERT models.\n\nfrom transformers import BertModel, BertTokenizer, AutoTokenizer\nimport numpy as np\nimport streamlit as st\nimport re\nimport pandas as pd\nfrom datetime import datetime\nimport nltk\nimport torch\n\n\nmodel = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\ntokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n\n\n#input is \"light.csv\" which does not include stop words. \ndf = pd.read_csv('../../../data/processed/paragraph.csv')\n# Filter\ntimestamps = df.year.to_list()\ntexts = df.text.to_list()\ntext = texts[1]\n\n\ndf.head(1)\n\n\n\n\n\n\n\n\nUnnamed: 0\nccode_iso\nsession\nyear\nparagraph_index\ntext\n\n\n\n\n0\n1\nAFG\n7\n1952\n1\nI consider it a great honour and privilege to ...\n\n\n\n\n\n\n\n\nprint(type(text))\n\n&lt;class 'str'&gt;\n\n\n\n\nDefine functions\n\ndef bert_preprocess(text):\n    \"\"\"\n    Preprocesses a document into a BERT-recognizable format \n    Input: text in a string format\n    output: three objects ready to be used for Bert modeling \n        marked_text (list)\n        indexed_tokens(list)\n        attention_mask(list)\n    \n    \"\"\"\n    # Tokenize the text\n    tokenized_text = tokenizer.tokenize(text)\n    truncate_length = len(tokenized_text) - 512 + 2  # +2 to account for [CLS] and [SEP]\n    \n    # Truncate the beginning and end of the text\n    truncated_text = tokenized_text[truncate_length//2 : -truncate_length//2]\n    \n    # Add padding\n    \n    # Add special tokens [CLS] and [SEP], convert tokens to ids, and create attention mask\n    marked_text = [\"[CLS] \"] + truncated_text + [\" [SEP]\"]\n    indexed_tokens = tokenizer.convert_tokens_to_ids(marked_text)\n    attention_mask = [1] * len(indexed_tokens)\n\n    # Pad sequences to max_seq_length\n    if len(indexed_tokens) &lt; 512:\n        indexed_tokens.append(0)\n        attention_mask.append(0)\n    \n    return marked_text, indexed_tokens, attention_mask\n\n\nmarked_text, indexed_tokens, attention_mask = bert_preprocess(text)\n\n\nhelp(get_bert_embeddings)\n\nHelp on function get_bert_embeddings in module __main__:\n\nget_bert_embeddings(marked_text, indexed_tokens, attention_mask)\n    input: processed text\n    output: dataframe of embedding weights for each token \n        ex) dimension of 512*768 where row represents token, column represents bert features\n\n\n\n\ndef get_bert_embeddings(marked_text, indexed_tokens, attention_mask):\n    \"\"\"\n    Generates embedding values for tokenized text \n    input: processed text, indexed_tokens and attention mask (all in list format)\n    output: dataframe of embedding weights for each token \n        ex) dimension of 512*768 where row represents token, column represents bert features\n    \n    \"\"\"\n    # Convert lists to PyTorch tensors\n    tokens_tensors = torch.tensor([indexed_tokens])\n    attention_masks = torch.tensor([attention_mask])\n    \n    with torch.no_grad():\n        #Run the embedding\n        outputs = model(input_ids=tokens_tensors.view(-1, tokens_tensors.size(-1)), \n                        attention_mask=attention_masks.view(-1, attention_masks.size(-1)))\n\n        # Extract the hidden states \n        hidden_states = outputs[2][0].squeeze().numpy()\n        \n        # Convert to data frame\n        pd_words = pd.Series(marked_text, name='term')\n        df_outputs = pd.DataFrame(hidden_states)\n        df_outputs['term'] = pd_words\n        \n        # Move 'term' column to the first position\n        df_outputs = df_outputs[['term'] + [col for col in df_outputs.columns if col != 'term']]\n        \n        # Remove duplicate tokens by averaging them out\n        df_outputs_embedding = df_outputs.groupby(['term']).mean()\n    return df_outputs_embedding\n\n\nget_bert_embeddings(marked_text, indexed_tokens, attention_mask)\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n...\n758\n759\n760\n761\n762\n763\n764\n765\n766\n767\n\n\nterm\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[SEP]\n-0.599731\n-0.287527\n0.995737\n-0.067600\n-0.116662\n-0.319243\n-0.035646\n-0.550722\n-0.154269\n0.226906\n...\n0.433558\n0.360281\n0.753348\n-1.155800\n0.198939\n0.126193\n0.058285\n0.035218\n-0.225301\n-0.376395\n\n\n##s\n-0.082928\n0.064610\n0.062934\n1.201868\n0.416490\n-0.351008\n-0.419693\n0.793464\n-0.682201\n-0.435875\n...\n-1.640653\n-0.082774\n1.440754\n0.477181\n0.555801\n0.517778\n0.029644\n0.167330\n-0.804072\n1.100950\n\n\n,\n0.238827\n-0.499530\n-0.229385\n-0.420359\n0.382101\n-0.133325\n-0.423249\n-0.133761\n0.079275\n-0.810453\n...\n-0.476354\n0.310680\n-0.071447\n-0.350534\n-0.166876\n-0.152760\n0.157087\n0.182910\n-0.305537\n0.119838\n\n\n-\n0.211686\n-0.337158\n-0.282966\n-0.379349\n0.213550\n-0.254544\n-0.361127\n-0.094978\n0.072562\n-0.825429\n...\n-0.457777\n0.271165\n0.238502\n-0.122299\n-0.090638\n-0.070707\n0.017792\n-0.049120\n-0.269647\n0.226714\n\n\n.\n0.117108\n-0.388444\n-0.088623\n0.064858\n0.523230\n-0.428734\n-0.267266\n-0.420127\n0.190312\n-0.766927\n...\n-0.490892\n0.354983\n-0.355035\n-0.418002\n0.253672\n0.086620\n0.108094\n-0.150912\n-0.198612\n0.161442\n\n\nIn\n1.179606\n0.055646\n0.182922\n1.080442\n0.191964\n-0.443555\n-0.347383\n0.757875\n-0.356111\n-1.096234\n...\n0.154227\n0.468894\n0.522242\n-0.500889\n0.947098\n1.150616\n-0.767531\n-0.148597\n-0.223548\n0.134304\n\n\nNations\n0.006905\n-0.580956\n0.575177\n-1.220215\n0.371888\n-0.279317\n0.700901\n-0.903072\n0.631587\n-0.739470\n...\n0.495864\n0.132003\n0.067810\n0.293461\n0.424441\n0.552663\n0.318386\n-0.620372\n-0.583365\n0.048380\n\n\nUnited\n-0.077556\n-0.105724\n1.057649\n-0.423865\n0.314821\n-0.185792\n-0.714371\n-0.607652\n-0.070977\n0.103325\n...\n-0.704180\n-1.008595\n-0.426895\n-0.018947\n0.567454\n0.483050\n-0.180623\n-0.287286\n-0.556010\n0.511452\n\n\n[CLS]\n-0.118897\n-0.518255\n0.159338\n-0.461482\n-0.003488\n-0.453042\n-0.212884\n-0.229699\n-0.063944\n-0.421272\n...\n0.242429\n0.009379\n0.467546\n-0.957577\n0.114305\n-0.369990\n0.035248\n0.089144\n-0.146707\n-0.127492\n\n\naccomplish\n-0.085958\n0.289747\n0.502433\n-0.699373\n-0.112547\n0.115439\n1.011047\n-0.570650\n-0.124616\n-0.372738\n...\n-1.153663\n-0.272904\n0.580479\n0.201596\n-0.194586\n-0.872371\n-0.358961\n0.039148\n0.101910\n-0.169740\n\n\nacts\n-0.178121\n0.666130\n0.413916\n0.099232\n-1.034455\n-0.040334\n-0.048890\n-0.098929\n-0.145200\n0.480938\n...\n-1.342113\n0.323047\n0.763901\n-1.770176\n0.986050\n-0.538208\n-0.744755\n0.057135\n-0.445161\n-0.774442\n\n\naid\n-0.427848\n0.147286\n0.013369\n0.471762\n0.168422\n0.895970\n0.872069\n1.716045\n0.837368\n0.494484\n...\n-0.787848\n-0.445969\n0.358512\n0.965379\n0.365942\n0.054571\n-0.555102\n-0.860554\n-0.171662\n-1.067538\n\n\naims\n1.024410\n-0.256186\n-0.053223\n0.638275\n-0.077131\n-0.311400\n-0.234701\n-0.026557\n0.915609\n-0.596711\n...\n-0.522890\n1.130598\n-0.809434\n-0.718155\n-0.150897\n-0.814818\n-0.124106\n-1.064612\n-0.574141\n-0.703143\n\n\nall\n-0.002165\n0.033546\n0.609011\n-0.239792\n-0.932221\n-1.037787\n0.136487\n-0.882456\n0.342895\n-0.798731\n...\n0.239174\n-0.662943\n0.205603\n0.161089\n-0.176249\n-0.105027\n0.036648\n0.276853\n0.527183\n-0.216994\n\n\nand\n0.685023\n0.240559\n-0.555069\n-0.011118\n0.690408\n0.024725\n-0.583992\n-0.181338\n-0.816213\n0.622959\n...\n-0.739703\n0.255513\n0.252658\n-0.401268\n0.020371\n0.737326\n0.633780\n-0.291272\n-0.483794\n-0.894787\n\n\nareas\n0.720950\n-0.746471\n0.160797\n-0.725814\n1.154829\n-0.101660\n-0.124824\n-0.682128\n-0.094830\n0.434859\n...\n-0.126514\n0.163580\n0.774643\n0.072612\n0.070189\n0.888373\n0.193730\n0.033260\n0.078655\n0.414108\n\n\nas\n-0.917634\n0.064711\n-0.368008\n0.218496\n1.246304\n-0.059035\n-1.098246\n0.450588\n-1.106012\n-1.061205\n...\n-0.457125\n-0.102798\n0.220228\n-0.558394\n-0.207785\n0.430128\n-1.262651\n0.324153\n-0.113458\n0.350910\n\n\nassistance\n-0.678422\n0.172338\n0.265142\n0.258749\n-0.105260\n-0.331368\n-0.350325\n0.263004\n-0.668104\n-0.555148\n...\n-0.475693\n0.409995\n0.346237\n0.555776\n0.440133\n-0.523475\n0.134694\n0.275381\n-0.253818\n0.210988\n\n\ncoincide\n-0.170578\n-0.268886\n-0.115447\n-0.694355\n0.483255\n-0.280104\n-0.640158\n0.034518\n-0.001312\n0.433044\n...\n-0.380226\n-0.208592\n-0.748574\n-0.197001\n0.404674\n-0.318124\n-0.521167\n0.667394\n-0.002012\n1.150480\n\n\ncollective\n0.151802\n0.762978\n-0.005754\n0.526812\n0.764982\n0.812513\n-0.570761\n-0.021987\n-1.306559\n-0.586478\n...\n-0.281096\n-1.654515\n-0.409773\n-0.740668\n0.533563\n-0.904656\n0.133838\n-0.766242\n0.390741\n-0.584280\n\n\nconscience\n0.158133\n-0.274482\n-0.492211\n-0.170320\n0.652437\n-0.445447\n0.168138\n-0.694122\n-0.364806\n-1.202534\n...\n-0.850401\n-0.854405\n0.362089\n0.396198\n0.172970\n-0.543768\n-1.138113\n0.421941\n1.142612\n1.083518\n\n\ncultural\n-1.082594\n-0.155604\n0.376953\n-0.332056\n-0.495655\n-1.082139\n0.782310\n-0.506714\n0.033708\n0.338000\n...\n0.613047\n0.565934\n-1.216563\n0.057687\n-0.932211\n-0.200133\n-0.734939\n0.179817\n-0.215364\n-0.216755\n\n\ndeveloped\n-0.195352\n0.150783\n0.080199\n-0.162700\n0.360601\n0.163544\n-0.581970\n0.052141\n0.185778\n-0.233883\n...\n-1.082397\n0.500910\n0.256611\n-0.607807\n-0.145842\n0.529889\n0.446537\n0.195365\n-0.643610\n-0.130024\n\n\ndevelopment\n0.298387\n0.496667\n-0.434238\n0.093009\n-1.293615\n0.209092\n-0.368899\n0.919280\n0.138753\n-0.650476\n...\n-0.645376\n1.387810\n0.642955\n0.327757\n-0.424770\n-0.255853\n0.202628\n0.501966\n-0.376638\n-0.267928\n\n\nduties\n-0.651811\n-0.242606\n0.490167\n-0.137662\n0.505857\n-0.002086\n1.298450\n0.396070\n1.254041\n-0.024695\n...\n0.302751\n-0.295479\n-0.401752\n-0.347428\n-0.645984\n-0.070883\n-1.304861\n-0.363276\n-0.646936\n-1.105535\n\n\neconomic\n0.327582\n0.387518\n-0.703620\n0.579996\n0.298967\n0.924665\n0.373069\n-0.637522\n0.973225\n0.572886\n...\n0.214301\n0.598506\n0.876789\n0.094422\n0.311424\n-0.415416\n-0.762125\n0.453513\n0.134451\n-0.050874\n\n\nends\n-0.546396\n-0.359361\n0.212410\n0.277001\n0.106774\n0.592411\n-0.247585\n-0.792451\n-0.884770\n0.545342\n...\n-0.271307\n-0.330248\n0.591369\n0.783333\n1.241485\n-0.296724\n0.078918\n0.412234\n0.387542\n0.192228\n\n\nfor\n-0.253029\n-0.404490\n-0.261728\n0.038780\n0.154741\n0.588547\n-1.170278\n-0.019293\n0.076067\n-1.264595\n...\n-0.787064\n-0.461386\n-0.638114\n-0.482141\n-0.344258\n-0.054569\n0.378593\n-0.465482\n-0.611659\n0.433159\n\n\nforward\n-0.207178\n0.236094\n-0.957996\n-0.357690\n0.334218\n-0.413327\n-0.956618\n-0.011278\n-0.408511\n-0.037497\n...\n-1.214147\n-0.303270\n0.135196\n0.555519\n0.122476\n0.240908\n-0.056521\n0.050130\n-0.211742\n0.378766\n\n\nguide\n-1.178150\n0.731618\n-0.593804\n0.415418\n1.651968\n-0.073628\n0.057820\n-0.396742\n-0.996873\n0.429075\n...\n0.614620\n-0.451440\n-1.288784\n-0.389848\n0.017629\n-0.483427\n-0.484336\n0.149367\n0.323914\n-1.239273\n\n\nhappily\n-0.552708\n0.431273\n-0.276702\n-0.626600\n1.248792\n-0.940124\n-0.367457\n-0.736995\n0.878078\n0.467198\n...\n0.395383\n-0.414090\n-0.134464\n-0.228733\n-0.090979\n0.121471\n0.091699\n-0.064050\n-0.222706\n0.177931\n\n\nin\n-0.825479\n-1.051559\n0.758063\n0.673075\n0.240419\n0.115155\n-0.920780\n0.137270\n1.564308\n-0.329897\n...\n-0.943635\n0.426585\n-0.385542\n-0.110009\n-1.135049\n-0.032381\n-0.399695\n0.427312\n0.118642\n0.217453\n\n\ninterest\n0.087404\n-0.640190\n-0.453728\n-0.850574\n-0.157392\n-0.533750\n0.637173\n-0.608730\n-0.633894\n0.933405\n...\n0.899409\n1.313719\n0.314493\n0.620090\n-0.622023\n0.070112\n-1.821788\n-0.131984\n-0.347964\n-0.195112\n\n\nits\n-0.217026\n0.894963\n-0.105397\n-0.401083\n-0.738265\n-0.480244\n-0.346089\n-0.352199\n1.088866\n-0.914263\n...\n-0.941486\n0.522719\n0.290851\n0.399336\n-0.462239\n-0.174071\n-0.092375\n0.078811\n0.854677\n-0.169473\n\n\nmoral\n0.619293\n0.499217\n0.249499\n-0.751159\n0.466876\n-0.062412\n-0.184458\n-0.660417\n0.652479\n-1.639679\n...\n-0.382880\n0.017941\n0.048614\n-0.491065\n0.557178\n1.361697\n0.181574\n-0.451610\n0.301997\n-0.267717\n\n\nmust\n-0.157701\n0.589252\n0.273769\n0.857760\n0.567033\n0.108004\n-1.062661\n-1.089537\n-0.240025\n-0.304565\n...\n0.769697\n-0.041358\n-0.410516\n0.544890\n-0.466517\n-1.122368\n0.304115\n0.411068\n0.301097\n0.433811\n\n\nobjectives\n-0.875071\n0.340940\n-0.162661\n0.404240\n0.205024\n-0.591867\n0.305278\n0.519380\n0.144190\n-0.521769\n...\n-0.237458\n-0.047777\n0.328942\n-1.136463\n0.665098\n0.725972\n0.299084\n-0.483213\n-0.158996\n-0.867711\n\n\nof\n-0.327949\n-0.544503\n-0.092067\n-1.195621\n0.039030\n-1.281222\n-0.414859\n0.070955\n-0.199553\n-1.428178\n...\n-0.035053\n0.183135\n0.080120\n-0.322540\n-0.468436\n0.623744\n0.315495\n0.084182\n0.077692\n0.203555\n\n\norder\n-0.067636\n-1.451491\n0.146754\n-0.419711\n0.023377\n-0.810850\n-0.734983\n-0.020393\n-0.560763\n0.204884\n...\n-0.109579\n0.385012\n-0.002484\n-0.126181\n-0.709134\n0.109215\n1.085052\n0.454821\n0.048261\n0.162490\n\n\npeoples\n-0.221793\n-0.247048\n-0.341812\n0.627216\n1.513762\n-0.743124\n-0.456467\n-1.155934\n0.653813\n-0.737646\n...\n0.766392\n-0.728573\n-0.624886\n0.481552\n0.536343\n-0.368652\n0.979576\n0.851340\n-0.597788\n0.720032\n\n\nphases\n-0.914526\n0.031760\n-0.057205\n-0.529099\n0.335894\n-0.689959\n-0.019860\n0.153372\n0.436006\n-0.038952\n...\n-0.668004\n0.173632\n-0.416013\n0.557431\n-0.360914\n-0.490024\n-0.671597\n0.189420\n0.384801\n-0.988437\n\n\npractical\n0.497227\n0.944226\n-0.767903\n-0.117738\n-0.066879\n0.199990\n0.709391\n0.005245\n0.146205\n-0.415131\n...\n0.073728\n-0.115236\n-0.118528\n0.329659\n-0.090454\n0.459422\n-1.281357\n-0.437196\n-0.268200\n0.232447\n\n\npush\n-0.184951\n0.711796\n0.721361\n-0.777537\n0.321118\n0.102113\n-0.503164\n0.589479\n1.586533\n0.306067\n...\n-0.007689\n-0.354350\n-0.783757\n0.479150\n0.510954\n0.808599\n-1.763679\n1.179172\n-0.048447\n-0.237922\n\n\nrealization\n0.680622\n0.343941\n0.359005\n-0.110402\n0.846315\n-1.126212\n0.410226\n-0.506499\n-0.529498\n-1.226504\n...\n0.534820\n0.661075\n0.972976\n0.132633\n0.495696\n-0.392315\n0.310346\n0.728478\n-0.813280\n0.737264\n\n\nself\n0.257648\n0.058829\n-0.417947\n0.250967\n0.102127\n-0.601216\n0.257821\n-0.101740\n-0.363018\n-0.105056\n...\n1.385324\n-0.540304\n-0.544518\n0.790096\n0.714771\n0.062684\n-0.041591\n0.477603\n0.045479\n0.348599\n\n\nsocial\n0.001411\n0.083508\n-0.384193\n0.038151\n0.828193\n-0.295133\n-0.131154\n-0.310905\n-0.194347\n-0.355901\n...\n-0.688219\n-0.004625\n-0.023948\n0.265741\n-0.029004\n-0.086471\n0.103009\n1.135597\n-0.636987\n-0.338693\n\n\nthe\n1.259149\n-0.390939\n-0.574276\n-0.651518\n0.975174\n-0.346215\n-0.203062\n0.069047\n-0.972633\n-0.484539\n...\n-0.177573\n0.605176\n-0.330061\n-0.963901\n0.492528\n0.279568\n-0.408966\n0.528585\n-1.137273\n0.370578\n\n\ntheir\n-0.141068\n-0.385690\n-0.610704\n-0.631536\n0.036775\n-0.008408\n0.058548\n0.447865\n-0.403555\n-0.706317\n...\n-0.900095\n0.260387\n-0.259527\n-0.011186\n0.366235\n-0.750171\n0.071075\n0.316691\n0.273126\n-1.098873\n\n\nthese\n-0.867060\n-0.423800\n-0.462822\n0.031337\n-0.921427\n0.606853\n-0.407772\n0.609299\n-0.070913\n0.411936\n...\n-0.375234\n-0.172975\n0.506652\n-0.142546\n0.120540\n-1.079829\n-0.097479\n-0.512669\n-0.959007\n0.081844\n\n\nthrough\n-0.806322\n0.435404\n-0.860480\n-0.352367\n-0.911619\n0.371939\n-0.302082\n-0.138660\n-0.286805\n0.741813\n...\n0.205986\n0.712598\n-0.843359\n0.651225\n0.107572\n0.096148\n-0.935132\n0.180383\n0.055736\n-0.279496\n\n\nto\n-0.467868\n-0.124578\n-0.321987\n0.056667\n-0.164021\n1.174730\n-0.633803\n0.867373\n-1.580327\n-0.784350\n...\n-0.367765\n-0.081297\n0.588999\n0.236422\n0.058517\n-0.139931\n0.747637\n-0.138854\n-0.143276\n-0.009610\n\n\nunder\n0.687285\n-0.849716\n0.345514\n-0.015210\n-0.001491\n0.095282\n-0.069619\n-0.023330\n-0.572866\n-1.167167\n...\n-0.920049\n0.214902\n0.161194\n-0.373119\n-0.300902\n-0.546927\n0.374067\n0.461742\n0.977844\n-0.106500\n\n\nwe\n0.493856\n-0.277951\n1.282449\n-0.818842\n-0.315630\n1.576497\n-0.768214\n-1.161283\n-1.137017\n0.787399\n...\n0.117417\n-0.324164\n-0.510348\n0.801145\n-0.253922\n0.568123\n0.851370\n-0.558899\n-0.064633\n-0.407102\n\n\nwhich\n-0.368462\n-0.361856\n0.409696\n0.587431\n0.708897\n0.291840\n-0.362036\n-0.530712\n-0.053614\n-0.711788\n...\n-1.084328\n-0.832080\n0.269114\n0.851772\n-0.942639\n-0.081171\n-1.273354\n-0.796438\n-0.260538\n0.355565\n\n\nwith\n-0.388580\n-0.219293\n-0.652044\n-1.386387\n-0.089682\n-0.403928\n-1.394354\n0.763693\n-0.379815\n-0.662670\n...\n-0.599527\n-0.076366\n0.786938\n-1.619844\n-0.512546\n-0.580194\n-0.000503\n-0.181073\n-1.548287\n0.417536\n\n\nworld\n0.737164\n-0.141081\n0.328124\n0.615530\n0.357371\n0.274039\n-0.563317\n0.040565\n-0.111780\n0.075683\n...\n-0.404257\n0.543159\n0.008046\n0.476506\n0.046138\n-0.633671\n-0.073570\n-0.446745\n-0.119588\n-0.238425\n\n\n\n\n56 rows × 768 columns",
    "crumbs": [
      "BERT Embedding",
      "Functions for BERT"
    ]
  },
  {
    "objectID": "rmarkdown/liwc_analysis.html",
    "href": "rmarkdown/liwc_analysis.html",
    "title": "liwc_modeling",
    "section": "",
    "text": "In this project, I use linguistic features of state representatives’ speech transcripts from the United Nations General Debate Corpus (UNGDC) to predict the regime type. The goal is twofold. First, we aim at running a hard test for a hypothesis that countries identified with distinct regime types show different linguistic styles. If I can predict the speaker’s regime type based on linguistic features, it is a strong indication of the difference in linguistic features across regime types. Second, this project analyzes key linguistic features that act as a strong signal of the state’s regime type. I further interpret substantive implication of strong coefficients and check how consistent their degrees of significance are across the models. This script uses the scores of LIWC features and merges with country-year level meta data. \"data/raw/controls/controls.csv\" has a battery of country-year level variables that might potentially confound the statistical modeling. With liwc_meta dataset, at the country-year level, I run a series of statistical models that probe the relationship between linguistic features and sentiment scores of that speech. To preview, LIWC features alone have a strong predictive power on regime types, even without the help of meta data.\nI test whether there is a correlation between a country’s invocation of international legal norms and the regime type. Among many, I generate three key legal principles that are prominent throughout the history of international politics. These are principle of sovereignty, principle of non-intervention, and the principle of human rights. Binary variables capture whether each principle was invoked, and count variables measure the number of time it was mentioned within one speech.",
    "crumbs": [
      "Linguistic Analysis",
      "LIWC Regression"
    ]
  },
  {
    "objectID": "rmarkdown/liwc_analysis.html#separate-test-data-from-validation-set.",
    "href": "rmarkdown/liwc_analysis.html#separate-test-data-from-validation-set.",
    "title": "liwc_modeling",
    "section": "Separate test data from validation set.",
    "text": "Separate test data from validation set.\nTake out the test data set (just a few years) and then split for th e validation data. In my dataset, I carve out observations from two years (2021 and 2022) as my test data.\nWithin the test data, I split the data in to two groups: pre and post Cold War with a threshold of 1990. I create several models based on the pre-Cold War era and generate model evaluation metrics by applying the models to the post Cold War era.",
    "crumbs": [
      "Linguistic Analysis",
      "LIWC Regression"
    ]
  },
  {
    "objectID": "rmarkdown/liwc_analysis.html#interpretation-of-the-model",
    "href": "rmarkdown/liwc_analysis.html#interpretation-of-the-model",
    "title": "liwc_modeling",
    "section": "Interpretation of the model",
    "text": "Interpretation of the model\nSummary table of the estimation results highlight features that play important role in predicting the regime type. Below plot displays the fitted model of how a linguistic feature of “focuspast” affects an outcome of regime type. It seems that there is a weak but consistent positive correlation between the linguistic tendency to focus on the past and the regime type. This pattern is consistent regardless of a country’s history of being a former colony.\n\nmodel_summary2&lt;-modelsummary(model0, \n                             stars = TRUE, \n                             output = \"kableExtra\", \n                             escape = FALSE)\n\nmodel_summary2%&gt;%kable_classic(full_width=F, html_font = \"Cambria\")%&gt;%\n    scroll_box(width = \"100%\", height = \"600px\")\n\n\n\n\n\n\n (1)\n\n\n\n\n(Intercept)\n56.129**\n\n\n\n(19.600)\n\n\nWC\n0.000\n\n\n\n(0.000)\n\n\nAnalytic\n−0.177*\n\n\n\n(0.082)\n\n\nClout\n0.073\n\n\n\n(0.102)\n\n\nAuthentic\n0.208\n\n\n\n(0.146)\n\n\nTone\n0.048\n\n\n\n(0.073)\n\n\nWPS\n0.032\n\n\n\n(0.021)\n\n\nBigWords\n0.002\n\n\n\n(0.136)\n\n\nDic\n−0.356+\n\n\n\n(0.214)\n\n\nLinguistic\n−0.383\n\n\n\n(0.467)\n\n\nfunction_feature\n0.212\n\n\n\n(0.541)\n\n\npronoun\n−23.295\n\n\n\n(25.957)\n\n\nppron\n20.785\n\n\n\n(25.931)\n\n\ni\n1.727\n\n\n\n(1.848)\n\n\nwe\n0.977\n\n\n\n(1.540)\n\n\nyou\n1.116\n\n\n\n(1.819)\n\n\nshehe\n4.889*\n\n\n\n(2.388)\n\n\nthey\n0.385\n\n\n\n(1.558)\n\n\nipron\n23.246\n\n\n\n(25.984)\n\n\ndet\n0.856*\n\n\n\n(0.410)\n\n\narticle\n−0.558\n\n\n\n(0.531)\n\n\nnumber\n−0.578\n\n\n\n(0.383)\n\n\nprep\n0.188\n\n\n\n(0.436)\n\n\nauxverb\n−0.518\n\n\n\n(0.674)\n\n\nadverb\n−0.545\n\n\n\n(0.454)\n\n\nconj\n0.038\n\n\n\n(0.435)\n\n\nnegate\n−0.553\n\n\n\n(0.945)\n\n\nverb\n0.287\n\n\n\n(0.540)\n\n\nadj\n0.015\n\n\n\n(0.447)\n\n\nquantity\n−0.104\n\n\n\n(0.436)\n\n\nDrives\n0.142\n\n\n\n(1.353)\n\n\naffiliation\n−0.450\n\n\n\n(1.378)\n\n\nachieve\n0.702\n\n\n\n(1.336)\n\n\npower\n0.369\n\n\n\n(1.361)\n\n\nCognition\n5.500*\n\n\n\n(2.315)\n\n\nallnone\n−6.289**\n\n\n\n(2.383)\n\n\ncogproc\n−4.793*\n\n\n\n(2.373)\n\n\ninsight\n−1.021\n\n\n\n(0.985)\n\n\ncause\n−1.302*\n\n\n\n(0.630)\n\n\ndiscrep\n1.417\n\n\n\n(1.001)\n\n\ntentat\n−0.535\n\n\n\n(0.667)\n\n\ncertitude\n−1.121\n\n\n\n(0.703)\n\n\ndiffer\n−0.609\n\n\n\n(1.165)\n\n\nmemory\n−6.128*\n\n\n\n(2.688)\n\n\nAffect\n−0.022\n\n\n\n(5.690)\n\n\ntone_pos\n−0.041\n\n\n\n(5.839)\n\n\ntone_neg\n0.831\n\n\n\n(5.769)\n\n\nemotion\n−0.774\n\n\n\n(5.514)\n\n\nemo_pos\n0.844\n\n\n\n(5.602)\n\n\nemo_neg\n0.821\n\n\n\n(5.795)\n\n\nemo_anx\n1.537\n\n\n\n(2.562)\n\n\nemo_anger\n−1.882\n\n\n\n(2.438)\n\n\nemo_sad\n0.102\n\n\n\n(2.483)\n\n\nswear\n−5.161\n\n\n\n(7.616)\n\n\nSocial\n0.380\n\n\n\n(0.576)\n\n\nsocbehav\n−0.103\n\n\n\n(0.707)\n\n\nprosocial\n−1.245*\n\n\n\n(0.578)\n\n\npolite\n−0.159\n\n\n\n(0.885)\n\n\nconflict\n−0.067\n\n\n\n(0.969)\n\n\nmoral\n−0.400\n\n\n\n(0.737)\n\n\ncomm\n−0.899\n\n\n\n(0.674)\n\n\nsocrefs\n0.513\n\n\n\n(0.883)\n\n\nfamily\n1.600\n\n\n\n(1.729)\n\n\nfriend\n−1.118\n\n\n\n(4.068)\n\n\nfemale\n−3.629***\n\n\n\n(0.893)\n\n\nmale\n−2.186\n\n\n\n(1.438)\n\n\nCulture\n−13.922\n\n\n\n(12.687)\n\n\npolitic\n13.677\n\n\n\n(12.684)\n\n\nethnicity\n13.891\n\n\n\n(12.669)\n\n\ntech\n14.631\n\n\n\n(12.729)\n\n\nLifestyle\n−0.439\n\n\n\n(1.383)\n\n\nleisure\n−0.848\n\n\n\n(1.967)\n\n\nhome\n1.860\n\n\n\n(2.424)\n\n\nwork\n0.167\n\n\n\n(1.329)\n\n\nmoney\n1.549\n\n\n\n(1.183)\n\n\nrelig\n0.291\n\n\n\n(1.483)\n\n\nPhysical\n−0.310\n\n\n\n(1.005)\n\n\nhealth\n1.032\n\n\n\n(1.550)\n\n\nillness\n−1.617\n\n\n\n(1.698)\n\n\nwellness\n2.602\n\n\n\n(2.940)\n\n\nmental\n−7.307\n\n\n\n(6.068)\n\n\nsubstances\n7.125\n\n\n\n(4.889)\n\n\nsexual\n0.010\n\n\n\n(1.714)\n\n\nfood\n1.069\n\n\n\n(1.163)\n\n\ndeath\n2.108\n\n\n\n(1.767)\n\n\nneed\n0.204\n\n\n\n(0.543)\n\n\nwant\n0.082\n\n\n\n(1.283)\n\n\nacquire\n−0.196\n\n\n\n(1.053)\n\n\nlack\n−2.447*\n\n\n\n(0.981)\n\n\nfulfill\n3.340**\n\n\n\n(1.235)\n\n\nfatigue\n5.842\n\n\n\n(9.757)\n\n\nreward\n−1.613\n\n\n\n(0.991)\n\n\nrisk\n−0.493\n\n\n\n(0.529)\n\n\ncuriosity\n−0.879\n\n\n\n(1.112)\n\n\nallure\n0.618*\n\n\n\n(0.305)\n\n\nPerception\n−1.966\n\n\n\n(1.222)\n\n\nattention\n2.146\n\n\n\n(1.483)\n\n\nmotion\n0.450\n\n\n\n(1.414)\n\n\nspace\n0.839\n\n\n\n(1.507)\n\n\nvisual\n2.029\n\n\n\n(1.462)\n\n\nauditory\n−0.259\n\n\n\n(2.508)\n\n\nfeeling\n1.492\n\n\n\n(2.047)\n\n\ntime\n−0.885\n\n\n\n(0.846)\n\n\nfocuspast\n0.479\n\n\n\n(0.399)\n\n\nfocuspresent\n0.187\n\n\n\n(0.395)\n\n\nfocusfuture\n0.205\n\n\n\n(0.534)\n\n\nConversation\n5.188\n\n\n\n(22.259)\n\n\nnetspeak\n4.449\n\n\n\n(20.407)\n\n\nassent\n−6.620\n\n\n\n(21.828)\n\n\nnonflu\n32.286\n\n\n\n(48.233)\n\n\nfiller\n−236.128\n\n\n\n(13385.385)\n\n\nAllPunc\n14.746\n\n\n\n(20.193)\n\n\nPeriod\n−13.898\n\n\n\n(20.179)\n\n\nComma\n−14.805\n\n\n\n(20.192)\n\n\nQMark\n−13.590\n\n\n\n(20.066)\n\n\nExclam\n−30.759\n\n\n\n(22.656)\n\n\nApostro\n−12.302\n\n\n\n(20.174)\n\n\nOtherP\n−14.791\n\n\n\n(20.203)\n\n\nmid_dispute\n0.021\n\n\n\n(0.159)\n\n\nwdi_gdpcapcon2015\n0.000***\n\n\n\n(0.000)\n\n\nwdi_gdpcapgr\n0.012\n\n\n\n(0.031)\n\n\nwdi_pop\n0.000\n\n\n\n(0.000)\n\n\npts_ptss\n−0.285\n\n\n\n(0.212)\n\n\nbmr_dem\n3.787***\n\n\n\n(0.473)\n\n\nkofgi_dr_eg\n−0.156\n\n\n\n(0.307)\n\n\nkofgi_dr_ig\n0.285\n\n\n\n(0.911)\n\n\nkofgi_dr_pg\n0.010\n\n\n\n(0.309)\n\n\nkofgi_dr_sg\n−0.206\n\n\n\n(0.300)\n\n\nwdi_log_gdpcapcon2015\n−0.931*\n\n\n\n(0.373)\n\n\nwdi_log_pop\n−1.365***\n\n\n\n(0.284)\n\n\npolity\n0.396\n\n\n\n(0.358)\n\n\npolity2\n0.109\n\n\n\n(0.287)\n\n\nplty_xrcomp\n1.619***\n\n\n\n(0.403)\n\n\nplty_xropen\n−0.274\n\n\n\n(0.210)\n\n\nplty_xconst\n−0.989***\n\n\n\n(0.261)\n\n\nplty_parreg\n0.297\n\n\n\n(0.279)\n\n\nplty_parcomp\n−0.994***\n\n\n\n(0.219)\n\n\nnavco_num_campaign\n0.646\n\n\n\n(0.472)\n\n\nnavco_campaign\n−1.011\n\n\n\n(0.658)\n\n\nup_num_conflict\n0.144+\n\n\n\n(0.079)\n\n\nup_conflict\n0.090\n\n\n\n(0.383)\n\n\nup_num_war\n−0.205\n\n\n\n(0.188)\n\n\nup_war\n0.589\n\n\n\n(0.542)\n\n\nv2x_polyarchy\n−8.736\n\n\n\n(6.993)\n\n\nv2x_libdem\n17.852+\n\n\n\n(9.112)\n\n\nv2x_freexp_altinf\n−10.215\n\n\n\n(22.267)\n\n\nv2x_frassoc_thick\n20.023***\n\n\n\n(5.353)\n\n\nv2xel_locelec\n−2.467***\n\n\n\n(0.678)\n\n\nv2xel_regelec\n2.273***\n\n\n\n(0.636)\n\n\nv2mecenefm\n3.073***\n\n\n\n(0.535)\n\n\nv2mecrit\n−0.454\n\n\n\n(0.498)\n\n\nv2mefemjrn\n0.092***\n\n\n\n(0.023)\n\n\nv2meharjrn\n0.944**\n\n\n\n(0.361)\n\n\nv2mebias\n0.374\n\n\n\n(0.460)\n\n\nv2mecorrpt\n−0.272\n\n\n\n(0.261)\n\n\nv2meslfcen\n−0.201\n\n\n\n(0.369)\n\n\nv2x_accountability\n4.663**\n\n\n\n(1.714)\n\n\nv2x_horacc\n−0.724\n\n\n\n(0.681)\n\n\nv2x_diagacc\n−6.909**\n\n\n\n(2.274)\n\n\nv2xnp_regcorr\n−10.914**\n\n\n\n(3.705)\n\n\nv2x_civlib\n25.843\n\n\n\n(83.332)\n\n\nv2x_clphy\n−8.202\n\n\n\n(27.502)\n\n\nv2x_clpol\n−42.879\n\n\n\n(28.508)\n\n\nv2x_clpriv\n−4.228\n\n\n\n(27.149)\n\n\nv2x_corr\n31.146***\n\n\n\n(6.097)\n\n\nv2x_pubcorr\n−11.666***\n\n\n\n(2.679)\n\n\nv2jucorrdc\n1.927***\n\n\n\n(0.471)\n\n\nv2x_rule\n−7.827*\n\n\n\n(3.936)\n\n\nv2xcl_acjst\n−2.272\n\n\n\n(1.535)\n\n\nv2xcs_ccsi\n1.947\n\n\n\n(3.536)\n\n\nv2x_freexp\n23.233+\n\n\n\n(13.869)\n\n\nv2xme_altinf\n9.918\n\n\n\n(10.429)\n\n\nv2xedvd_me_cent\n9.479**\n\n\n\n(3.408)\n\n\nht_colonial\n−1.653**\n\n\n\n(0.518)\n\n\nsovereignty\n1.113*\n\n\n\n(0.461)\n\n\nintervention\n0.373\n\n\n\n(0.496)\n\n\nhuman_rights\n0.545\n\n\n\n(0.352)\n\n\nsovereignty_count\n−0.300+\n\n\n\n(0.178)\n\n\nintervention_count\n0.201\n\n\n\n(0.212)\n\n\nhuman_rights_count\n0.086\n\n\n\n(0.091)\n\n\nNum.Obs.\n2828\n\n\nAIC\n909.2\n\n\nBIC\n1979.7\n\n\nLog.Lik.\n−274.593\n\n\nRMSE\n0.16\n\n\n\n + p\n\n\n\n\n\n\n\n\nvisreg(model0, xvar = \"focusfuture\", by = \"ht_colonial\", scale = \"linear\")",
    "crumbs": [
      "Linguistic Analysis",
      "LIWC Regression"
    ]
  },
  {
    "objectID": "rmarkdown/UNGDC_topic_modeling_updated.html",
    "href": "rmarkdown/UNGDC_topic_modeling_updated.html",
    "title": "Dynamic UNGDC (updated)",
    "section": "",
    "text": "This version does use tf-idf for LDA analysis. For the older version, refer to UNGDC_topic_modeling.qmd. I created a separate version for two reasons. First, some of the functions and options deprecated from the quanteda R package. Earlier version might not be reproducible. Second, the inclusion of tf-idf to generate LDA analysis has a tradeoff. Since it gives less weights to terms that appear frequently across the documents, by definition, tf-idf lowers the correlation between terms over different time window. It is harder to notice a clear linkage between two topics represented by different terms. However, unlike the earlier version that excludes tf-idf, topics are more specific, and substantively meaningful.",
    "crumbs": [
      "Topic Modeling",
      "Decadal LDA"
    ]
  },
  {
    "objectID": "rmarkdown/UNGDC_topic_modeling_updated.html#dynamic-topic-modeling-for-ungdc",
    "href": "rmarkdown/UNGDC_topic_modeling_updated.html#dynamic-topic-modeling-for-ungdc",
    "title": "Dynamic UNGDC (updated)",
    "section": "Dynamic Topic Modeling for UNGDC",
    "text": "Dynamic Topic Modeling for UNGDC\nIn order to generate LDA topic modeling results for the corpus of UNGD, I split the corpus into different time frames. The entire time span of 1945 until 2022 is split into 8 intervals, with a duration of 10 years.\n\n# Load packages\nlibrary(plyr)\nlibrary(dplyr)\nlibrary(tm)\nlibrary(gplots)\nlibrary(ggplot2)\nlibrary(quanteda)\nlibrary(readr)\nlibrary(seededlda)\nlibrary(slam)\nlibrary(jsonlite)\nlibrary(tm)\nlibrary(tidyr)\nlibrary(knitr)\n\nlight &lt;- readRDS(\"data/processed/cleaned.RDS\")\n\n#Set up the parameters\nlight_interval &lt;- light %&gt;%\n  dplyr::mutate(span = as.factor(cut(year,\n                                     breaks = c(seq(from = 1945, to = 2022, by = 10), 2022)))) %&gt;%\n  dplyr::arrange(year)\n\n\n# I added two additional stop words that aren't captured in the generic stop words dictionary. \n\nmystopwords &lt;- c(\"will\", \"must\")\ncustom_stopwords &lt;- c(stopwords(\"english\"), mystopwords)",
    "crumbs": [
      "Topic Modeling",
      "Decadal LDA"
    ]
  },
  {
    "objectID": "rmarkdown/UNGDC_topic_modeling_updated.html#term-frequency-inverse-matrix-and-descriptive-data-visualization",
    "href": "rmarkdown/UNGDC_topic_modeling_updated.html#term-frequency-inverse-matrix-and-descriptive-data-visualization",
    "title": "Dynamic UNGDC (updated)",
    "section": "Term Frequency-Inverse Matrix and Descriptive Data Visualization",
    "text": "Term Frequency-Inverse Matrix and Descriptive Data Visualization\n\nTo inspect the data and frequent words across time intervals, below code generates top-20 terms based on the tf-idf scores.\nInput dataset: “data/processed/cleaned.RDS”.\n\n\n# Function for generating tf_idf and plots.\nsapply(levels(light_interval$span), function(i) {\n  subset_i &lt;- light_interval %&gt;% dplyr::filter(span %in% i)\n  corpus_subset &lt;- Corpus(VectorSource(subset_i$text))\n  tdm &lt;- TermDocumentMatrix(corpus_subset,\n                            control = list(weighting = weightTfIdf,\n                                           removePunctuation = TRUE,\n                                           stemming = TRUE,\n                                           removeNumbers = TRUE,\n                                           stopwords = TRUE,\n                                           removewords = mystopwords))\n  top_terms &lt;- slam::row_sums(as.matrix(tdm))\n  \n  # Create a data frame with terms and tfidf values\n  top_terms_df &lt;- data.frame(term = names(top_terms), tfidf = top_terms)\n  \n  # Order the terms by tfidf value\n  top_terms_df &lt;- top_terms_df[order(top_terms_df$tfidf, decreasing = TRUE), ]\n  \n  # Select the top 20 terms\n  top_terms_df &lt;- head(top_terms_df, 20)\n  \n  figure_i &lt;- ggplot(top_terms_df, aes(x = reorder(term, tfidf), y = tfidf)) +\n    geom_bar(stat = \"identity\", fill = \"skyblue\") +\n    theme_minimal() +\n    labs(title = \"Top 20 Terms by TF-IDF\",\n         x = \"Terms\",\n         y = \"TF-IDF Score\") +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1))\n  \n  output_file &lt;- file.path(\"figs/\", paste0(\"plot_\", i, \".png\"))\n  ggsave(output_file, figure_i, width = 8, height = 5, units = \"in\")\n})\n\n\ndfm function helps remove stop words and perform other preprocessing steps to create a more refined document-feature matrix. Additionally, the subsequent dfm_tfidf function is used to compute TF-IDF (Term Frequency-Inverse Document Frequency) scores, which down-weights terms that appear frequently across documents.",
    "crumbs": [
      "Topic Modeling",
      "Decadal LDA"
    ]
  },
  {
    "objectID": "rmarkdown/UNGDC_topic_modeling_updated.html#reading-in-lda-results",
    "href": "rmarkdown/UNGDC_topic_modeling_updated.html#reading-in-lda-results",
    "title": "Dynamic UNGDC (updated)",
    "section": "Reading in LDA results",
    "text": "Reading in LDA results\nAfter running the LDA model, I read in each LDA results as a separate element in a list form. Below code prins out top 10 terms associated with each topic in the LDA models for different span levels. Each row represents one semantic topic.\n\nread_lda_models &lt;- function(span_levels, output_dir = \"output/lda/decade_0120_replicate\") {\n  lda_models &lt;- list()\n\n  for (i in span_levels) {\n    lda_output_file &lt;- file.path(output_dir, paste0(\"lda_model_\", i, \".RDS\"))\n\n    if (file.exists(lda_output_file)) {\n      lda_model &lt;- readRDS(lda_output_file)\n      lda_models[[i]] &lt;- lda_model\n      cat(sprintf(\"LDA model for %s successfully loaded.\\n\", i))\n    } else {\n      cat(sprintf(\"LDA model file for %s not found.\\n\", i))\n    }\n  }\n\n  return(lda_models)\n}\n\n\n\nlda_models &lt;- read_lda_models(span_levels)\n\nLDA model for (1945,1955] successfully loaded.\nLDA model for (1955,1965] successfully loaded.\nLDA model for (1965,1975] successfully loaded.\nLDA model for (1975,1985] successfully loaded.\nLDA model for (1985,1995] successfully loaded.\nLDA model for (1995,2005] successfully loaded.\nLDA model for (2005,2015] successfully loaded.\nLDA model for (2015,2022] successfully loaded.\n\ntopic_tables &lt;- function(lda_models, span_levels) {\n  topic_tables &lt;- list()\n\n  for (i in span_levels) {\n    if (i %in% names(lda_models)) {\n      lda_model &lt;- lda_models[[i]]\n      terms &lt;- terms(lda_model, 10)\n      topic_table &lt;- data.frame(Terms = terms)\n      topic_tables[[i]] &lt;- topic_table\n    } else {\n      cat(sprintf(\"LDA model for %s not found.\\n\", i))\n    }\n  }\n\n  all_topics &lt;- do.call(rbind, topic_tables)\n  return(all_topics)\n}\n\n\ntopic_tables &lt;- topic_tables(lda_models, span_levels)\nprint(knitr::kable(topic_tables))\n\n\n\n|               |Terms.topic1  |Terms.topic2 |Terms.topic3 |Terms.topic4 |Terms.topic5 |Terms.topic6 |Terms.topic7 |Terms.topic8 |Terms.topic9  |Terms.topic10 |\n|:--------------|:-------------|:------------|:------------|:------------|:------------|:------------|:------------|:------------|:-------------|:-------------|\n|(1945,1955].1  |ussr          |arab         |german       |argentin     |bolivia      |hyderabad    |netherland   |resumpt      |communist     |india         |\n|(1945,1955].2  |soviet        |israel       |czechoslovak |latin        |cuba         |egypt        |bandung      |korea        |soviet        |australian    |\n|(1945,1955].3  |yugoslav      |palestin     |polish       |trade        |greek        |india        |african      |collect      |chines        |commiss       |\n|(1945,1955].4  |atom          |jerusalem    |soviet       |chile        |greec        |sudan        |south        |recommend    |communism     |council       |\n|(1945,1955].5  |yugoslavia    |morocco      |germani      |uruguay      |dominican    |egyptian     |geneva       |independ     |china         |think         |\n|(1945,1955].6  |armament      |tunisia      |people’      |veto         |guatemala    |pakistan     |africa       |leader       |korea         |say           |\n|(1945,1955].7  |union         |jew          |poland       |american     |colombia     |el           |indonesia    |europ        |union         |veto          |\n|(1945,1955].8  |prohibit      |refuge       |weapon       |panama       |bolivian     |salvador     |thailand     |veto         |imprison      |soviet        |\n|(1945,1955].9  |weapon        |jewish       |hydrogen     |venezuela    |guatemalan   |sudanes      |zealand      |revis        |costa         |china         |\n|(1945,1955].10 |american      |franc        |european     |per          |cuban        |british      |asia         |collabor     |mainland      |arbitr        |\n|(1955,1965].1  |particip      |bantu        |malaysia     |cambodia     |netherland   |pakistan     |american     |african      |german        |arab          |\n|(1955,1965].2  |moscow        |iceland      |zealand      |lao          |congo        |cyprus       |cuba         |africa       |socialist     |israel        |\n|(1955,1965].3  |industri      |south        |australia    |spain        |indonesia    |turkish      |cuban        |portug       |soviet        |palestin      |\n|(1955,1965].4  |coexist       |indian       |philippin    |communist    |irian        |kashmir      |panama       |mali         |czechoslovak  |egypt         |\n|(1955,1965].5  |fund          |canada       |malaya       |viet         |nigeria      |india        |guatemala    |portugues    |albania       |algerian      |\n|(1955,1965].6  |cent          |canadian     |australian   |spanish      |berlin       |turkey       |dominican    |somali       |romanian      |libya         |\n|(1955,1965].7  |trade         |danish       |feder        |chines       |belgian      |greek        |venezuela    |congo        |germani       |franc         |\n|(1955,1965].8  |scienc        |goa          |india        |cambodian    |indonesian   |greec        |latin        |austrian     |byelorussian  |libyan        |\n|(1955,1965].9  |concept       |africa       |indonesia    |pathet       |west         |nepal        |america      |cameroon     |nato          |canal         |\n|(1955,1965].10 |invest        |chairman     |manila       |royal        |want         |jammu        |paraguay     |malagasi     |albanian      |jordan        |\n|(1965,1975].1  |like          |pakistan     |african      |imperialist  |like         |israel       |austria      |cuba         |turkey        |haiti         |\n|(1965,1975].2  |programm      |india        |ghana        |khmer        |socialist    |arab         |spain        |iceland      |cyprus        |oil           |\n|(1965,1975].3  |nuclear       |zealand      |rwanda       |aggress      |soviet       |isra         |salvador     |venezuela    |turkish       |australia     |\n|(1965,1975].4  |big           |ireland      |portug       |imperi       |german       |palestin     |italian      |cuban        |argentina     |haitian       |\n|(1965,1975].5  |neighbour     |netherland   |uganda       |revisionist  |mongolian    |zionist      |el           |panama       |greec         |volta         |\n|(1965,1975].6  |space         |japan        |burundi      |albania      |byelorussian |palestinian  |itali        |bolivia      |argentin      |philippin     |\n|(1965,1975].7  |strategi      |burma        |africa       |albanian     |ssr          |yemen        |gibraltar    |zair         |peru          |price         |\n|(1965,1975].8  |franc         |kashmir      |portugues    |viet         |czechoslovak |israel’      |rica         |chile        |greek         |upper         |\n|(1965,1975].9  |youth         |fiji         |kenya        |cambodia     |ukrainian    |aggress      |hondura      |latin        |brazil        |food          |\n|(1965,1975].10 |madam         |pacif        |oau          |chines       |europ        |iraq         |uruguay      |dominican    |dahomey       |australian    |\n|(1975,1985].1  |malta         |soviet       |ireland      |imperialist  |turkey       |benin        |guinea       |pleasur      |guatemala     |¬             |\n|(1975,1985].2  |zionist       |japan        |panama       |vietnames    |yemen        |burundi      |papua        |dialog       |uganda        |barbado       |\n|(1975,1985].3  |bahama        |europ        |ecuador      |kampuchea    |egypt        |mali         |zealand      |cooper       |timor         |paraguay      |\n|(1975,1985].4  |itali         |german       |latin        |chines       |morocco      |rwanda       |pacif        |program      |nicaragua     |ghana         |\n|(1975,1985].5  |iranian       |union        |bolivia      |lao          |turkish      |seneg        |chad         |per          |guinea        |tion          |\n|(1975,1985].6  |iraqi         |socialist    |dominican    |thailand     |pakistan     |zair         |bangladesh   |refuge       |hondura       |guyana        |\n|(1975,1985].7  |mediterranean |mongolian    |rica         |nam          |sudan        |oau          |australia    |india        |salvador      |ment          |\n|(1975,1985].8  |tobago        |poland       |costa        |viet         |arab         |kenya        |surinam      |fortieth     |revolutionari |con           |\n|(1975,1985].9  |libyan        |austria      |spain        |ethiopia     |islam        |chad         |equatori     |sea          |guatemalan    |venezuela     |\n|(1975,1985].10 |islam         |detent       |american     |romania      |isra         |mauritania   |canada       |indian       |angola        |caribbean     |\n|(1985,1995].1  |wish          |wish         |wish         |panama       |wish         |wish         |wish         |wish         |wish          |wish          |\n|(1985,1995].2  |paraguay      |co           |islam        |burundi      |guinea       |canada       |european     |saint        |cooper        |malawi        |\n|(1985,1995].3  |american      |organis      |arab         |myanmar      |pacif        |netherland   |europ        |bahama       |boutro        |african       |\n|(1985,1995].4  |latin         |program      |sri          |rwanda       |viet         |philippin    |ukrain       |nepal        |eighth        |chad          |\n|(1985,1995].5  |bolivia       |dialog       |iranian      |romania      |nam          |want         |albania      |caribbean    |bosnia        |niger         |\n|(1985,1995].6  |dominican     |twelv        |lebanon      |zair         |japan        |revolut      |belarus      |pakistan     |herzegovina   |swaziland     |\n|(1985,1995].7  |ecuador       |align        |lanka        |panamanian   |equatori     |canadian     |poland       |barbado      |somalia       |uganda        |\n|(1985,1995].8  |hondura       |namibia      |iraqi        |belgium      |solomon      |let          |csce         |haiti        |l993          |kenya         |\n|(1985,1995].9  |chile         |disarma      |ireland      |canal        |zealand      |enemi        |austria      |surinam      |fiftieth      |benin         |\n|(1985,1995].10 |costa         |drug         |tunisia      |rwandes      |papua        |children     |croatia      |india        |npt           |angola        |\n|(1995,2005].1  |outset        |outset       |outset       |outset       |outset       |outset       |outset       |outset       |outset        |outset        |\n|(1995,2005].2  |african       |azerbaijan   |island       |korea        |croatia      |marino       |trinidad     |afghanistan  |arab          |sri           |\n|(1995,2005].3  |africa        |cyprus       |caribbean    |korean       |european     |san          |tobago       |taliban      |iraq          |ethiopia      |\n|(1995,2005].4  |guinea        |tajikistan   |pacif        |nepal        |herzegovina  |women        |belarus      |swaziland    |israel        |lanka         |\n|(1995,2005].5  |congo         |armenia      |saint        |pakistan     |mongolia     |sixtieth     |slovakia     |ecuador      |palestinian   |eritrea       |\n|(1995,2005].6  |malawi        |turkmenistan |papua        |ireland      |kosovo       |iraq         |panama       |bolivia      |isra          |andorra       |\n|(1995,2005].7  |chad          |turkey       |bahama       |thailand     |€            |outcom       |haiti        |myanmar      |lebanon       |eritrean      |\n|(1995,2005].8  |burundi       |kazakhstan   |barbado      |asean        |latvia       |weapon       |mexico       |estonia      |malta         |cuba          |\n|(1995,2005].9  |liberia       |georgia      |solomon      |monaco       |bosnia       |document     |guatemala    |chile        |kuwait        |truth         |\n|(1995,2005].10 |uganda        |turkish      |small        |india        |bulgaria     |uruguay      |dominican    |paraguay     |iraqi         |muslim        |\n|(2005,2015].1  |everi         |everi        |everi        |everi        |everi        |everi        |everi        |everi        |everi         |everi         |\n|(2005,2015].2  |nepal         |pakistan     |serbia       |japan        |mdgs         |guinea       |island       |arab         |ecuador       |azerbaijan    |\n|(2005,2015].3  |iceland       |iran         |fiji         |timor        |treati       |african      |sid          |yemen        |panama        |georgia       |\n|(2005,2015].4  |trinidad      |muslim       |european     |mongolia     |g            |korea        |pacif        |kuwait       |paraguay      |asean         |\n|(2005,2015].5  |burundi       |islam        |kosovo       |ireland      |nuclear      |mali         |solomon      |syrian       |marino        |kazakhstan    |\n|(2005,2015].6  |sri           |god          |bosnia       |lest         |mediat       |somalia      |saint        |iraq         |peru          |ukrain        |\n|(2005,2015].7  |tobago        |war          |herzegovina  |bangladesh   |disput       |korean       |bahama       |lebanon      |america       |afghanistan   |\n|(2005,2015].8  |canada        |nuclear      |cyprus       |latvia       |disarma      |sudan        |caribbean    |palestinian  |american      |moldova       |\n|(2005,2015].9  |malawi        |want         |malta        |cambodia     |migrat       |philippin    |grenada      |egypt        |latin         |thailand      |\n|(2005,2015].10 |zambia        |israel       |croatia      |australia    |multilater   |bissau       |small        |libya        |bolivia       |turkmenistan  |\n|(2015,2022].1  |distinct      |african      |israel       |distinct     |ukrain       |india        |pacif        |bosnia       |pandem        |korea         |\n|(2015,2022].2  |peacekeep     |mali         |syrian       |azerbaijan   |european     |pakistan     |island       |herzegovina  |covid         |malaysia      |\n|(2015,2022].3  |andorra       |sudan        |iran         |armenia      |russian      |sri          |ocean        |saint        |un            |asean         |\n|(2015,2022].4  |trade         |sahel        |brazil       |trinidad     |russia       |lanka        |solomon      |caribbean    |vaccin        |mongolia      |\n|(2015,2022].5  |weapon        |congo        |colombia     |tobago       |eu           |costa        |tonga        |beliz        |75th          |thailand      |\n|(2015,2022].6  |migrant       |chad         |spain        |burundi      |ireland      |bangladesh   |papua        |mauritius    |marino        |kazakhstan    |\n|(2015,2022].7  |educ          |guinea       |venezuela    |kingdom      |georgia      |canada       |australia    |nepal        |bhutan        |turkmenistan  |\n|(2015,2022].8  |energi        |africa       |iraq         |morocco      |serbia       |rica         |tanzania     |guatemala    |kenya         |japan         |\n|(2015,2022].9  |refuge        |madagascar   |palestinian  |arab         |europ        |kashmir      |micronesia   |moldova      |botswana      |kyrgyzstan    |\n|(2015,2022].10 |sdgs          |burkina      |lebanon      |yemeni       |montenegro   |muslim       |tuvalu       |bahama       |somalia       |tajikistan    |\n\n\n\nEach column in the dataset corresponds to a vector of terms representing a specific topic. However, extracting substantively meaningful topics poses challenges due to several issues. One notable challenge is the variability in the set of terms used to represent the same topic across different time periods. For instance, the topic of international security may be discussed in relation to the Soviet Union and North Korea in earlier time periods, whereas in more recent times, it may be associated with Russia and Ukraine.\nAnother important problem is identifying related topics over time. There is a difficulty of establishing connections between topics and understanding their evolution across different temporal contexts. Some topics and terms disappear abruptly, while new topics emerge. Identifying the connection between vectors poses a challenge.",
    "crumbs": [
      "Topic Modeling",
      "Decadal LDA"
    ]
  },
  {
    "objectID": "rmarkdown/UNGDC_topic_modeling_updated.html#dynamic-topic-modeling",
    "href": "rmarkdown/UNGDC_topic_modeling_updated.html#dynamic-topic-modeling",
    "title": "Dynamic UNGDC (updated)",
    "section": "Dynamic Topic Modeling",
    "text": "Dynamic Topic Modeling\n\nTo address the above mentioned challenges, we refered to existing papers.\n\"BERTopic Dynamic Topic Modeling\"(https://maartengr.github.io/BERTopic/getting_started/topicsovertime/topicsovertime.html)\nGreene and cross, 2017 (https://doi.org/10.1017/pan.2016.7)\n\n\nThis generates output for a single pair of time frames\n\nmodel1&lt;-lda_models[[1]]\nmodel2&lt;-lda_models[[2]]\n\n# phi value is a topic probability of every word\nphi1 &lt;- model1$phi\n\n#phi1$topic &lt;- sequence(nrow(phi1))\n\nphi2 &lt;- model2$phi\n#phi2$topic &lt;- sequence(nrow(phi2))\n\n\n# Convert matrices to data frames\nphi1_df &lt;- as.data.frame(phi1)\nphi2_df &lt;- as.data.frame(phi2)\n\norder_phi1 &lt;- order(colMeans(phi1_df), decreasing = TRUE)\norder_phi2 &lt;- order(colMeans(phi2_df), decreasing = TRUE)\n\n# Reorder columns based on the mean\nphi1_df &lt;- phi1_df[, order_phi1]\nphi2_df &lt;- phi2_df[, order_phi2]\n\n# Identify columns to drop based on colMeans\n## Try without dropping\ncolumns_to_drop_phi1 &lt;- colMeans(phi1_df) &lt; 0.00001\ncolumns_to_drop_phi2 &lt;- colMeans(phi2_df) &lt; 0.00001\n\n# Drop identified columns\nphi1_df &lt;- phi1_df[, !columns_to_drop_phi1, drop = FALSE]\nphi2_df &lt;- phi2_df[, !columns_to_drop_phi2, drop = FALSE]\n\n\n# Get the union of column names\nall_terms &lt;- union(colnames(phi1_df), colnames(phi2_df))\n\n#fill missing values with zeros\nphi1_union &lt;- bind_cols(phi1_df, setNames(data.frame(matrix(0, nrow = nrow(phi1_df), ncol = length(setdiff(all_terms, colnames(phi1_df))))), setdiff(all_terms, colnames(phi1_df))))\nphi2_union &lt;- bind_cols(phi2_df, setNames(data.frame(matrix(0, nrow = nrow(phi2_df), ncol = length(setdiff(all_terms, colnames(phi2_df))))), setdiff(all_terms, colnames(phi2_df))))\n\n# Reorder columns alphabetically\nphi1_union &lt;- phi1_union[, order(colnames(phi1_union))]\nphi2_union &lt;- phi2_union[, order(colnames(phi2_union))]\n\n\ndim(phi1_union)\ndim(phi2_union)\n\n\ncor&lt;-cor(t(phi1_union), t(phi2_union))\n\n\nheatmap.2(cor,\n          Rowv = FALSE, Colv = FALSE,\n          col = heat.colors(256),\n          trace = \"none\", # no row/column names\n          key = TRUE, keysize = 1.5,\n          density.info = \"none\", margins = c(5, 5),\n          cexCol = 1, cexRow = 1, # adjust text size\n          notecol = \"black\", notecex = 0.7,\n          main = \"Correlation Matrix\",\n          xlab = \"Period 2\", ylab = \"Period 1\",\n          symkey = FALSE)\n\norder_phi1_union &lt;- order(colMeans(phi1_union), decreasing = TRUE)\nphi1_result &lt;- phi1_union[, order_phi1_union]\n\norder_phi2_union &lt;- order(colMeans(phi2_union), decreasing = TRUE)\nphi2_result &lt;- phi2_union[, order_phi2_union]\n\n\nphi1_result_row &lt;- orderBasedOnRow(phi1_union, 1)\nphi1_result_long&lt;-phi1_result_row%&gt;%\n  tidyr::pivot_longer(everything(), names_to=\"term_1\", values_to=\"probability_1\")\n\nphi2_result_row &lt;- orderBasedOnRow(phi2_union, 6)\nphi2_result_long&lt;-phi2_result_row%&gt;%\n  tidyr::pivot_longer(everything(), names_to=\"term_2\", values_to=\"probability_2\")\n\npair&lt;-bind_cols(phi1_result_long, phi2_result_long)\n\n#Function to print out the words\n\norderBasedOnRow &lt;- function(df, I) {\n  # Order columns based on the Ith row values\n  ordered_cols &lt;- order(apply(df, 2, function(x) x[I]), decreasing = TRUE)\n\n  # Reorder the data frame columns\n  ordered_df &lt;- df[, ordered_cols]\n\n  ordered_row &lt;- ordered_df[I, 1:10]\n\n  return(ordered_row)\n}",
    "crumbs": [
      "Topic Modeling",
      "Decadal LDA"
    ]
  },
  {
    "objectID": "rmarkdown/UNGDC_topic_modeling_updated.html#below-function-generates-heatmaps-for-a-pair-of-models.",
    "href": "rmarkdown/UNGDC_topic_modeling_updated.html#below-function-generates-heatmaps-for-a-pair-of-models.",
    "title": "Dynamic UNGDC (updated)",
    "section": "Below function generates heatmaps for a pair of models.",
    "text": "Below function generates heatmaps for a pair of models.\n\ngenerate_heatmap &lt;- function(model1, model2, correlation_threshold = 0.9) {\n  phi1 &lt;- model1$phi\n  phi2 &lt;- model2$phi\n\n  phi1_df &lt;- as.data.frame(phi1)\n  phi2_df &lt;- as.data.frame(phi2)\n  \n  all_terms &lt;- union(colnames(phi1_df), colnames(phi2_df))\n\n  phi1_union &lt;- bind_cols(phi1_df, setNames(data.frame(matrix(0, nrow = nrow(phi1_df), ncol = length(setdiff(all_terms, colnames(phi1_df))))), setdiff(all_terms, colnames(phi1_df))))\n  phi2_union &lt;- bind_cols(phi2_df, setNames(data.frame(matrix(0, nrow = nrow(phi2_df), ncol = length(setdiff(all_terms, colnames(phi2_df))))), setdiff(all_terms, colnames(phi2_df))))\n\n  phi1_union &lt;- phi1_union[, order(colnames(phi1_union))]\n  phi2_union &lt;- phi2_union[, order(colnames(phi2_union))]\n\n  dim(phi1_union)\n  dim(phi2_union)\n\n  cor_matrix &lt;- cor(t(phi1_union), t(phi2_union))\n\n  # Heatmap for correlation matrix\n  heatmap.2(cor_matrix,\n            Rowv = FALSE, Colv = FALSE,\n            col = heat.colors(16),\n            trace = \"none\", # no row/column names\n            key = TRUE, keysize = 1.5,\n            density.info = \"none\", margins = c(5, 5),\n            cexCol = 1, cexRow = 1, # adjust text size\n            notecol = \"black\", notecex = 0.7,\n            xlab = \"Time 2\",\n            ylab = \"Time 1\",\n            symkey = FALSE)\n\n  return(list(phi1_union = phi1_union, phi2_union = phi2_union, cor_matrix = cor_matrix))\n}",
    "crumbs": [
      "Topic Modeling",
      "Decadal LDA"
    ]
  },
  {
    "objectID": "rmarkdown/UNGDC_topic_modeling_updated.html#rows-with-high-correlation",
    "href": "rmarkdown/UNGDC_topic_modeling_updated.html#rows-with-high-correlation",
    "title": "Dynamic UNGDC (updated)",
    "section": "Rows with high correlation",
    "text": "Rows with high correlation\n\n# Function to print the ordered rows for each topic with high correlation\nprint_ordered_rows &lt;- function(phi1_union, phi2_union, cor_matrix, high_corr_indices, correlation_threshold = 0.9) {\n  # Find indices where correlation is higher than the threshold\n  high_corr_indices &lt;- which(cor_matrix &gt; correlation_threshold & !is.na(cor_matrix), arr.ind = TRUE)\n\n  # Create an empty list to store results\n  result_list &lt;- list()\n\n  # Print the ordered rows for each topic with high correlation\n  for (i in seq_len(nrow(high_corr_indices))) {\n    model1_topic &lt;- high_corr_indices[i, 1]\n    model2_topic &lt;- high_corr_indices[i, 2]\n\n    # Print the ordered rows for each model's topic\n    cat(paste(\"Model 1 - Topic\", model1_topic), \"\\n\")\n    phi1_result_row &lt;- orderBasedOnRow(phi1_union, model1_topic)\n\n    cat(paste(\"Model 2 - Topic\", model2_topic), \"\\n\")\n    phi2_result_row &lt;- orderBasedOnRow(phi2_union, model2_topic)\n\n    # Convert result rows to long format\n    phi1_result_long &lt;- phi1_result_row %&gt;%\n      tidyr::pivot_longer(everything(), names_to = \"term_1\", values_to = \"probability_1\")\n\n    phi2_result_long &lt;- phi2_result_row %&gt;%\n      tidyr::pivot_longer(everything(), names_to = \"term_2\", values_to = \"probability_2\")\n\n    # Combine phi1 and phi2 results\n    pair &lt;- bind_cols(phi1_result_long, phi2_result_long)\n\n    # Append the result to the list\n    result_list[[i]] &lt;- pair\n  }\n\n  # Combine all results into a single dataframe\n  final_result &lt;- do.call(bind_rows, result_list)\n\n  return(final_result)\n}",
    "crumbs": [
      "Topic Modeling",
      "Decadal LDA"
    ]
  },
  {
    "objectID": "rmarkdown/UNGDC_topic_modeling_updated.html#execute-functions-over-pairs",
    "href": "rmarkdown/UNGDC_topic_modeling_updated.html#execute-functions-over-pairs",
    "title": "Dynamic UNGDC (updated)",
    "section": "Execute functions over pairs",
    "text": "Execute functions over pairs\n\n# Loop through pairs of models to generate heatmaps and print results\nfor (i in 1:(length(lda_models) - 1)) {\n  model1 &lt;- lda_models[[i]]\n  model2 &lt;- lda_models[[i + 1]]\n\n  result &lt;- generate_heatmap(model1, model2, correlation_threshold = 0.5)\n  \n  phi1_union &lt;- result$phi1_union\n  phi2_union &lt;- result$phi2_union\n  cor_matrix &lt;- result$cor_matrix\n\n  # Print ordered rows only if there are high correlations\n  if (any(cor_matrix &gt; 0.5, na.rm = TRUE)) {\n    phi1_result &lt;- phi1_union[, order(colMeans(phi1_union), decreasing = TRUE)]\n    phi2_result &lt;- phi2_union[, order(colMeans(phi2_union), decreasing = TRUE)]\n\n    # Call the modified function and pass high_corr_indices as an argument\n    final_result &lt;- print_ordered_rows(phi1_result, phi2_result, cor_matrix, high_corr_indices, correlation_threshold = 0.5)\n    print(final_result)\n  }\n}\n\n\n\n\n\n\n\n\nModel 1 - Topic 3 \nModel 2 - Topic 9 \nModel 1 - Topic 2 \nModel 2 - Topic 10 \n# A tibble: 20 × 4\n   term_1       probability_1 term_2       probability_2\n   &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;                &lt;dbl&gt;\n 1 german             0.0150  german             0.0138 \n 2 czechoslovak       0.0119  socialist          0.0102 \n 3 polish             0.0113  soviet             0.00986\n 4 soviet             0.0108  czechoslovak       0.00816\n 5 germani            0.0101  albania            0.00793\n 6 people’            0.00766 romanian           0.00732\n 7 poland             0.00693 germani            0.00728\n 8 weapon             0.00632 byelorussian       0.00726\n 9 hydrogen           0.00619 nato               0.00629\n10 geneva             0.00595 albanian           0.00548\n11 arab               0.0271  arab               0.0249 \n12 israel             0.0228  israel             0.0231 \n13 palestin           0.0129  palestin           0.0155 \n14 jerusalem          0.0104  egypt              0.0105 \n15 morocco            0.00949 algerian           0.0101 \n16 tunisia            0.00899 libya              0.00916\n17 jew                0.00821 franc              0.00826\n18 refuge             0.00728 libyan             0.00782\n19 jewish             0.00635 canal              0.00776\n20 franc              0.00500 jordan             0.00729\n\n\n\n\n\n\n\n\n\nModel 1 - Topic 8 \nModel 2 - Topic 3 \nModel 1 - Topic 10 \nModel 2 - Topic 6 \nModel 1 - Topic 7 \nModel 2 - Topic 8 \n# A tibble: 30 × 4\n   term_1    probability_1 term_2    probability_2\n   &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;             &lt;dbl&gt;\n 1 african         0.0150  african         0.00885\n 2 africa          0.00815 ghana           0.00692\n 3 portug          0.00735 rwanda          0.00661\n 4 mali            0.00729 portug          0.00620\n 5 portugues       0.00670 uganda          0.00618\n 6 somali          0.00661 burundi         0.00593\n 7 congo           0.00627 africa          0.00530\n 8 austrian        0.00601 portugues       0.00462\n 9 cameroon        0.00564 kenya           0.00460\n10 malagasi        0.00553 oau             0.00452\n# ℹ 20 more rows\n\n\n\n\n\n\n\n\n\nModel 1 - Topic 4 \nModel 2 - Topic 4 \n# A tibble: 10 × 4\n   term_1      probability_1 term_2      probability_2\n   &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;\n 1 imperialist       0.0162  imperialist       0.0108 \n 2 khmer             0.00847 vietnames         0.0106 \n 3 aggress           0.00749 kampuchea         0.00971\n 4 imperi            0.00718 chines            0.00956\n 5 revisionist       0.00666 lao               0.00954\n 6 albania           0.00659 thailand          0.00947\n 7 albanian          0.00594 nam               0.00870\n 8 viet              0.00576 viet              0.00863\n 9 cambodia          0.00553 ethiopia          0.00833\n10 chines            0.00545 romania           0.00801",
    "crumbs": [
      "Topic Modeling",
      "Decadal LDA"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "United Nations General Debate Corpus (UNGDC)",
    "section": "",
    "text": "This corpus contains 10568 English transcripts of speeches delivered by state representatives of the UN member states at the United Nations General Debate from 1946 until 2022. Text data was made available by Baturo et al. (2017). Original data is in a form of .txt file, each containing speech transcript from one member state in a given year. This RDS dataset was generated by executing “RDS_generator.R” file to read in all .txt files into a single dataframe. File size is 58.61 MB. Alternatively, run “json_convertor.R” file to transform plain texts into structured .json files.\nDatasets can be found here. Three identifying variables across all documents are: ccode_iso (ISO 3-letter character country code), session (session number of the given UNGD meeting), year (year of UNGD).\nRefer to the description.Rmd file for an overview of the dataset.\n\n\n\nFile\nDescription\n\n\n\n\ncleaned.csv\n10568 observations. “text” is cleaned after removing white spaces(multiple spaces and tab), digits followed by a dot. This does not exclude any stop words.\n\n\nlight.csv\n10568 observations. “text” does not have any stop words.\n\n\nmeta.csv\n10568 observations with 110 variables. This data contains country-year level information for each speaker country. Refer to codebook for more description on each feature.\n\n\nliwc_controls.csv\n10568 observations with 222 variables. This data contains country-year level information for each speaker country as well as psychological, linguistic constructs generated by LIWC.\n\n\n\n\n\n\n`UNGDC_topic_modeling_updated.qmd’ renders LDA results. This version replaced deprecated functions from the quanteda package. It also presents a workflow with the goal of handling dynamic nature of topic models. Using correlation, this script shows the overlap between topics, represented with different terms over time.\n\n\n\nSlava Jankin, Alexander Baturo, and Niheer Dasandi. “Words to Unite Nations: The Complete UN General Debate Corpus, 1946-Present.” OSF working paper, https://osf.io/6kty4\nAlexander Baturo, Niheer Dasandi, and Slava Mikhaylov, “Understanding State Preferences With Text As Data: Introducing the UN General Debate Corpus” Research & Politics, 2017.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#data-description",
    "href": "index.html#data-description",
    "title": "United Nations General Debate Corpus (UNGDC)",
    "section": "",
    "text": "This corpus contains 10568 English transcripts of speeches delivered by state representatives of the UN member states at the United Nations General Debate from 1946 until 2022. Text data was made available by Baturo et al. (2017). Original data is in a form of .txt file, each containing speech transcript from one member state in a given year. This RDS dataset was generated by executing “RDS_generator.R” file to read in all .txt files into a single dataframe. File size is 58.61 MB. Alternatively, run “json_convertor.R” file to transform plain texts into structured .json files.\nDatasets can be found here. Three identifying variables across all documents are: ccode_iso (ISO 3-letter character country code), session (session number of the given UNGD meeting), year (year of UNGD).\nRefer to the description.Rmd file for an overview of the dataset.\n\n\n\nFile\nDescription\n\n\n\n\ncleaned.csv\n10568 observations. “text” is cleaned after removing white spaces(multiple spaces and tab), digits followed by a dot. This does not exclude any stop words.\n\n\nlight.csv\n10568 observations. “text” does not have any stop words.\n\n\nmeta.csv\n10568 observations with 110 variables. This data contains country-year level information for each speaker country. Refer to codebook for more description on each feature.\n\n\nliwc_controls.csv\n10568 observations with 222 variables. This data contains country-year level information for each speaker country as well as psychological, linguistic constructs generated by LIWC.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#lda-analysis",
    "href": "index.html#lda-analysis",
    "title": "United Nations General Debate Corpus (UNGDC)",
    "section": "",
    "text": "`UNGDC_topic_modeling_updated.qmd’ renders LDA results. This version replaced deprecated functions from the quanteda package. It also presents a workflow with the goal of handling dynamic nature of topic models. Using correlation, this script shows the overlap between topics, represented with different terms over time.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "United Nations General Debate Corpus (UNGDC)",
    "section": "",
    "text": "Slava Jankin, Alexander Baturo, and Niheer Dasandi. “Words to Unite Nations: The Complete UN General Debate Corpus, 1946-Present.” OSF working paper, https://osf.io/6kty4\nAlexander Baturo, Niheer Dasandi, and Slava Mikhaylov, “Understanding State Preferences With Text As Data: Introducing the UN General Debate Corpus” Research & Politics, 2017.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "rmarkdown/moving_lda_0219.html",
    "href": "rmarkdown/moving_lda_0219.html",
    "title": "Moving LDA Version - Inverse Weighted",
    "section": "",
    "text": "This study analyzes the global agenda of the United Nations General Debate (UNGD) and shows temporal development of the topics. Substantively, UNGDC reflects in change of agendas when exogenous shocks take place. The issue of connecting time-series evolution of topic has been addressed by others. Rieger et al. (Rieger, Jentsch, and Rahnenführer 2021) introduces a sequential approach to LDA with the accompanying package, and Greene at al. (Greene and Cross 2017) uses non-negative matrix factorization to analyze the European Parliament Debate Corpus.\nThere are two main challenges to address cross-section time-series text dataset. First, same topic is represented with different sets of terms over time, given the social context and norms around a specific construct. Second, given changes around the topic representation, it requires theory-based post-labeling to",
    "crumbs": [
      "Topic Modeling",
      "Moving LDA"
    ]
  },
  {
    "objectID": "rmarkdown/moving_lda_0219.html#introduction",
    "href": "rmarkdown/moving_lda_0219.html#introduction",
    "title": "Moving LDA Version - Inverse Weighted",
    "section": "",
    "text": "This study analyzes the global agenda of the United Nations General Debate (UNGD) and shows temporal development of the topics. Substantively, UNGDC reflects in change of agendas when exogenous shocks take place. The issue of connecting time-series evolution of topic has been addressed by others. Rieger et al. (Rieger, Jentsch, and Rahnenführer 2021) introduces a sequential approach to LDA with the accompanying package, and Greene at al. (Greene and Cross 2017) uses non-negative matrix factorization to analyze the European Parliament Debate Corpus.\nThere are two main challenges to address cross-section time-series text dataset. First, same topic is represented with different sets of terms over time, given the social context and norms around a specific construct. Second, given changes around the topic representation, it requires theory-based post-labeling to",
    "crumbs": [
      "Topic Modeling",
      "Moving LDA"
    ]
  },
  {
    "objectID": "rmarkdown/moving_lda_0219.html#goal",
    "href": "rmarkdown/moving_lda_0219.html#goal",
    "title": "Moving LDA Version - Inverse Weighted",
    "section": "Goal",
    "text": "Goal\nIn order to generate LDA estimations across time more smoothly, this script changes the UNGDC_topic_modeling_updated.qmdand experiments with different moving window. Just like the other scripts, I use cleaned.csv file. It has four columns: “ccode_iso”, “session”, “year”, and finally “text”.",
    "crumbs": [
      "Topic Modeling",
      "Moving LDA"
    ]
  },
  {
    "objectID": "rmarkdown/moving_lda_0219.html#experiment-logs",
    "href": "rmarkdown/moving_lda_0219.html#experiment-logs",
    "title": "Moving LDA Version - Inverse Weighted",
    "section": "Experiment logs",
    "text": "Experiment logs\nSize of the window, and overlapping interval can influence the level of correlation between vectors. The goal of experiments with changing parameters is to capture general themes that discuss beyond a region-specific topic. Furthermore, I overcome the problem of raw term frequency that treats all terms as equally important. Inverse document frequency (idf) of a term is a weight, defined as logged value of the total number of documents in a collection denominated by the number of documents that contain the term. Intuitively, this gives less weight to terms that show up commonly across all the documents. The term frequency-inverse document frequency(tf-idf) weighting scheme returns a weight to a term that increases with the number of occurrence within a small (Rieger, Jentsch, and Rahnenführer 2021)set of documents ((Manning, Raghavan, and Schütze 2008)). This supplements the explicit omission of stop words by winnowing out context-specific frequent words.\nThere are different options for weight type, which determines the way each term is counted. Functionally, I used quanteda package to specify this scheme option. I tried count type, which provides an integer feature of count, and proportion type that is based on the relative frequency of a term compared to total counts. Proportion type is calculated by \\(\\frac{tf_{ij}}{\\Sigma_{j} {tf_{ij}}}\\) where in \\(i, j\\) each represents indices for a term and a document. Given the normalization process of the proportion weight type, variation between terms is smaller than simple count type. This is expected to lessen the gap between rare and frequent terms, and hence allow model to capture even general terms. However, R package seededlda and its function topic_models does not allow tf_idf based on “proportion” as an input because LDA assumes integer counts as observations, not floats.\nThis version presents the outcome generated by Experiment 3. Experiment 2 log can be found in moving_lda_0218.qmd.\n\nTrial 1: 10-year, 5 overlap, saved in moving_0209. tfidf option: count and inverse. 10 topics\nTrial 2: 10-year, 5 overlap, saved in moving_0218_2. tfidf option: none. 20 topics\nTrial 3: 10-year, 5 overlap, saved in moving_0219. tfidf option: count and inverse. 20 topics\nTrial 4: try a different R package for the proportion-inverse-weighted LDA other than ‘quanteda’",
    "crumbs": [
      "Topic Modeling",
      "Moving LDA"
    ]
  },
  {
    "objectID": "rmarkdown/moving_lda_0219.html#setting-up-libraries-and-load-raw-data",
    "href": "rmarkdown/moving_lda_0219.html#setting-up-libraries-and-load-raw-data",
    "title": "Moving LDA Version - Inverse Weighted",
    "section": "Setting up libraries and load raw data",
    "text": "Setting up libraries and load raw data\n\nlibrary(plyr)\nlibrary(dplyr)\nlibrary(tm)\nlibrary(ggplot2)\nlibrary(quanteda)\nlibrary(readr)\nlibrary(seededlda)\nlibrary(slam)\nlibrary(jsonlite)\nlibrary(gplots) #this is for heatmap\nlibrary(zoo)\nlibrary(tibble)\nlibrary(knitr)\nlibrary(topicmodels)\n\n\n#light&lt;-read.csv(\"../data/processed/cleaned.csv\")\n#light&lt;-light%&gt;%select(-X)\n\nmystopwords &lt;- c(\"will\", \"must\", \"mr\") #removing context-specific stopwords\ncustom_stopwords &lt;-c(stopwords(\"english\"), mystopwords)\n\n# Set up the parameters\ninterval &lt;- 10\n\nbreaks &lt;- c(seq(from = 1945, to = 2020, by = 5), 2022) \n\nlast_break &lt;- breaks[length(breaks)-1]\n\nif (last_break + interval &gt; 2020) {\n  moving_breaks &lt;- breaks\n} else {\n  moving_breaks &lt;- c(breaks, last_break + interval)\n}\n\nstart_years &lt;- moving_breaks[1:14]\nend_years &lt;- start_years + interval\nend_years &lt;- end_years[1:14]\n\n# add the final two windows\nspan_levels &lt;- c(paste0(start_years, \"-\", end_years), \"2015-2022\", \"2020-2022\")",
    "crumbs": [
      "Topic Modeling",
      "Moving LDA"
    ]
  },
  {
    "objectID": "rmarkdown/moving_lda_0219.html#uncomment-the-below-section-to-run-the-lda-analysis",
    "href": "rmarkdown/moving_lda_0219.html#uncomment-the-below-section-to-run-the-lda-analysis",
    "title": "Moving LDA Version - Inverse Weighted",
    "section": "Uncomment the below section to run the LDA analysis",
    "text": "Uncomment the below section to run the LDA analysis\n\n#lda_generator(light, span_levels)",
    "crumbs": [
      "Topic Modeling",
      "Moving LDA"
    ]
  },
  {
    "objectID": "rmarkdown/moving_lda_0219.html#function-1-generating-heatmaps",
    "href": "rmarkdown/moving_lda_0219.html#function-1-generating-heatmaps",
    "title": "Moving LDA Version - Inverse Weighted",
    "section": "Function 1) Generating heatmaps",
    "text": "Function 1) Generating heatmaps\nTo visualize the correlation between term-weight vectors from two time periods, below function generates heatmaps across pairs. This process also includes intermediate steps that generate a union of term vectors, which is needed to match the dimension between two matrices. A pair of lda_models should be neighbors from two consecutive time intervals, which may vary.\n\nInputs: span levels in character form, two lda_models in a list form\nOutput: Heatmap plots",
    "crumbs": [
      "Topic Modeling",
      "Moving LDA"
    ]
  },
  {
    "objectID": "rmarkdown/moving_lda_0219.html#function-2-printing-out-correlated-term-vectors",
    "href": "rmarkdown/moving_lda_0219.html#function-2-printing-out-correlated-term-vectors",
    "title": "Moving LDA Version - Inverse Weighted",
    "section": "Function 2) Printing out correlated term vectors",
    "text": "Function 2) Printing out correlated term vectors\nBased on the correlation matrix, below code prints out term vectors that show high correlation. It also lists the topic index from two different time intervals. Note that even the highly-correlated topics can have different topic indices.\n\nprint_ordered_rows &lt;- function(phi1_union, phi2_union, cor_matrix, high_corr_indices, correlation_threshold = 0.9) {\n  # Find indices where correlation is higher than the threshold\n  high_corr_indices &lt;- which(cor_matrix &gt; correlation_threshold & !is.na(cor_matrix), arr.ind = TRUE)\n  \n  # Create an empty list to store results\n  result_list &lt;- list()\n  \n  # Print the ordered rows for each topic with high correlation\n  for (i in seq_len(nrow(high_corr_indices))) {\n    model1_topic &lt;- high_corr_indices[i, 1]\n    model2_topic &lt;- high_corr_indices[i, 2]\n    \n    # Print the ordered rows for each model's topic\n    cat(paste(\"Model 1 - Topic\", model1_topic), \"\\n\")\n    phi1_result_row &lt;- orderBasedOnRow(phi1_union, model1_topic)\n    \n    cat(paste(\"Model 2 - Topic\", model2_topic), \"\\n\")\n    phi2_result_row &lt;- orderBasedOnRow(phi2_union, model2_topic)\n    \n    # Convert result rows to long format\n    phi1_result_long &lt;- phi1_result_row %&gt;%\n      tidyr::pivot_longer(everything(), names_to = \"term_1\", values_to = \"probability_1\")\n    \n    phi2_result_long &lt;- phi2_result_row %&gt;%\n      tidyr::pivot_longer(everything(), names_to = \"term_2\", values_to = \"probability_2\")\n    \n    # Combine phi1 and phi2 results\n    pair &lt;- bind_cols(phi1_result_long, phi2_result_long)\n    \n    # Append the result to the list\n    result_list[[i]] &lt;- pair\n  }\n  \n  # Combine all results into a single dataframe\n  final_result &lt;- do.call(bind_rows, result_list)\n  \n  print(kable(final_result))\n}",
    "crumbs": [
      "Topic Modeling",
      "Moving LDA"
    ]
  },
  {
    "objectID": "rmarkdown/moving_lda_0219.html#function-3-sorting-top-10-terms-from-each-term-vector.",
    "href": "rmarkdown/moving_lda_0219.html#function-3-sorting-top-10-terms-from-each-term-vector.",
    "title": "Moving LDA Version - Inverse Weighted",
    "section": "Function 3) Sorting top 10 terms from each term vector.",
    "text": "Function 3) Sorting top 10 terms from each term vector.\nPrevious steps have sorted term columns alphabetically to create correlation matrix. I re-organize each time period’s term vector in the order of weights to list the most semantically significant term within each topic.\n\norderBasedOnRow &lt;- function(df, I) {\n  # Order columns based on the Ith row values\n  ordered_cols &lt;- order(apply(df, 2, function(x) x[I]), decreasing = TRUE)\n\n  # Reorder the data frame columns\n  ordered_df &lt;- df[, ordered_cols]\n\n  ordered_row &lt;- ordered_df[I, 1:10]\n\n  return(ordered_row)\n}",
    "crumbs": [
      "Topic Modeling",
      "Moving LDA"
    ]
  },
  {
    "objectID": "rmarkdown/liwc_randomforest.html",
    "href": "rmarkdown/liwc_randomforest.html",
    "title": "liwc_randomforest",
    "section": "",
    "text": "To compare the performance of logistic regression, we use non-parametric random forest models to see how well a battery of LIWC features can predict the regime type.\n\n\n\nlibrary(readr)\nlibrary(corrr)\nlibrary(ggplot2)\nlibrary(gmodels)\nlibrary(dplyr)\nlibrary(tidyverse)\nlibrary(countrycode)\nlibrary(broom)\nlibrary(knitr) \nlibrary(readxl)\nlibrary(rsample)\nlibrary(randomForest)\nlibrary(randomForestExplainer)\nlibrary(caret)\nlibrary(pROC)\nlibrary(kableExtra)",
    "crumbs": [
      "Linguistic Analysis",
      "LIWC Random Forest"
    ]
  },
  {
    "objectID": "rmarkdown/liwc_randomforest.html#data-and-setup",
    "href": "rmarkdown/liwc_randomforest.html#data-and-setup",
    "title": "liwc_randomforest",
    "section": "",
    "text": "library(readr)\nlibrary(corrr)\nlibrary(ggplot2)\nlibrary(gmodels)\nlibrary(dplyr)\nlibrary(tidyverse)\nlibrary(countrycode)\nlibrary(broom)\nlibrary(knitr) \nlibrary(readxl)\nlibrary(rsample)\nlibrary(randomForest)\nlibrary(randomForestExplainer)\nlibrary(caret)\nlibrary(pROC)\nlibrary(kableExtra)",
    "crumbs": [
      "Linguistic Analysis",
      "LIWC Random Forest"
    ]
  },
  {
    "objectID": "rmarkdown/liwc_randomforest.html#trial-1-including-wc-wps-period",
    "href": "rmarkdown/liwc_randomforest.html#trial-1-including-wc-wps-period",
    "title": "liwc_randomforest",
    "section": "Trial 1: Including WC, WPS, Period",
    "text": "Trial 1: Including WC, WPS, Period\nAs a baseline, the first trial keeps all of the LIWC features to the random forest model. This hit the accuracy rate of 0.7496. To make sure there is enough observations for both democracy and non-democracy, we use stratified sampling based on the main output of interest, “dd_democracy.” This means that the model performance can change when the distribution of the output is different from the current dataset. Our dataset has a well balanced distribution, with 4883 non-democracies and 4763 democracies. We randomly keep 30% of the data as a testing dataset.\nFunctionally, we use R packages (randomForestExplainer?; randomForest?) to generate various metrics of Importance.\n\nset.seed(3)\nsplit &lt;- rsample::initial_split(data, prop=0.7, strata=\"dd_democracy\")\ntrainN &lt;- rsample::training(split)\ntrainN$dd_democracy&lt;-factor(trainN$dd_democracy)\ntestN &lt;- rsample::testing(split)\n\n# Remove identifier variables. dd_regime is a 6-fold classification that is more comprehensive than dd_democracy.\ntrainN &lt;- trainN[, !(names(trainN) %in% c(\"ccode_iso\", \"year\", \"session\", \"dd_regime\"))]\ntestN &lt;- testN[, !(names(testN) %in% c(\"ccode_iso\", \"year\", \"session\", \"dd_regime\"))]\n\n# Remove rows with missing values\ntrainN &lt;- na.omit(trainN)\n\n# Fit random forest model\nbag.democracy1 &lt;- randomForest(dd_democracy ~ ., \n                               data = trainN, \n                               ntree = 500,\n                               mtry = ncol(trainN) - 1,\n                               importance = TRUE)\n\n# setting type to 1 selects Mean Accuracy Decrease, not Gini Coefficient. \nimportance(bag.democracy1,  type=1, scale = TRUE) %&gt;%\n  as.data.frame() %&gt;%\n  arrange(desc(abs(MeanDecreaseAccuracy))) %&gt;%head(20) %&gt;%\n  kbl() %&gt;%  kable_paper(\"hover\", full_width = FALSE) %&gt;%\n  scroll_box(width = \"100%\", height = \"400px\") \n\n\n\n\n\n\nMeanDecreaseAccuracy\n\n\n\n\nethnicity\n52.43919\n\n\nWPS\n40.94694\n\n\nPeriod\n38.65419\n\n\npower\n31.79705\n\n\nneed\n28.39407\n\n\ni\n28.20742\n\n\nmale\n24.63802\n\n\nwe\n20.74922\n\n\nprep\n20.62515\n\n\ndet\n20.46042\n\n\nverb\n20.29697\n\n\nfocusfuture\n19.64246\n\n\ntone_neg\n17.90792\n\n\nAuthentic\n17.84676\n\n\ntime\n17.73310\n\n\nemotion\n17.24758\n\n\nmoral\n17.14259\n\n\nauxverb\n17.06410\n\n\naffiliation\n16.23283\n\n\nDic\n15.76028\n\n\n\n\n\n\nvarImpPlot(bag.democracy1, type=1, scale = TRUE, sort=T, n.var= 25, main= \"Democracy vs. Non-democracy\", pch=16)\n\n\n\n\n\n\n\n# P-value on whether the observed number of successes &gt; the theoretical number of successes if random\nimportance_frame &lt;- measure_importance(bag.democracy1)\nimportance_frame%&gt;%\n  as.data.frame()%&gt;%\n  arrange(desc(abs(accuracy_decrease)))%&gt;% head(20) %&gt;%\n  kbl() %&gt;%  kable_paper(\"hover\", full_width = FALSE) %&gt;%\n  scroll_box(width = \"100%\", height = \"400px\") \n\n\n\n\n\nvariable\nmean_min_depth\nno_of_nodes\naccuracy_decrease\ngini_decrease\nno_of_trees\ntimes_a_root\np_value\n\n\n\n\nWPS\n1.33800\n4228\n0.0292639\n269.30627\n500\n344\n0.0000000\n\n\nPeriod\n3.13000\n3944\n0.0241194\n139.40684\n500\n156\n0.0000000\n\n\nethnicity\n1.19000\n3901\n0.0196658\n171.78294\n500\n0\n0.0000000\n\n\npower\n2.54200\n3936\n0.0110459\n93.92074\n500\n0\n0.0000000\n\n\nneed\n2.22800\n3657\n0.0085726\n71.88716\n500\n0\n0.0000000\n\n\nverb\n5.07824\n2162\n0.0072887\n37.01881\n494\n0\n0.9999992\n\n\nwe\n3.89208\n2725\n0.0065841\n48.25348\n498\n0\n0.0000000\n\n\ni\n3.35400\n4388\n0.0065604\n72.32486\n500\n0\n0.0000000\n\n\nmale\n2.80200\n3466\n0.0061633\n65.59172\n500\n0\n0.0000000\n\n\nauxverb\n6.49336\n2000\n0.0041989\n22.23185\n491\n0\n1.0000000\n\n\nprep\n5.44200\n3072\n0.0040095\n34.02075\n500\n0\n0.0000000\n\n\naffiliation\n5.89904\n2381\n0.0038055\n27.99589\n499\n0\n0.5835760\n\n\ntone_neg\n5.40904\n2658\n0.0036777\n30.89870\n499\n0\n0.0000000\n\n\ndet\n5.07000\n3109\n0.0036137\n37.64137\n500\n0\n0.0000000\n\n\nfocusfuture\n4.56200\n3573\n0.0035237\n46.24975\n500\n0\n0.0000000\n\n\nemotion\n4.28000\n2976\n0.0033963\n44.34134\n500\n0\n0.0000000\n\n\ndiscrep\n5.08304\n2693\n0.0029824\n36.01785\n499\n0\n0.0000000\n\n\nmoral\n4.21800\n3802\n0.0029608\n46.71324\n500\n0\n0.0000000\n\n\nAuthentic\n4.98208\n3068\n0.0028583\n37.35554\n498\n0\n0.0000000\n\n\ntime\n4.80400\n3647\n0.0028430\n42.62420\n500\n0\n0.0000000\n\n\n\n\n\n\n# scale = TRUE divides the permutation based measures into their \"standard errors\"\n#The function automatically scales the importance scores to be between 0 and 100. \n#Using scale = FALSE avoids this normalization step.\n\n\nTrial 1 Prediction Performance\n\nRT.pred1 &lt;- predict(bag.democracy1, newdata=testN, type=\"class\")\nRT.evlau1 &lt;- caret::confusionMatrix(as.factor(testN$dd_democracy), \n                                   RT.pred1, \n                                   positive = \"1\",\n                                   dnn = c(\"Reference\",\"Prediction\"))\nRT.evlau1\n\nConfusion Matrix and Statistics\n\n         Prediction\nReference    0    1\n        0 1081  384\n        1  313 1111\n                                          \n               Accuracy : 0.7587          \n                 95% CI : (0.7427, 0.7742)\n    No Information Rate : 0.5175          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.5177          \n                                          \n Mcnemar's Test P-Value : 0.008015        \n                                          \n            Sensitivity : 0.7431          \n            Specificity : 0.7755          \n         Pos Pred Value : 0.7802          \n         Neg Pred Value : 0.7379          \n             Prevalence : 0.5175          \n         Detection Rate : 0.3846          \n   Detection Prevalence : 0.4929          \n      Balanced Accuracy : 0.7593          \n                                          \n       'Positive' Class : 1               \n                                          \n\n# ROC curve and AUC\nRT.pred.roc1 &lt;- predict(bag.democracy1, newdata=testN, type=\"prob\")\nroc_RT.tree1 &lt;- roc(as.factor(testN$dd_democracy), RT.pred.roc1[,\"1\"])\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls &lt; cases\n\npar(mfrow=c(1,1))\nplot(roc_RT.tree1, main=\"ROC curve for Random Forest\", \n     col=\"blue\", lwd=2, legacy.axes=FALSE)\ntitle(main = paste('Area under the curve: ',auc(roc_RT.tree1)))\n\n\n\n\n\n\n\n\n\n\nPost Analysis on Trial 1: Understanding WPS\nBased on several importance metrics, “WPS” showed up as important features. Given theoretically weak ties between WPS and regime type, we investigate sources of biases in the model. The specific question here is ?\n\nHypothesis 1: Correlated varaibles\nGenerally, random forest has a strong performance in even correlated variables. Nevertheless, we check if there are any features that are storngly correlated with WPS.\nWPS is correlated with the percentage of “preposition” words and “determiners.” These are grammatical terms that are expected to increase with longer sentences in general. “Period” is negatively correlated. In Trial 2, we exclude correlated features and test how robust the model is.\n\ntrainN %&gt;% \n    correlate() %&gt;% \n    focus(WPS) %&gt;% arrange(desc(abs(WPS))) %&gt;%head(20) %&gt;%\n  kbl() %&gt;%  kable_paper(\"hover\", full_width = FALSE) %&gt;%\n  scroll_box(width = \"100%\", height = \"400px\") \n\nNon-numeric variables removed from input: `text`, and `dd_democracy`\nCorrelation computed with\n• Method: 'pearson'\n• Missing treated using: 'pairwise.complete.obs'\n\n\n\n\n\n\nterm\nWPS\n\n\n\n\nPeriod\n-0.6904750\n\n\nprep\n0.4428323\n\n\naffiliation\n-0.4018895\n\n\nAllPunc\n-0.3844678\n\n\ndet\n0.3819913\n\n\nClout\n-0.3778785\n\n\nWC\n0.3339915\n\n\nwe\n-0.3338740\n\n\narticle\n0.3317527\n\n\nipron\n0.3228187\n\n\nSocial\n-0.3142653\n\n\nDrives\n-0.3052480\n\n\ndiffer\n0.3039888\n\n\nfunction_feature\n0.2969884\n\n\nneed\n-0.2930493\n\n\nsocrefs\n-0.2837073\n\n\ntime\n-0.2719273\n\n\nrisk\n-0.2647073\n\n\nppron\n-0.2492513\n\n\nprosocial\n-0.2404551\n\n\n\n\n\n\n\n\n\nHypothesis 2: WPS has a strong predictive power\nIt might also be the case that WPS has a predictive power in a substantive manner. To make this null hypothesis as strong as possible, we only use a single feature, “WPS” to predict the output. Our expectation is a poor performance, in that we do not find any strong theoretical ground to expect a correlation between linguistic style to use a long sentence and a regime type.Contrary to our expectation, using WPS as a single predictor showed a great performance with the OOB estimate of error rate as low as 42.43%.\n\nset.seed(4)\nsplit &lt;- rsample::initial_split(data, prop=0.7, strata=\"dd_democracy\")\ntrainN &lt;- rsample::training(split)\ntrainN$dd_democracy&lt;-factor(trainN$dd_democracy)\ntestN &lt;- rsample::testing(split)\n\ntrainN &lt;- trainN[, (names(trainN) %in% c(\"WPS\", \"dd_democracy\"))]\ntestN &lt;- testN[, (names(testN) %in% c(\"WPS\", \"dd_democracy\"))]\n\n# Remove rows with missing values\ntrainN &lt;- na.omit(trainN)\n\n# Fit random forest model after removing missing values\nbag.democracy.h1 &lt;- randomForest(dd_democracy ~ ., \n                               data = trainN, \n                               ntree = 500,\n                               mtry = ncol(trainN) - 1,\n                               importance = TRUE)\nbag.democracy.h1\n\n\nCall:\n randomForest(formula = dd_democracy ~ ., data = trainN, ntree = 500,      mtry = ncol(trainN) - 1, importance = TRUE) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 1\n\n        OOB estimate of  error rate: 42.43%\nConfusion matrix:\n     0    1 class.error\n0 2205 1220   0.3562044\n1 1649 1687   0.4943046\n\n\nWe further tried creating a binary variable of long or short sentences on average, based on the “WPS.” Using WPS’s median value as a threshold, we created a new variable “long,” 1 when the WPS is greater than or equal to 29 and 0 otherwise. Using it as the only predictor, we put the variable into a harder test. Even more surprisingly, the error rate turned out to be 35.18%.\n\nwps.vis&lt;-data%&gt;%\n  group_by(dd_democracy)%&gt;%\n  mutate(wps.median=median(WPS), \n         wps.sd=sd(WPS), \n         long=ifelse(WPS&gt;=29, 1, 0)\n         )\n\nset.seed(5)\nsplit &lt;- rsample::initial_split(wps.vis, prop=0.7, strata=\"dd_democracy\")\ntrainN &lt;- rsample::training(split)\ntrainN$dd_democracy&lt;-factor(trainN$dd_democracy)\ntestN &lt;- rsample::testing(split)\n\ntrainN &lt;- trainN[, (names(trainN) %in% c(\"long\", \"dd_democracy\"))]\ntestN &lt;- testN[, (names(testN) %in% c(\"long\", \"dd_democracy\"))]\ntrainN &lt;- na.omit(trainN)\n\nbag.democracy.h2 &lt;- randomForest(dd_democracy ~ long, \n                               data = trainN, \n                               ntree = 500,\n                               mtry = ncol(trainN) - 1,\n                               importance = TRUE)\nbag.RT.pred.h2 &lt;- predict(bag.democracy.h2, newdata = testN) \nRT.pred.h2 &lt;- predict(bag.democracy.h2, newdata=testN, type=\"class\")\nRT.evlau.h2 &lt;- caret::confusionMatrix(as.factor(testN$dd_democracy), \n                                   RT.pred.h2, \n                                   positive = \"1\",\n                                   dnn = c(\"Reference\",\"Prediction\"))\nRT.evlau.h2\n\nConfusion Matrix and Statistics\n\n         Prediction\nReference   0   1\n        0 940 531\n        1 517 918\n                                          \n               Accuracy : 0.6394          \n                 95% CI : (0.6216, 0.6568)\n    No Information Rate : 0.5014          \n    P-Value [Acc &gt; NIR] : &lt;2e-16          \n                                          \n                  Kappa : 0.2787          \n                                          \n Mcnemar's Test P-Value : 0.688           \n                                          \n            Sensitivity : 0.6335          \n            Specificity : 0.6452          \n         Pos Pred Value : 0.6397          \n         Neg Pred Value : 0.6390          \n             Prevalence : 0.4986          \n         Detection Rate : 0.3159          \n   Detection Prevalence : 0.4938          \n      Balanced Accuracy : 0.6394          \n                                          \n       'Positive' Class : 1               \n                                          \n\n\nIt requires more theoretical investigation to figure out why a linguistic tendency to use long sentences have a strong explanation for the regime type. We also suspect a confounding effect of whether the speech was translated.\n\n\nHypothesis 3: Language as a confounder\nIt can actually be the case that countries that are not speaking English lead to a confounding effect. Data available here. New variable “eng” is coded 1 when one of the spoken languages is English, 0 otherwise.\n\nlang&lt;-read_csv(\"data/raw/countries_languages.csv\")\n\nRows: 198 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): Country, Languages Spoken\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# this is a metadata on country's official language\n\nlang&lt;-lang%&gt;%\n  mutate(ccode_iso = countrycode(Country, origin = 'country.name', destination = 'iso3c'))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `ccode_iso = countrycode(Country, origin = \"country.name\",\n  destination = \"iso3c\")`.\nCaused by warning:\n! Some values were not matched unambiguously: Kosovo, Micronesia\n\nlang&lt;-lang %&gt;%\n  mutate(eng=ifelse(str_detect(`Languages Spoken`, \"English\"), 1, 0))\n\nlang&lt;-lang%&gt;%\n  select(ccode_iso, eng)\n\nlang_data&lt;- left_join(data, lang, by=\"ccode_iso\")\n\nggplot(lang_data, aes(x=as.factor(eng), y=WPS)) + \n    geom_boxplot() \n\n\n\n\n\n\n\nset.seed(8)\nsplit &lt;- rsample::initial_split(data, prop=0.7, strata=\"dd_democracy\")\ntrainN &lt;- rsample::training(split)\ntrainN$dd_democracy&lt;-factor(trainN$dd_democracy)\ntestN &lt;- rsample::testing(split)\n\ntrainN &lt;- trainN[, (names(trainN) %in% c(\"WPS\", \"dd_democracy\"))]\ntestN &lt;- testN[, (names(testN) %in% c(\"WPS\", \"dd_democracy\"))]\n\n# Remove rows with missing values\ntrainN &lt;- na.omit(trainN)\n\n# Fit random forest model after removing missing values\nbag.democracy.h3 &lt;- randomForest(dd_democracy ~ ., \n                               data = trainN, \n                               ntree = 500,\n                               mtry = ncol(trainN) - 1,\n                               importance = TRUE)\nbag.democracy.h3\n\n\nCall:\n randomForest(formula = dd_democracy ~ ., data = trainN, ntree = 500,      mtry = ncol(trainN) - 1, importance = TRUE) \n               Type of random forest: classification\n                     Number of trees: 500\nNo. of variables tried at each split: 1\n\n        OOB estimate of  error rate: 44.03%\nConfusion matrix:\n     0    1 class.error\n0 2009 1418   0.4137730\n1 1567 1786   0.4673427",
    "crumbs": [
      "Linguistic Analysis",
      "LIWC Random Forest"
    ]
  },
  {
    "objectID": "rmarkdown/liwc_randomforest.html#trial-2-pca-on-liwc-features",
    "href": "rmarkdown/liwc_randomforest.html#trial-2-pca-on-liwc-features",
    "title": "liwc_randomforest",
    "section": "Trial 2: PCA on LIWC features",
    "text": "Trial 2: PCA on LIWC features\nTo account for high linearity among variables, including but not limited to WPS, we tried tried factor analysis to reduce the dimension. The results show that there are several vectors that represent the data without a strong skewness. The first representative vector explains only around 15% of the entire variance. Nevertheless, we fit the model with only the top five most representative components.\n\npca_data&lt;-data%&gt;%select(-text, -Segment, -ccode_iso, -dd_democracy)\npca_result&lt;- prcomp(pca_data,\n             center = TRUE,\n            scale. = TRUE)\n\nlibrary(factoextra)\n\nWelcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n\nfviz_eig(pca_result)\n\n\n\n\n\n\n\nggplot(data = NULL) +\n  geom_segment(data = as.data.frame(pca_result$rotation), \n               aes(x = 0, y = 0, xend = PC1, yend = PC2),\n               arrow = arrow(length = unit(0.2, \"cm\")), color = 'blue') +\n  geom_text(data = as.data.frame(pca_result$rotation), \n            aes(label = rownames(pca_result$rotation), x = PC1, y = PC2), \n            size = 5, check_overlap = TRUE) +  # Adjust the size parameter here\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nCross validation after PCA\nWe select the top 5 vectors that best represent the data. This will account for 30% of variances explained. After selecting 5 components, accuracy became 68%. We also used the top 3 components, which dropped the accuracy to 65%.\n\npca.df&lt;-pca_result$rotation\npca.df&lt;-pca.df%&gt;%as.data.frame()%&gt;%arrange(desc(abs(PC1)))\n\ncombined_data &lt;- cbind(pca_result$x[, 1:5], dd_democracy = data$dd_democracy)\ncombined_data &lt;- as.data.frame(combined_data)\n\ncombined_data$dd_democracy &lt;- as.factor(combined_data$dd_democracy)\n\nset.seed(6)\nsplit &lt;- rsample::initial_split(combined_data, prop = 0.7, strat = \"dd_democracy\")\ntrainN &lt;- rsample::training(split)\ntestN &lt;- rsample::testing(split)\n\n\ntrainN &lt;- trainN[, !(names(trainN) %in% c(\"ccode_iso\", \"year\", \"session\", \"dd_regime\"))]\ntestN &lt;- testN[, !(names(testN) %in% c(\"ccode_iso\", \"year\", \"session\", \"dd_regime\"))]\n\ntrainN &lt;- na.omit(trainN)\nbag.democracy.pca &lt;- randomForest(dd_democracy ~ ., \n                               data = trainN, \n                               ntree = 500,\n                               mtry = ncol(trainN) - 1,\n                               importance = TRUE)\n\n\npredictions &lt;- predict(bag.democracy.pca, newdata = testN)\nconfusionMatrix(data = predictions, reference = testN$dd_democracy)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 1009  446\n         1  462  976\n                                         \n               Accuracy : 0.6861         \n                 95% CI : (0.6689, 0.703)\n    No Information Rate : 0.5085         \n    P-Value [Acc &gt; NIR] : &lt;2e-16         \n                                         \n                  Kappa : 0.3722         \n                                         \n Mcnemar's Test P-Value : 0.6186         \n                                         \n            Sensitivity : 0.6859         \n            Specificity : 0.6864         \n         Pos Pred Value : 0.6935         \n         Neg Pred Value : 0.6787         \n             Prevalence : 0.5085         \n         Detection Rate : 0.3488         \n   Detection Prevalence : 0.5029         \n      Balanced Accuracy : 0.6861         \n                                         \n       'Positive' Class : 0              \n                                         \n\n\nTo understand the substantively important features, grouped by components, we checked importance metrics and the biplot.\n\nimportance(bag.democracy.pca,  type=1, scale = TRUE) %&gt;%\n  as.data.frame() %&gt;%\n  arrange(desc(abs(MeanDecreaseAccuracy))) %&gt;% head(20) %&gt;%\n  kbl() %&gt;%  kable_paper(\"hover\", full_width = FALSE) %&gt;%\n  scroll_box(width = \"100%\", height = \"200px\") \n\n\n\n\n\n\nMeanDecreaseAccuracy\n\n\n\n\nPC2\n135.05817\n\n\nPC3\n72.20042\n\n\nPC4\n47.44939\n\n\nPC1\n21.11336\n\n\nPC5\n18.64682\n\n\n\n\n\n\nggplot(data = NULL) +\n  geom_segment(data = as.data.frame(pca_result$rotation), \n               aes(x = 0, y = 0, xend = PC2, yend = PC3),\n               arrow = arrow(length = unit(0.2, \"cm\")), color = 'blue') +\n  geom_text(data = as.data.frame(pca_result$rotation), \n            aes(label = rownames(pca_result$rotation), x = PC2, y = PC3), \n            size = 5, check_overlap = TRUE) +  # Adjust the size parameter here\n  theme_minimal()+\n  labs(x = \"PC2\", y = \"PC3\")",
    "crumbs": [
      "Linguistic Analysis",
      "LIWC Random Forest"
    ]
  },
  {
    "objectID": "rmarkdown/liwc_randomforest.html#trial-3-excluding-wc-wps-and-period",
    "href": "rmarkdown/liwc_randomforest.html#trial-3-excluding-wc-wps-and-period",
    "title": "liwc_randomforest",
    "section": "Trial 3: excluding WC, WPS, and Period",
    "text": "Trial 3: excluding WC, WPS, and Period\nTo zero in on more meaningful features other than WPS, we left out some of the correlated features along with WPS. OOB estimate of error rate slightly increased around 0.5 percentage point(%p) after removing WC, WPS, and Period. Prediction accuracy against testN slightly dropped to 0.7409 accordingly.\n\nset.seed(7)\nsplit &lt;- rsample::initial_split(data, prop=0.7, strata=\"dd_democracy\")\ntrainN &lt;- rsample::training(split)\ntrainN$dd_democracy&lt;-factor(trainN$dd_democracy)\ntestN &lt;- rsample::testing(split)\n\ntrainN &lt;- trainN[, !(names(trainN) %in% c(\"ccode_iso\", \"year\", \"session\", \"dd_regime\", \"WC\", \"WPS\", \"Period\"))]\ntestN &lt;- testN[, !(names(testN) %in% c(\"ccode_iso\", \"year\", \"session\", \"dd_regime\", \"WC\", \"WPS\", \"Period\"))]\n\n# Remove rows with missing values\ntrainN &lt;- na.omit(trainN)\n\n# Fit random forest model after removing missing values\nbag.democracy3 &lt;- randomForest(dd_democracy ~ ., \n                               data = trainN, \n                               ntree = 500,\n                               mtry = ncol(trainN) - 1,\n                               importance = TRUE)\n\nvarImpPlot(bag.democracy3, sort=T, n.var= 25, main= \"Democracy vs. Non-democracy\", pch=16)\n\n\n\n\n\n\n\nRT.pred3 &lt;- predict(bag.democracy3, newdata=testN, type=\"class\")\n\nRT.evlau3 &lt;- caret::confusionMatrix(as.factor(testN$dd_democracy), \n                                   RT.pred3, \n                                   positive = \"1\",\n                                   dnn = c(\"Reference\",\"Prediction\"))\nRT.evlau3\n\nConfusion Matrix and Statistics\n\n         Prediction\nReference    0    1\n        0 1087  381\n        1  313 1115\n                                          \n               Accuracy : 0.7604          \n                 95% CI : (0.7444, 0.7758)\n    No Information Rate : 0.5166          \n    P-Value [Acc &gt; NIR] : &lt; 2e-16         \n                                          \n                  Kappa : 0.5209          \n                                          \n Mcnemar's Test P-Value : 0.01098         \n                                          \n            Sensitivity : 0.7453          \n            Specificity : 0.7764          \n         Pos Pred Value : 0.7808          \n         Neg Pred Value : 0.7405          \n             Prevalence : 0.5166          \n         Detection Rate : 0.3850          \n   Detection Prevalence : 0.4931          \n      Balanced Accuracy : 0.7609          \n                                          \n       'Positive' Class : 1               \n                                          \n\n# Importance matrix\nimportance(bag.democracy3, type=1, scale = TRUE) %&gt;%\n  as.data.frame() %&gt;%\n  arrange(desc(MeanDecreaseAccuracy)) %&gt;%head(20) %&gt;%\n  kbl() %&gt;%  kable_paper(\"hover\", full_width = FALSE) %&gt;%\n  scroll_box(width = \"100%\", height = \"400px\") \n\n\n\n\n\n\nMeanDecreaseAccuracy\n\n\n\n\nethnicity\n51.13591\n\n\npower\n33.46922\n\n\ni\n32.02684\n\n\nneed\n30.90368\n\n\nverb\n30.65794\n\n\nmale\n27.91114\n\n\nprep\n27.77320\n\n\ndet\n23.38925\n\n\nfocusfuture\n21.45934\n\n\nthey\n20.92268\n\n\ntime\n20.59665\n\n\naffiliation\n19.55701\n\n\narticle\n17.50262\n\n\nDic\n16.89642\n\n\nwe\n16.73911\n\n\npolite\n16.32449\n\n\nfemale\n16.15401\n\n\nPhysical\n16.04930\n\n\nauxverb\n16.04831\n\n\nemotion\n16.02271\n\n\n\n\n\n\n\nThere wasn’t a significant change in accuracy compared to Trial 1. We found one explanation from a chapter from Limitations of Interpretable Machine Learning Methods.\n\n\n\n\n\n\n“There is a drop in Leave-One-Covariate-Out(LOCO) Feature Importance of the two features the higher the correlation. However, in case of almost perfect multicollinearity, dropping the features that are correlated out of consideration to calculate the LOCO Feature Importance, the other feature can kind of”pick up” the effect on the target variable. As a consequence, there is no change in accuracy which means that there is only a small, up to no, increase in the error (parr?).”\n\n\n\n\nTrial 3.1) Subsetting aggregate-level features only\nWe suspected if the LIWC’s aggregate indices were correlated with their composite variables.\nAccuracy : 0.7132\n\nsubset&lt;-data%&gt;%\n  dplyr::select(Analytic, Clout, Authentic, Tone, BigWords, Linguistic, Dic, Drives,\n                Cognition, Affect, Culture, Lifestyle, Physical, Perception, Conversation,\n                AllPunc, dd_democracy)\n\nset.seed(4)\n\nsplit &lt;- rsample::initial_split(subset, prop=0.7, strata=\"dd_democracy\")\ntrainN &lt;- rsample::training(split)\ntrainN$dd_democracy&lt;-factor(trainN$dd_democracy)\ntestN &lt;- rsample::testing(split)\n\n# Remove rows with missing values\ntrainN &lt;- na.omit(trainN)\n\n# Fit random forest model after removing missing values\nbag.democracy3.1 &lt;- randomForest(dd_democracy ~ ., \n                               data = trainN, \n                               ntree = 500,\n                               mtry = ncol(trainN) - 1,\n                               importance = TRUE)\n\nvarImpPlot(bag.democracy3.1, sort=T, n.var= 15, main= \"Democracy vs. Non-democracy\", pch=16)\n\n\n\n\n\n\n\nbag.RT.pred3.1 &lt;- predict(bag.democracy3.1, newdata = testN) \n\nRT.pred3.1 &lt;- predict(bag.democracy3.1, newdata=testN, type=\"class\")\n\nRT.evlau3.1 &lt;- caret::confusionMatrix(as.factor(testN$dd_democracy), \n                                   RT.pred3.1, \n                                   positive = \"1\",\n                                   dnn = c(\"Reference\",\"Prediction\"))\nRT.evlau3.1\n\nConfusion Matrix and Statistics\n\n         Prediction\nReference   0   1\n        0 955 503\n        1 434 993\n                                          \n               Accuracy : 0.6752          \n                 95% CI : (0.6578, 0.6923)\n    No Information Rate : 0.5185          \n    P-Value [Acc &gt; NIR] : &lt; 2e-16         \n                                          \n                  Kappa : 0.3507          \n                                          \n Mcnemar's Test P-Value : 0.02632         \n                                          \n            Sensitivity : 0.6638          \n            Specificity : 0.6875          \n         Pos Pred Value : 0.6959          \n         Neg Pred Value : 0.6550          \n             Prevalence : 0.5185          \n         Detection Rate : 0.3442          \n   Detection Prevalence : 0.4946          \n      Balanced Accuracy : 0.6757          \n                                          \n       'Positive' Class : 1               \n                                          \n\n# Importance matrix\nimportance(bag.democracy3.1) %&gt;%\n  as.data.frame() %&gt;%\n  arrange(desc(abs(MeanDecreaseAccuracy))) %&gt;%head(20) %&gt;%\n  kbl() %&gt;%  kable_paper(\"hover\", full_width = FALSE) %&gt;%\n  scroll_box(width = \"100%\", height = \"400px\") \n\n\n\n\n\n\n0\n1\nMeanDecreaseAccuracy\nMeanDecreaseGini\n\n\n\n\nAnalytic\n40.865438\n40.5745666\n69.475826\n354.02036\n\n\nTone\n31.030152\n38.8144334\n49.865735\n294.86567\n\n\nDic\n14.952745\n37.0847678\n43.995731\n229.15114\n\n\nAffect\n28.986786\n15.3885397\n33.259720\n241.52373\n\n\nCulture\n27.213898\n16.0477721\n33.030883\n203.12302\n\n\nClout\n2.076986\n34.4868326\n33.008103\n226.76502\n\n\nAuthentic\n12.168968\n26.0004756\n31.905431\n214.44350\n\n\nLinguistic\n19.979601\n11.1680229\n29.746702\n185.47989\n\n\nBigWords\n14.040369\n16.4929244\n28.085091\n182.40524\n\n\nPhysical\n12.876732\n25.6306420\n27.995429\n222.85713\n\n\nCognition\n17.978734\n8.5972236\n25.942107\n185.94632\n\n\nAllPunc\n7.938512\n20.7900459\n21.466392\n212.65380\n\n\nDrives\n7.031147\n14.8450348\n19.890098\n174.94870\n\n\nLifestyle\n16.039245\n4.8331877\n17.043656\n204.61453\n\n\nPerception\n14.559775\n0.2686298\n11.574761\n181.72314\n\n\nConversation\n4.495709\n-0.6776919\n2.867841\n64.91052\n\n\n\n\n\n\n\n\n\nTrial 3.2) Subsetting lower-level features only\nWe also tried the opposite of Trial 3.1 by removing aggregate indices. There wasn’t a significant change in the overall accuracy.\nAccuracy : 0.7444\n\nsubset2&lt;-data[, !names(data) %in%\n                c(\"WC\", \"WPS\", \"BigWords\",\"Tone\", \"Analytic\", \"Clout\", \"Authentic\", \"Dic\", \"Linguistic\", \"Drives\", \"Cognition\", \"Affect\", \"Culture\", \"Lifestyle\", \"Physical\", \"Perception\", \"Conversation\", \"AllPunc\", \"function_features\", \"ppron\", \"emotion\", \"socbehav\", \"socrefs\", \"Culture\", \"Lifestyle\", \"Physical\", \"States\", \"Motives\", \"Perception\", \"Conversational\", \"Social\", \"Period\")]\n\nsubset2&lt;-subset2[, c(6:99)]\n\nset.seed(4)\n\nsplit &lt;- rsample::initial_split(subset2, prop=0.7, strata=\"dd_democracy\")\ntrainN &lt;- rsample::training(split)\ntrainN$dd_democracy&lt;-factor(trainN$dd_democracy)\ntestN &lt;- rsample::testing(split)\n\n# Remove rows with missing values\ntrainN &lt;- na.omit(trainN)\n\n# Fit random forest model after removing missing values\nbag.democracy3.2 &lt;- randomForest(dd_democracy ~ ., \n                               data = trainN, \n                               ntree = 500,\n                               mtry = ncol(trainN) - 1,\n                               importance = TRUE)\n\nvarImpPlot(bag.democracy3.2, sort=T, n.var= 25, main= \"Democracy vs. Non-democracy\", pch=16)\n\n\n\n\n\n\n\nbag.RT.pred3.2 &lt;- predict(bag.democracy3.2, newdata = testN) \n\nRT.pred3.2 &lt;- predict(bag.democracy3.2, newdata=testN, type=\"class\")\n\nRT.evlau3.2 &lt;- caret::confusionMatrix(as.factor(testN$dd_democracy), \n                                   RT.pred3.2, \n                                   positive = \"1\",\n                                   dnn = c(\"Reference\",\"Prediction\"))\nRT.evlau3.2\n\nConfusion Matrix and Statistics\n\n         Prediction\nReference    0    1\n        0 1076  382\n        1  353 1074\n                                          \n               Accuracy : 0.7452          \n                 95% CI : (0.7289, 0.7611)\n    No Information Rate : 0.5047          \n    P-Value [Acc &gt; NIR] : &lt;2e-16          \n                                          \n                  Kappa : 0.4905          \n                                          \n Mcnemar's Test P-Value : 0.3017          \n                                          \n            Sensitivity : 0.7376          \n            Specificity : 0.7530          \n         Pos Pred Value : 0.7526          \n         Neg Pred Value : 0.7380          \n             Prevalence : 0.5047          \n         Detection Rate : 0.3723          \n   Detection Prevalence : 0.4946          \n      Balanced Accuracy : 0.7453          \n                                          \n       'Positive' Class : 1               \n                                          \n\n# Importance matrix\nimportance(bag.democracy3.2) %&gt;%\n  as.data.frame() %&gt;%\n  arrange(desc(abs(MeanDecreaseAccuracy)))%&gt;%head(20) %&gt;%\n  kbl() %&gt;%  kable_paper(\"hover\", full_width = FALSE) %&gt;%\n  scroll_box(width = \"100%\", height = \"400px\") \n\n\n\n\n\n\n0\n1\nMeanDecreaseAccuracy\nMeanDecreaseGini\n\n\n\n\nethnicity\n40.496721\n31.074208\n50.09892\n221.37936\n\n\nneed\n15.734335\n33.871823\n36.28270\n124.83331\n\n\nverb\n31.315470\n13.138998\n34.59106\n97.08215\n\n\ni\n23.235183\n22.270993\n30.93661\n89.70045\n\n\nprep\n16.968264\n23.774738\n28.87460\n100.98803\n\n\nmale\n19.759043\n16.576991\n25.58376\n87.51931\n\n\npower\n18.891030\n17.563230\n25.32166\n87.31213\n\n\ntime\n20.056701\n14.606792\n24.44933\n72.75779\n\n\naffiliation\n19.047576\n10.563920\n24.26797\n55.20462\n\n\ndet\n18.228342\n11.364488\n21.72084\n64.99771\n\n\nfocusfuture\n13.306782\n15.162868\n20.25781\n57.26593\n\n\nwe\n13.938593\n17.412296\n19.91901\n89.74543\n\n\ntone_neg\n14.538008\n9.963408\n18.85690\n40.67337\n\n\npolite\n13.026583\n11.498368\n18.43403\n46.60988\n\n\nthey\n13.789092\n10.871015\n18.05035\n55.15415\n\n\nauxverb\n12.749960\n8.589462\n17.78425\n30.48857\n\n\nmoral\n17.453997\n7.680520\n17.67750\n56.75672\n\n\narticle\n9.150537\n11.787643\n16.66485\n45.86875\n\n\nfocuspresent\n6.011927\n13.206392\n16.21394\n30.35236\n\n\nallure\n10.644039\n8.607002\n15.72731\n31.95471\n\n\n\n\n\n\n\nRandom forest models did not show a better performance than logistic regression. We attribute this marginal performance to the fact that binary outcome is balanced. Previous studies have merited random forests to study rare events ((Muchlinski2016?), (Wang2019?)).",
    "crumbs": [
      "Linguistic Analysis",
      "LIWC Random Forest"
    ]
  },
  {
    "objectID": "rmarkdown/liwc_randomforest.html#trial-4-including-wc-wps-period-and-language-feature",
    "href": "rmarkdown/liwc_randomforest.html#trial-4-including-wc-wps-period-and-language-feature",
    "title": "liwc_randomforest",
    "section": "Trial 4 Including WC, WPS, Period and Language feature",
    "text": "Trial 4 Including WC, WPS, Period and Language feature\n\nset.seed(9)\nsplit &lt;- rsample::initial_split(lang_data, prop=0.7, strata=\"dd_democracy\")\ntrainN &lt;- rsample::training(split)\ntrainN$dd_democracy&lt;-factor(trainN$dd_democracy)\ntestN &lt;- rsample::testing(split)\n\n# Remove identifier variables. dd_regime is a 6-fold classification that is more comprehensive than dd_democracy.\ntrainN &lt;- trainN[, !(names(trainN) %in% c(\"ccode_iso\", \"year\", \"session\", \"dd_regime\"))]\ntestN &lt;- testN[, !(names(testN) %in% c(\"ccode_iso\", \"year\", \"session\", \"dd_regime\"))]\n\n# Remove rows with missing values\ntrainN &lt;- na.omit(trainN)\n\n# Fit random forest model\nbag.democracy4 &lt;- randomForest(dd_democracy ~ ., \n                               data = trainN, \n                               ntree = 500,\n                               mtry = ncol(trainN) - 1,\n                               importance = TRUE)\n\nbag.RT.pred4 &lt;- predict(bag.democracy4, newdata = testN) \nRT.pred4 &lt;- predict(bag.democracy4, newdata=testN, type=\"class\")\nRT.evlau4 &lt;- caret::confusionMatrix(as.factor(testN$dd_democracy), \n                                   RT.pred4, \n                                   positive = \"1\",\n                                   dnn = c(\"Reference\",\"Prediction\"))\nRT.evlau4\n\nConfusion Matrix and Statistics\n\n         Prediction\nReference    0    1\n        0 1112  350\n        1  337 1084\n                                          \n               Accuracy : 0.7617          \n                 95% CI : (0.7457, 0.7772)\n    No Information Rate : 0.5026          \n    P-Value [Acc &gt; NIR] : &lt;2e-16          \n                                          \n                  Kappa : 0.5234          \n                                          \n Mcnemar's Test P-Value : 0.6471          \n                                          \n            Sensitivity : 0.7559          \n            Specificity : 0.7674          \n         Pos Pred Value : 0.7628          \n         Neg Pred Value : 0.7606          \n             Prevalence : 0.4974          \n         Detection Rate : 0.3760          \n   Detection Prevalence : 0.4929          \n      Balanced Accuracy : 0.7617          \n                                          \n       'Positive' Class : 1               \n                                          \n\n# setting type to 1 selects Mean Accuracy Decrease, not Gini Coefficient. \nimportance(bag.democracy4,  type=1, scale = TRUE) %&gt;%\n  as.data.frame() %&gt;%\n  arrange(desc(abs(MeanDecreaseAccuracy))) %&gt;%head(20) %&gt;%\n  kbl() %&gt;%  kable_paper(\"hover\", full_width = FALSE) %&gt;%\n  scroll_box(width = \"100%\", height = \"400px\") \n\n\n\n\n\n\nMeanDecreaseAccuracy\n\n\n\n\nethnicity\n57.85337\n\n\nPeriod\n48.33889\n\n\nneed\n36.14936\n\n\ni\n31.42236\n\n\nWPS\n29.88887\n\n\npower\n28.01390\n\n\nmale\n27.68903\n\n\nthey\n23.98209\n\n\nmoral\n23.20073\n\n\nverb\n20.61054\n\n\nfocusfuture\n20.20344\n\n\nAuthentic\n18.01747\n\n\nmoney\n17.53209\n\n\nemotion\n17.42359\n\n\ntone_neg\n16.48298\n\n\ntime\n16.47235\n\n\ndiscrep\n16.24091\n\n\ndet\n15.86645\n\n\narticle\n15.28797\n\n\nAffect\n15.26143\n\n\n\n\n\n\nvarImpPlot(bag.democracy4, type=1, scale = TRUE, sort=T, n.var= 25, main= \"Democracy vs. Non-democracy\", pch=16)",
    "crumbs": [
      "Linguistic Analysis",
      "LIWC Random Forest"
    ]
  }
]