[
  {
    "objectID": "jupyter_notebook/functions_for_bert.html",
    "href": "jupyter_notebook/functions_for_bert.html",
    "title": "BERT Functions",
    "section": "",
    "text": "BERT Functions\nI define two functions to run Bert models. First part processes a single text document into a format that is recognizable by BERT. The second part uses the tokenized text to generate embedding values using pre-trained BERT models.\n\nfrom transformers import BertModel, BertTokenizer, AutoTokenizer\nimport numpy as np\nimport streamlit as st\nimport re\nimport pandas as pd\nfrom datetime import datetime\nimport nltk\nimport torch\n\n\nmodel = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\ntokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n\n\n#input is \"light.csv\" which does not include stop words. \ndf = pd.read_csv('../../../data/processed/paragraph.csv')\n# Filter\ntimestamps = df.year.to_list()\ntexts = df.text.to_list()\ntext = texts[1]\n\n\ndf.head(1)\n\n\n\n\n\n\n\n\nUnnamed: 0\nccode_iso\nsession\nyear\nparagraph_index\ntext\n\n\n\n\n0\n1\nAFG\n7\n1952\n1\nI consider it a great honour and privilege to ...\n\n\n\n\n\n\n\n\nprint(type(text))\n\n&lt;class 'str'&gt;\n\n\n\n\nDefine functions\n\ndef bert_preprocess(text):\n    \"\"\"\n    Preprocesses a document into a BERT-recognizable format \n    Input: text in a string format\n    output: three objects ready to be used for Bert modeling \n        marked_text (list)\n        indexed_tokens(list)\n        attention_mask(list)\n    \n    \"\"\"\n    # Tokenize the text\n    tokenized_text = tokenizer.tokenize(text)\n    truncate_length = len(tokenized_text) - 512 + 2  # +2 to account for [CLS] and [SEP]\n    \n    # Truncate the beginning and end of the text\n    truncated_text = tokenized_text[truncate_length//2 : -truncate_length//2]\n    \n    # Add padding\n    \n    # Add special tokens [CLS] and [SEP], convert tokens to ids, and create attention mask\n    marked_text = [\"[CLS] \"] + truncated_text + [\" [SEP]\"]\n    indexed_tokens = tokenizer.convert_tokens_to_ids(marked_text)\n    attention_mask = [1] * len(indexed_tokens)\n\n    # Pad sequences to max_seq_length\n    if len(indexed_tokens) &lt; 512:\n        indexed_tokens.append(0)\n        attention_mask.append(0)\n    \n    return marked_text, indexed_tokens, attention_mask\n\n\nmarked_text, indexed_tokens, attention_mask = bert_preprocess(text)\n\n\nhelp(get_bert_embeddings)\n\nHelp on function get_bert_embeddings in module __main__:\n\nget_bert_embeddings(marked_text, indexed_tokens, attention_mask)\n    input: processed text\n    output: dataframe of embedding weights for each token \n        ex) dimension of 512*768 where row represents token, column represents bert features\n\n\n\n\ndef get_bert_embeddings(marked_text, indexed_tokens, attention_mask):\n    \"\"\"\n    Generates embedding values for tokenized text \n    input: processed text, indexed_tokens and attention mask (all in list format)\n    output: dataframe of embedding weights for each token \n        ex) dimension of 512*768 where row represents token, column represents bert features\n    \n    \"\"\"\n    # Convert lists to PyTorch tensors\n    tokens_tensors = torch.tensor([indexed_tokens])\n    attention_masks = torch.tensor([attention_mask])\n    \n    with torch.no_grad():\n        #Run the embedding\n        outputs = model(input_ids=tokens_tensors.view(-1, tokens_tensors.size(-1)), \n                        attention_mask=attention_masks.view(-1, attention_masks.size(-1)))\n\n        # Extract the hidden states \n        hidden_states = outputs[2][0].squeeze().numpy()\n        \n        # Convert to data frame\n        pd_words = pd.Series(marked_text, name='term')\n        df_outputs = pd.DataFrame(hidden_states)\n        df_outputs['term'] = pd_words\n        \n        # Move 'term' column to the first position\n        df_outputs = df_outputs[['term'] + [col for col in df_outputs.columns if col != 'term']]\n        \n        # Remove duplicate tokens by averaging them out\n        df_outputs_embedding = df_outputs.groupby(['term']).mean()\n    return df_outputs_embedding\n\n\nget_bert_embeddings(marked_text, indexed_tokens, attention_mask)\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n...\n758\n759\n760\n761\n762\n763\n764\n765\n766\n767\n\n\nterm\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[SEP]\n-0.599731\n-0.287527\n0.995737\n-0.067600\n-0.116662\n-0.319243\n-0.035646\n-0.550722\n-0.154269\n0.226906\n...\n0.433558\n0.360281\n0.753348\n-1.155800\n0.198939\n0.126193\n0.058285\n0.035218\n-0.225301\n-0.376395\n\n\n##s\n-0.082928\n0.064610\n0.062934\n1.201868\n0.416490\n-0.351008\n-0.419693\n0.793464\n-0.682201\n-0.435875\n...\n-1.640653\n-0.082774\n1.440754\n0.477181\n0.555801\n0.517778\n0.029644\n0.167330\n-0.804072\n1.100950\n\n\n,\n0.238827\n-0.499530\n-0.229385\n-0.420359\n0.382101\n-0.133325\n-0.423249\n-0.133761\n0.079275\n-0.810453\n...\n-0.476354\n0.310680\n-0.071447\n-0.350534\n-0.166876\n-0.152760\n0.157087\n0.182910\n-0.305537\n0.119838\n\n\n-\n0.211686\n-0.337158\n-0.282966\n-0.379349\n0.213550\n-0.254544\n-0.361127\n-0.094978\n0.072562\n-0.825429\n...\n-0.457777\n0.271165\n0.238502\n-0.122299\n-0.090638\n-0.070707\n0.017792\n-0.049120\n-0.269647\n0.226714\n\n\n.\n0.117108\n-0.388444\n-0.088623\n0.064858\n0.523230\n-0.428734\n-0.267266\n-0.420127\n0.190312\n-0.766927\n...\n-0.490892\n0.354983\n-0.355035\n-0.418002\n0.253672\n0.086620\n0.108094\n-0.150912\n-0.198612\n0.161442\n\n\nIn\n1.179606\n0.055646\n0.182922\n1.080442\n0.191964\n-0.443555\n-0.347383\n0.757875\n-0.356111\n-1.096234\n...\n0.154227\n0.468894\n0.522242\n-0.500889\n0.947098\n1.150616\n-0.767531\n-0.148597\n-0.223548\n0.134304\n\n\nNations\n0.006905\n-0.580956\n0.575177\n-1.220215\n0.371888\n-0.279317\n0.700901\n-0.903072\n0.631587\n-0.739470\n...\n0.495864\n0.132003\n0.067810\n0.293461\n0.424441\n0.552663\n0.318386\n-0.620372\n-0.583365\n0.048380\n\n\nUnited\n-0.077556\n-0.105724\n1.057649\n-0.423865\n0.314821\n-0.185792\n-0.714371\n-0.607652\n-0.070977\n0.103325\n...\n-0.704180\n-1.008595\n-0.426895\n-0.018947\n0.567454\n0.483050\n-0.180623\n-0.287286\n-0.556010\n0.511452\n\n\n[CLS]\n-0.118897\n-0.518255\n0.159338\n-0.461482\n-0.003488\n-0.453042\n-0.212884\n-0.229699\n-0.063944\n-0.421272\n...\n0.242429\n0.009379\n0.467546\n-0.957577\n0.114305\n-0.369990\n0.035248\n0.089144\n-0.146707\n-0.127492\n\n\naccomplish\n-0.085958\n0.289747\n0.502433\n-0.699373\n-0.112547\n0.115439\n1.011047\n-0.570650\n-0.124616\n-0.372738\n...\n-1.153663\n-0.272904\n0.580479\n0.201596\n-0.194586\n-0.872371\n-0.358961\n0.039148\n0.101910\n-0.169740\n\n\nacts\n-0.178121\n0.666130\n0.413916\n0.099232\n-1.034455\n-0.040334\n-0.048890\n-0.098929\n-0.145200\n0.480938\n...\n-1.342113\n0.323047\n0.763901\n-1.770176\n0.986050\n-0.538208\n-0.744755\n0.057135\n-0.445161\n-0.774442\n\n\naid\n-0.427848\n0.147286\n0.013369\n0.471762\n0.168422\n0.895970\n0.872069\n1.716045\n0.837368\n0.494484\n...\n-0.787848\n-0.445969\n0.358512\n0.965379\n0.365942\n0.054571\n-0.555102\n-0.860554\n-0.171662\n-1.067538\n\n\naims\n1.024410\n-0.256186\n-0.053223\n0.638275\n-0.077131\n-0.311400\n-0.234701\n-0.026557\n0.915609\n-0.596711\n...\n-0.522890\n1.130598\n-0.809434\n-0.718155\n-0.150897\n-0.814818\n-0.124106\n-1.064612\n-0.574141\n-0.703143\n\n\nall\n-0.002165\n0.033546\n0.609011\n-0.239792\n-0.932221\n-1.037787\n0.136487\n-0.882456\n0.342895\n-0.798731\n...\n0.239174\n-0.662943\n0.205603\n0.161089\n-0.176249\n-0.105027\n0.036648\n0.276853\n0.527183\n-0.216994\n\n\nand\n0.685023\n0.240559\n-0.555069\n-0.011118\n0.690408\n0.024725\n-0.583992\n-0.181338\n-0.816213\n0.622959\n...\n-0.739703\n0.255513\n0.252658\n-0.401268\n0.020371\n0.737326\n0.633780\n-0.291272\n-0.483794\n-0.894787\n\n\nareas\n0.720950\n-0.746471\n0.160797\n-0.725814\n1.154829\n-0.101660\n-0.124824\n-0.682128\n-0.094830\n0.434859\n...\n-0.126514\n0.163580\n0.774643\n0.072612\n0.070189\n0.888373\n0.193730\n0.033260\n0.078655\n0.414108\n\n\nas\n-0.917634\n0.064711\n-0.368008\n0.218496\n1.246304\n-0.059035\n-1.098246\n0.450588\n-1.106012\n-1.061205\n...\n-0.457125\n-0.102798\n0.220228\n-0.558394\n-0.207785\n0.430128\n-1.262651\n0.324153\n-0.113458\n0.350910\n\n\nassistance\n-0.678422\n0.172338\n0.265142\n0.258749\n-0.105260\n-0.331368\n-0.350325\n0.263004\n-0.668104\n-0.555148\n...\n-0.475693\n0.409995\n0.346237\n0.555776\n0.440133\n-0.523475\n0.134694\n0.275381\n-0.253818\n0.210988\n\n\ncoincide\n-0.170578\n-0.268886\n-0.115447\n-0.694355\n0.483255\n-0.280104\n-0.640158\n0.034518\n-0.001312\n0.433044\n...\n-0.380226\n-0.208592\n-0.748574\n-0.197001\n0.404674\n-0.318124\n-0.521167\n0.667394\n-0.002012\n1.150480\n\n\ncollective\n0.151802\n0.762978\n-0.005754\n0.526812\n0.764982\n0.812513\n-0.570761\n-0.021987\n-1.306559\n-0.586478\n...\n-0.281096\n-1.654515\n-0.409773\n-0.740668\n0.533563\n-0.904656\n0.133838\n-0.766242\n0.390741\n-0.584280\n\n\nconscience\n0.158133\n-0.274482\n-0.492211\n-0.170320\n0.652437\n-0.445447\n0.168138\n-0.694122\n-0.364806\n-1.202534\n...\n-0.850401\n-0.854405\n0.362089\n0.396198\n0.172970\n-0.543768\n-1.138113\n0.421941\n1.142612\n1.083518\n\n\ncultural\n-1.082594\n-0.155604\n0.376953\n-0.332056\n-0.495655\n-1.082139\n0.782310\n-0.506714\n0.033708\n0.338000\n...\n0.613047\n0.565934\n-1.216563\n0.057687\n-0.932211\n-0.200133\n-0.734939\n0.179817\n-0.215364\n-0.216755\n\n\ndeveloped\n-0.195352\n0.150783\n0.080199\n-0.162700\n0.360601\n0.163544\n-0.581970\n0.052141\n0.185778\n-0.233883\n...\n-1.082397\n0.500910\n0.256611\n-0.607807\n-0.145842\n0.529889\n0.446537\n0.195365\n-0.643610\n-0.130024\n\n\ndevelopment\n0.298387\n0.496667\n-0.434238\n0.093009\n-1.293615\n0.209092\n-0.368899\n0.919280\n0.138753\n-0.650476\n...\n-0.645376\n1.387810\n0.642955\n0.327757\n-0.424770\n-0.255853\n0.202628\n0.501966\n-0.376638\n-0.267928\n\n\nduties\n-0.651811\n-0.242606\n0.490167\n-0.137662\n0.505857\n-0.002086\n1.298450\n0.396070\n1.254041\n-0.024695\n...\n0.302751\n-0.295479\n-0.401752\n-0.347428\n-0.645984\n-0.070883\n-1.304861\n-0.363276\n-0.646936\n-1.105535\n\n\neconomic\n0.327582\n0.387518\n-0.703620\n0.579996\n0.298967\n0.924665\n0.373069\n-0.637522\n0.973225\n0.572886\n...\n0.214301\n0.598506\n0.876789\n0.094422\n0.311424\n-0.415416\n-0.762125\n0.453513\n0.134451\n-0.050874\n\n\nends\n-0.546396\n-0.359361\n0.212410\n0.277001\n0.106774\n0.592411\n-0.247585\n-0.792451\n-0.884770\n0.545342\n...\n-0.271307\n-0.330248\n0.591369\n0.783333\n1.241485\n-0.296724\n0.078918\n0.412234\n0.387542\n0.192228\n\n\nfor\n-0.253029\n-0.404490\n-0.261728\n0.038780\n0.154741\n0.588547\n-1.170278\n-0.019293\n0.076067\n-1.264595\n...\n-0.787064\n-0.461386\n-0.638114\n-0.482141\n-0.344258\n-0.054569\n0.378593\n-0.465482\n-0.611659\n0.433159\n\n\nforward\n-0.207178\n0.236094\n-0.957996\n-0.357690\n0.334218\n-0.413327\n-0.956618\n-0.011278\n-0.408511\n-0.037497\n...\n-1.214147\n-0.303270\n0.135196\n0.555519\n0.122476\n0.240908\n-0.056521\n0.050130\n-0.211742\n0.378766\n\n\nguide\n-1.178150\n0.731618\n-0.593804\n0.415418\n1.651968\n-0.073628\n0.057820\n-0.396742\n-0.996873\n0.429075\n...\n0.614620\n-0.451440\n-1.288784\n-0.389848\n0.017629\n-0.483427\n-0.484336\n0.149367\n0.323914\n-1.239273\n\n\nhappily\n-0.552708\n0.431273\n-0.276702\n-0.626600\n1.248792\n-0.940124\n-0.367457\n-0.736995\n0.878078\n0.467198\n...\n0.395383\n-0.414090\n-0.134464\n-0.228733\n-0.090979\n0.121471\n0.091699\n-0.064050\n-0.222706\n0.177931\n\n\nin\n-0.825479\n-1.051559\n0.758063\n0.673075\n0.240419\n0.115155\n-0.920780\n0.137270\n1.564308\n-0.329897\n...\n-0.943635\n0.426585\n-0.385542\n-0.110009\n-1.135049\n-0.032381\n-0.399695\n0.427312\n0.118642\n0.217453\n\n\ninterest\n0.087404\n-0.640190\n-0.453728\n-0.850574\n-0.157392\n-0.533750\n0.637173\n-0.608730\n-0.633894\n0.933405\n...\n0.899409\n1.313719\n0.314493\n0.620090\n-0.622023\n0.070112\n-1.821788\n-0.131984\n-0.347964\n-0.195112\n\n\nits\n-0.217026\n0.894963\n-0.105397\n-0.401083\n-0.738265\n-0.480244\n-0.346089\n-0.352199\n1.088866\n-0.914263\n...\n-0.941486\n0.522719\n0.290851\n0.399336\n-0.462239\n-0.174071\n-0.092375\n0.078811\n0.854677\n-0.169473\n\n\nmoral\n0.619293\n0.499217\n0.249499\n-0.751159\n0.466876\n-0.062412\n-0.184458\n-0.660417\n0.652479\n-1.639679\n...\n-0.382880\n0.017941\n0.048614\n-0.491065\n0.557178\n1.361697\n0.181574\n-0.451610\n0.301997\n-0.267717\n\n\nmust\n-0.157701\n0.589252\n0.273769\n0.857760\n0.567033\n0.108004\n-1.062661\n-1.089537\n-0.240025\n-0.304565\n...\n0.769697\n-0.041358\n-0.410516\n0.544890\n-0.466517\n-1.122368\n0.304115\n0.411068\n0.301097\n0.433811\n\n\nobjectives\n-0.875071\n0.340940\n-0.162661\n0.404240\n0.205024\n-0.591867\n0.305278\n0.519380\n0.144190\n-0.521769\n...\n-0.237458\n-0.047777\n0.328942\n-1.136463\n0.665098\n0.725972\n0.299084\n-0.483213\n-0.158996\n-0.867711\n\n\nof\n-0.327949\n-0.544503\n-0.092067\n-1.195621\n0.039030\n-1.281222\n-0.414859\n0.070955\n-0.199553\n-1.428178\n...\n-0.035053\n0.183135\n0.080120\n-0.322540\n-0.468436\n0.623744\n0.315495\n0.084182\n0.077692\n0.203555\n\n\norder\n-0.067636\n-1.451491\n0.146754\n-0.419711\n0.023377\n-0.810850\n-0.734983\n-0.020393\n-0.560763\n0.204884\n...\n-0.109579\n0.385012\n-0.002484\n-0.126181\n-0.709134\n0.109215\n1.085052\n0.454821\n0.048261\n0.162490\n\n\npeoples\n-0.221793\n-0.247048\n-0.341812\n0.627216\n1.513762\n-0.743124\n-0.456467\n-1.155934\n0.653813\n-0.737646\n...\n0.766392\n-0.728573\n-0.624886\n0.481552\n0.536343\n-0.368652\n0.979576\n0.851340\n-0.597788\n0.720032\n\n\nphases\n-0.914526\n0.031760\n-0.057205\n-0.529099\n0.335894\n-0.689959\n-0.019860\n0.153372\n0.436006\n-0.038952\n...\n-0.668004\n0.173632\n-0.416013\n0.557431\n-0.360914\n-0.490024\n-0.671597\n0.189420\n0.384801\n-0.988437\n\n\npractical\n0.497227\n0.944226\n-0.767903\n-0.117738\n-0.066879\n0.199990\n0.709391\n0.005245\n0.146205\n-0.415131\n...\n0.073728\n-0.115236\n-0.118528\n0.329659\n-0.090454\n0.459422\n-1.281357\n-0.437196\n-0.268200\n0.232447\n\n\npush\n-0.184951\n0.711796\n0.721361\n-0.777537\n0.321118\n0.102113\n-0.503164\n0.589479\n1.586533\n0.306067\n...\n-0.007689\n-0.354350\n-0.783757\n0.479150\n0.510954\n0.808599\n-1.763679\n1.179172\n-0.048447\n-0.237922\n\n\nrealization\n0.680622\n0.343941\n0.359005\n-0.110402\n0.846315\n-1.126212\n0.410226\n-0.506499\n-0.529498\n-1.226504\n...\n0.534820\n0.661075\n0.972976\n0.132633\n0.495696\n-0.392315\n0.310346\n0.728478\n-0.813280\n0.737264\n\n\nself\n0.257648\n0.058829\n-0.417947\n0.250967\n0.102127\n-0.601216\n0.257821\n-0.101740\n-0.363018\n-0.105056\n...\n1.385324\n-0.540304\n-0.544518\n0.790096\n0.714771\n0.062684\n-0.041591\n0.477603\n0.045479\n0.348599\n\n\nsocial\n0.001411\n0.083508\n-0.384193\n0.038151\n0.828193\n-0.295133\n-0.131154\n-0.310905\n-0.194347\n-0.355901\n...\n-0.688219\n-0.004625\n-0.023948\n0.265741\n-0.029004\n-0.086471\n0.103009\n1.135597\n-0.636987\n-0.338693\n\n\nthe\n1.259149\n-0.390939\n-0.574276\n-0.651518\n0.975174\n-0.346215\n-0.203062\n0.069047\n-0.972633\n-0.484539\n...\n-0.177573\n0.605176\n-0.330061\n-0.963901\n0.492528\n0.279568\n-0.408966\n0.528585\n-1.137273\n0.370578\n\n\ntheir\n-0.141068\n-0.385690\n-0.610704\n-0.631536\n0.036775\n-0.008408\n0.058548\n0.447865\n-0.403555\n-0.706317\n...\n-0.900095\n0.260387\n-0.259527\n-0.011186\n0.366235\n-0.750171\n0.071075\n0.316691\n0.273126\n-1.098873\n\n\nthese\n-0.867060\n-0.423800\n-0.462822\n0.031337\n-0.921427\n0.606853\n-0.407772\n0.609299\n-0.070913\n0.411936\n...\n-0.375234\n-0.172975\n0.506652\n-0.142546\n0.120540\n-1.079829\n-0.097479\n-0.512669\n-0.959007\n0.081844\n\n\nthrough\n-0.806322\n0.435404\n-0.860480\n-0.352367\n-0.911619\n0.371939\n-0.302082\n-0.138660\n-0.286805\n0.741813\n...\n0.205986\n0.712598\n-0.843359\n0.651225\n0.107572\n0.096148\n-0.935132\n0.180383\n0.055736\n-0.279496\n\n\nto\n-0.467868\n-0.124578\n-0.321987\n0.056667\n-0.164021\n1.174730\n-0.633803\n0.867373\n-1.580327\n-0.784350\n...\n-0.367765\n-0.081297\n0.588999\n0.236422\n0.058517\n-0.139931\n0.747637\n-0.138854\n-0.143276\n-0.009610\n\n\nunder\n0.687285\n-0.849716\n0.345514\n-0.015210\n-0.001491\n0.095282\n-0.069619\n-0.023330\n-0.572866\n-1.167167\n...\n-0.920049\n0.214902\n0.161194\n-0.373119\n-0.300902\n-0.546927\n0.374067\n0.461742\n0.977844\n-0.106500\n\n\nwe\n0.493856\n-0.277951\n1.282449\n-0.818842\n-0.315630\n1.576497\n-0.768214\n-1.161283\n-1.137017\n0.787399\n...\n0.117417\n-0.324164\n-0.510348\n0.801145\n-0.253922\n0.568123\n0.851370\n-0.558899\n-0.064633\n-0.407102\n\n\nwhich\n-0.368462\n-0.361856\n0.409696\n0.587431\n0.708897\n0.291840\n-0.362036\n-0.530712\n-0.053614\n-0.711788\n...\n-1.084328\n-0.832080\n0.269114\n0.851772\n-0.942639\n-0.081171\n-1.273354\n-0.796438\n-0.260538\n0.355565\n\n\nwith\n-0.388580\n-0.219293\n-0.652044\n-1.386387\n-0.089682\n-0.403928\n-1.394354\n0.763693\n-0.379815\n-0.662670\n...\n-0.599527\n-0.076366\n0.786938\n-1.619844\n-0.512546\n-0.580194\n-0.000503\n-0.181073\n-1.548287\n0.417536\n\n\nworld\n0.737164\n-0.141081\n0.328124\n0.615530\n0.357371\n0.274039\n-0.563317\n0.040565\n-0.111780\n0.075683\n...\n-0.404257\n0.543159\n0.008046\n0.476506\n0.046138\n-0.633671\n-0.073570\n-0.446745\n-0.119588\n-0.238425\n\n\n\n\n56 rows × 768 columns",
    "crumbs": [
      "BERT",
      "BERT Functions"
    ]
  },
  {
    "objectID": "rmarkdown/moving_lda_0219.html",
    "href": "rmarkdown/moving_lda_0219.html",
    "title": "Moving LDA Version - Inverse Weighted",
    "section": "",
    "text": "This study analyzes the global agenda of the United Nations General Debate (UNGD) and shows temporal development of the topics. Substantively, UNGDC reflects in change of agendas when exogenous shocks take place. The issue of connecting time-series evolution of topic has been addressed by others. Rieger et al. (rieger2021?) introduces a sequential approach to LDA with the accompanying package, and Greene at al. (greene2017?) uses non-negative matrix factorization to analyze the European Parliament Debate Corpus.\nThere are two main challenges to address cross-section time-series text dataset. First, same topic is represented with different sets of terms over time, given the social context and norms around a specific construct. Second, given changes around the topic representation, it requires theory-based post-labeling to",
    "crumbs": [
      "Topic Modeling",
      "Moving LDA"
    ]
  },
  {
    "objectID": "rmarkdown/moving_lda_0219.html#introduction",
    "href": "rmarkdown/moving_lda_0219.html#introduction",
    "title": "Moving LDA Version - Inverse Weighted",
    "section": "",
    "text": "This study analyzes the global agenda of the United Nations General Debate (UNGD) and shows temporal development of the topics. Substantively, UNGDC reflects in change of agendas when exogenous shocks take place. The issue of connecting time-series evolution of topic has been addressed by others. Rieger et al. (rieger2021?) introduces a sequential approach to LDA with the accompanying package, and Greene at al. (greene2017?) uses non-negative matrix factorization to analyze the European Parliament Debate Corpus.\nThere are two main challenges to address cross-section time-series text dataset. First, same topic is represented with different sets of terms over time, given the social context and norms around a specific construct. Second, given changes around the topic representation, it requires theory-based post-labeling to",
    "crumbs": [
      "Topic Modeling",
      "Moving LDA"
    ]
  },
  {
    "objectID": "rmarkdown/moving_lda_0219.html#goal",
    "href": "rmarkdown/moving_lda_0219.html#goal",
    "title": "Moving LDA Version - Inverse Weighted",
    "section": "Goal",
    "text": "Goal\nIn order to generate LDA estimations across time more smoothly, this script changes the UNGDC_topic_modeling_updated.qmdand experiments with different moving window. Just like the other scripts, I use cleaned.csv file. It has four columns: “ccode_iso”, “session”, “year”, and finally “text”.",
    "crumbs": [
      "Topic Modeling",
      "Moving LDA"
    ]
  },
  {
    "objectID": "rmarkdown/moving_lda_0219.html#experiment-logs",
    "href": "rmarkdown/moving_lda_0219.html#experiment-logs",
    "title": "Moving LDA Version - Inverse Weighted",
    "section": "Experiment logs",
    "text": "Experiment logs\nSize of the window, and overlapping interval can influence the level of correlation between vectors. The goal of experiments with changing parameters is to capture general themes that discuss beyond a region-specific topic. Furthermore, I overcome the problem of raw term frequency that treats all terms as equally important. Inverse document frequency (idf) of a term is a weight, defined as logged value of the total number of documents in a collection denominated by the number of documents that contain the term. Intuitively, this gives less weight to terms that show up commonly across all the documents. The term frequency-inverse document frequency(tf-idf) weighting scheme returns a weight to a term that increases with the number of occurrence within a small (rieger2021?)set of documents ((manning2008?)). This supplements the explicit omission of stop words by winnowing out context-specific frequent words.\nThere are different options for weight type, which determines the way each term is counted. Functionally, I used quanteda package to specify this scheme option. I tried count type, which provides an integer feature of count, and proportion type that is based on the relative frequency of a term compared to total counts. Proportion type is calculated by \\(\\frac{tf_{ij}}{\\Sigma_{j} {tf_{ij}}}\\) where in \\(i, j\\) each represents indices for a term and a document. Given the normalization process of the proportion weight type, variation between terms is smaller than simple count type. This is expected to lessen the gap between rare and frequent terms, and hence allow model to capture even general terms. However, R package seededlda and its function topic_models does not allow tf_idf based on “proportion” as an input because LDA assumes integer counts as observations, not floats.\nThis version presents the outcome generated by Experiment 3. Experiment 2 log can be found in moving_lda_0218.qmd.\n\nTrial 1: 10-year, 5 overlap, saved in moving_0209. tfidf option: count and inverse. 10 topics\nTrial 2: 10-year, 5 overlap, saved in moving_0218_2. tfidf option: none. 20 topics\nTrial 3: 10-year, 5 overlap, saved in moving_0219. tfidf option: count and inverse. 20 topics\nTrial 4: try a different R package for the proportion-inverse-weighted LDA other than ‘quanteda’",
    "crumbs": [
      "Topic Modeling",
      "Moving LDA"
    ]
  },
  {
    "objectID": "rmarkdown/moving_lda_0219.html#setting-up-libraries-and-load-raw-data",
    "href": "rmarkdown/moving_lda_0219.html#setting-up-libraries-and-load-raw-data",
    "title": "Moving LDA Version - Inverse Weighted",
    "section": "Setting up libraries and load raw data",
    "text": "Setting up libraries and load raw data\n\nlibrary(plyr)\nlibrary(dplyr)\nlibrary(tm)\nlibrary(ggplot2)\nlibrary(quanteda)\nlibrary(readr)\nlibrary(seededlda)\nlibrary(slam)\nlibrary(jsonlite)\nlibrary(gplots) #this is for heatmap\nlibrary(zoo)\nlibrary(tibble)\nlibrary(knitr)\nlibrary(topicmodels)\n\n\n#light&lt;-read.csv(\"../data/processed/cleaned.csv\")\n#light&lt;-light%&gt;%select(-X)\n\nmystopwords &lt;- c(\"will\", \"must\", \"mr\") #removing context-specific stopwords\ncustom_stopwords &lt;-c(stopwords(\"english\"), mystopwords)\n\n# Set up the parameters\ninterval &lt;- 10\n\nbreaks &lt;- c(seq(from = 1945, to = 2020, by = 5), 2022) \n\nlast_break &lt;- breaks[length(breaks)-1]\n\nif (last_break + interval &gt; 2020) {\n  moving_breaks &lt;- breaks\n} else {\n  moving_breaks &lt;- c(breaks, last_break + interval)\n}\n\nstart_years &lt;- moving_breaks[1:14]\nend_years &lt;- start_years + interval\nend_years &lt;- end_years[1:14]\n\n# add the final two windows\nspan_levels &lt;- c(paste0(start_years, \"-\", end_years), \"2015-2022\", \"2020-2022\")",
    "crumbs": [
      "Topic Modeling",
      "Moving LDA"
    ]
  },
  {
    "objectID": "rmarkdown/moving_lda_0219.html#uncomment-the-below-section-to-run-the-lda-analysis",
    "href": "rmarkdown/moving_lda_0219.html#uncomment-the-below-section-to-run-the-lda-analysis",
    "title": "Moving LDA Version - Inverse Weighted",
    "section": "Uncomment the below section to run the LDA analysis",
    "text": "Uncomment the below section to run the LDA analysis\n\n#lda_generator(light, span_levels)",
    "crumbs": [
      "Topic Modeling",
      "Moving LDA"
    ]
  },
  {
    "objectID": "rmarkdown/moving_lda_0219.html#function-1-generating-heatmaps",
    "href": "rmarkdown/moving_lda_0219.html#function-1-generating-heatmaps",
    "title": "Moving LDA Version - Inverse Weighted",
    "section": "Function 1) Generating heatmaps",
    "text": "Function 1) Generating heatmaps\nTo visualize the correlation between term-weight vectors from two time periods, below function generates heatmaps across pairs. This process also includes intermediate steps that generate a union of term vectors, which is needed to match the dimension between two matrices. A pair of lda_models should be neighbors from two consecutive time intervals, which may vary.\n\nInputs: span levels in character form, two lda_models in a list form\nOutput: Heatmap plots",
    "crumbs": [
      "Topic Modeling",
      "Moving LDA"
    ]
  },
  {
    "objectID": "rmarkdown/moving_lda_0219.html#function-2-printing-out-correlated-term-vectors",
    "href": "rmarkdown/moving_lda_0219.html#function-2-printing-out-correlated-term-vectors",
    "title": "Moving LDA Version - Inverse Weighted",
    "section": "Function 2) Printing out correlated term vectors",
    "text": "Function 2) Printing out correlated term vectors\nBased on the correlation matrix, below code prints out term vectors that show high correlation. It also lists the topic index from two different time intervals. Note that even the highly-correlated topics can have different topic indices.\n\nprint_ordered_rows &lt;- function(phi1_union, phi2_union, cor_matrix, high_corr_indices, correlation_threshold = 0.9) {\n  # Find indices where correlation is higher than the threshold\n  high_corr_indices &lt;- which(cor_matrix &gt; correlation_threshold & !is.na(cor_matrix), arr.ind = TRUE)\n  \n  # Create an empty list to store results\n  result_list &lt;- list()\n  \n  # Print the ordered rows for each topic with high correlation\n  for (i in seq_len(nrow(high_corr_indices))) {\n    model1_topic &lt;- high_corr_indices[i, 1]\n    model2_topic &lt;- high_corr_indices[i, 2]\n    \n    # Print the ordered rows for each model's topic\n    cat(paste(\"Model 1 - Topic\", model1_topic), \"\\n\")\n    phi1_result_row &lt;- orderBasedOnRow(phi1_union, model1_topic)\n    \n    cat(paste(\"Model 2 - Topic\", model2_topic), \"\\n\")\n    phi2_result_row &lt;- orderBasedOnRow(phi2_union, model2_topic)\n    \n    # Convert result rows to long format\n    phi1_result_long &lt;- phi1_result_row %&gt;%\n      tidyr::pivot_longer(everything(), names_to = \"term_1\", values_to = \"probability_1\")\n    \n    phi2_result_long &lt;- phi2_result_row %&gt;%\n      tidyr::pivot_longer(everything(), names_to = \"term_2\", values_to = \"probability_2\")\n    \n    # Combine phi1 and phi2 results\n    pair &lt;- bind_cols(phi1_result_long, phi2_result_long)\n    \n    # Append the result to the list\n    result_list[[i]] &lt;- pair\n  }\n  \n  # Combine all results into a single dataframe\n  final_result &lt;- do.call(bind_rows, result_list)\n  \n  print(kable(final_result))\n}",
    "crumbs": [
      "Topic Modeling",
      "Moving LDA"
    ]
  },
  {
    "objectID": "rmarkdown/moving_lda_0219.html#function-3-sorting-top-10-terms-from-each-term-vector.",
    "href": "rmarkdown/moving_lda_0219.html#function-3-sorting-top-10-terms-from-each-term-vector.",
    "title": "Moving LDA Version - Inverse Weighted",
    "section": "Function 3) Sorting top 10 terms from each term vector.",
    "text": "Function 3) Sorting top 10 terms from each term vector.\nPrevious steps have sorted term columns alphabetically to create correlation matrix. I re-organize each time period’s term vector in the order of weights to list the most semantically significant term within each topic.\n\norderBasedOnRow &lt;- function(df, I) {\n  # Order columns based on the Ith row values\n  ordered_cols &lt;- order(apply(df, 2, function(x) x[I]), decreasing = TRUE)\n\n  # Reorder the data frame columns\n  ordered_df &lt;- df[, ordered_cols]\n\n  ordered_row &lt;- ordered_df[I, 1:10]\n\n  return(ordered_row)\n}",
    "crumbs": [
      "Topic Modeling",
      "Moving LDA"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "United Nations General Debate Corpus (UNGDC)",
    "section": "",
    "text": "This corpus contains 10568 English transcripts of speeches delivered by state representatives of the UN member states at the United Nations General Debate from 1946 until 2022. Text data was made available by Baturo et al. (2017). Original data is in a form of .txt file, each containing speech transcript from one member state in a given year. This RDS dataset was generated by executing “RDS_generator.R” file to read in all .txt files into a single dataframe. File size is 58.61 MB. Alternatively, run “json_convertor.R” file to transform plain texts into structured .json files.\nDatasets can be found here. Three identifying variables across all documents are: ccode_iso (ISO 3-letter character country code), session (session number of the given UNGD meeting), year (year of UNGD).\nRefer to the description.Rmd file for an overview of the dataset.\n\n\n\nFile\nDescription\n\n\n\n\ncleaned.csv\n10568 observations. “text” is cleaned after removing white spaces(multiple spaces and tab), digits followed by a dot. This does not exclude any stop words.\n\n\nlight.csv\n10568 observations. “text” does not have any stop words.\n\n\nmeta.csv\n10568 observations with 110 variables. This data contains country-year level information for each speaker country. Refer to codebook for more description on each feature.\n\n\nliwc_controls.csv\n10568 observations with 222 variables. This data contains country-year level information for each speaker country as well as psychological, linguistic constructs generated by LIWC.\n\n\n\n\n\n\n`UNGDC_topic_modeling_updated.qmd’ renders LDA results. This version replaced deprecated functions from the quanteda package. It also presents a workflow with the goal of handling dynamic nature of topic models. Using correlation, this script shows the overlap between topics, represented with different terms over time.\n\n\n\nSlava Jankin, Alexander Baturo, and Niheer Dasandi. “Words to Unite Nations: The Complete UN General Debate Corpus, 1946-Present.” OSF working paper, https://osf.io/6kty4\nAlexander Baturo, Niheer Dasandi, and Slava Mikhaylov, “Understanding State Preferences With Text As Data: Introducing the UN General Debate Corpus” Research & Politics, 2017.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#data-description",
    "href": "index.html#data-description",
    "title": "United Nations General Debate Corpus (UNGDC)",
    "section": "",
    "text": "This corpus contains 10568 English transcripts of speeches delivered by state representatives of the UN member states at the United Nations General Debate from 1946 until 2022. Text data was made available by Baturo et al. (2017). Original data is in a form of .txt file, each containing speech transcript from one member state in a given year. This RDS dataset was generated by executing “RDS_generator.R” file to read in all .txt files into a single dataframe. File size is 58.61 MB. Alternatively, run “json_convertor.R” file to transform plain texts into structured .json files.\nDatasets can be found here. Three identifying variables across all documents are: ccode_iso (ISO 3-letter character country code), session (session number of the given UNGD meeting), year (year of UNGD).\nRefer to the description.Rmd file for an overview of the dataset.\n\n\n\nFile\nDescription\n\n\n\n\ncleaned.csv\n10568 observations. “text” is cleaned after removing white spaces(multiple spaces and tab), digits followed by a dot. This does not exclude any stop words.\n\n\nlight.csv\n10568 observations. “text” does not have any stop words.\n\n\nmeta.csv\n10568 observations with 110 variables. This data contains country-year level information for each speaker country. Refer to codebook for more description on each feature.\n\n\nliwc_controls.csv\n10568 observations with 222 variables. This data contains country-year level information for each speaker country as well as psychological, linguistic constructs generated by LIWC.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#lda-analysis",
    "href": "index.html#lda-analysis",
    "title": "United Nations General Debate Corpus (UNGDC)",
    "section": "",
    "text": "`UNGDC_topic_modeling_updated.qmd’ renders LDA results. This version replaced deprecated functions from the quanteda package. It also presents a workflow with the goal of handling dynamic nature of topic models. Using correlation, this script shows the overlap between topics, represented with different terms over time.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "United Nations General Debate Corpus (UNGDC)",
    "section": "",
    "text": "Slava Jankin, Alexander Baturo, and Niheer Dasandi. “Words to Unite Nations: The Complete UN General Debate Corpus, 1946-Present.” OSF working paper, https://osf.io/6kty4\nAlexander Baturo, Niheer Dasandi, and Slava Mikhaylov, “Understanding State Preferences With Text As Data: Introducing the UN General Debate Corpus” Research & Politics, 2017.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "rmarkdown/UNGDC_topic_modeling_updated.html",
    "href": "rmarkdown/UNGDC_topic_modeling_updated.html",
    "title": "Dynamic UNGDC (updated)",
    "section": "",
    "text": "This version does use tf-idf for LDA analysis. For the older version, refer to UNGDC_topic_modeling.qmd. I created a separate version for two reasons. First, some of the functions and options deprecated from the quanteda R package. Earlier version might not be reproducible. Second, the inclusion of tf-idf to generate LDA analysis has a tradeoff. Since it gives less weights to terms that appear frequently across the documents, by definition, tf-idf lowers the correlation between terms over different time window. It is harder to notice a clear linkage between two topics represented by different terms. However, unlike the earlier version that excludes tf-idf, topics are more specific, and substantively meaningful.",
    "crumbs": [
      "Topic Modeling",
      "Decadal LDA"
    ]
  },
  {
    "objectID": "rmarkdown/UNGDC_topic_modeling_updated.html#dynamic-topic-modeling-for-ungdc",
    "href": "rmarkdown/UNGDC_topic_modeling_updated.html#dynamic-topic-modeling-for-ungdc",
    "title": "Dynamic UNGDC (updated)",
    "section": "Dynamic Topic Modeling for UNGDC",
    "text": "Dynamic Topic Modeling for UNGDC\nIn order to generate LDA topic modeling results for the corpus of UNGD, I split the corpus into different time frames. The entire time span of 1945 until 2022 is split into 8 intervals, with a duration of 10 years.\n\n# Load packages\nlibrary(plyr)\nlibrary(dplyr)\nlibrary(tm)\nlibrary(gplots)\nlibrary(ggplot2)\nlibrary(quanteda)\nlibrary(readr)\nlibrary(seededlda)\nlibrary(slam)\nlibrary(jsonlite)\nlibrary(tm)\nlibrary(tidyr)\nlibrary(knitr)\n\nlight &lt;- readRDS(\"data/processed/cleaned.RDS\")\n\n#Set up the parameters\nlight_interval &lt;- light %&gt;%\n  dplyr::mutate(span = as.factor(cut(year,\n                                     breaks = c(seq(from = 1945, to = 2022, by = 10), 2022)))) %&gt;%\n  dplyr::arrange(year)\n\n\n# I added two additional stop words that aren't captured in the generic stop words dictionary. \n\nmystopwords &lt;- c(\"will\", \"must\")\ncustom_stopwords &lt;- c(stopwords(\"english\"), mystopwords)",
    "crumbs": [
      "Topic Modeling",
      "Decadal LDA"
    ]
  },
  {
    "objectID": "rmarkdown/UNGDC_topic_modeling_updated.html#term-frequency-inverse-matrix-and-descriptive-data-visualization",
    "href": "rmarkdown/UNGDC_topic_modeling_updated.html#term-frequency-inverse-matrix-and-descriptive-data-visualization",
    "title": "Dynamic UNGDC (updated)",
    "section": "Term Frequency-Inverse Matrix and Descriptive Data Visualization",
    "text": "Term Frequency-Inverse Matrix and Descriptive Data Visualization\n\nTo inspect the data and frequent words across time intervals, below code generates top-20 terms based on the tf-idf scores.\nInput dataset: “data/processed/cleaned.RDS”.\n\n\n# Function for generating tf_idf and plots.\nsapply(levels(light_interval$span), function(i) {\n  subset_i &lt;- light_interval %&gt;% dplyr::filter(span %in% i)\n  corpus_subset &lt;- Corpus(VectorSource(subset_i$text))\n  tdm &lt;- TermDocumentMatrix(corpus_subset,\n                            control = list(weighting = weightTfIdf,\n                                           removePunctuation = TRUE,\n                                           stemming = TRUE,\n                                           removeNumbers = TRUE,\n                                           stopwords = TRUE,\n                                           removewords = mystopwords))\n  top_terms &lt;- slam::row_sums(as.matrix(tdm))\n  \n  # Create a data frame with terms and tfidf values\n  top_terms_df &lt;- data.frame(term = names(top_terms), tfidf = top_terms)\n  \n  # Order the terms by tfidf value\n  top_terms_df &lt;- top_terms_df[order(top_terms_df$tfidf, decreasing = TRUE), ]\n  \n  # Select the top 20 terms\n  top_terms_df &lt;- head(top_terms_df, 20)\n  \n  figure_i &lt;- ggplot(top_terms_df, aes(x = reorder(term, tfidf), y = tfidf)) +\n    geom_bar(stat = \"identity\", fill = \"skyblue\") +\n    theme_minimal() +\n    labs(title = \"Top 20 Terms by TF-IDF\",\n         x = \"Terms\",\n         y = \"TF-IDF Score\") +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1))\n  \n  output_file &lt;- file.path(\"figs/\", paste0(\"plot_\", i, \".png\"))\n  ggsave(output_file, figure_i, width = 8, height = 5, units = \"in\")\n})\n\n\ndfm function helps remove stop words and perform other preprocessing steps to create a more refined document-feature matrix. Additionally, the subsequent dfm_tfidf function is used to compute TF-IDF (Term Frequency-Inverse Document Frequency) scores, which down-weights terms that appear frequently across documents.",
    "crumbs": [
      "Topic Modeling",
      "Decadal LDA"
    ]
  },
  {
    "objectID": "rmarkdown/UNGDC_topic_modeling_updated.html#reading-in-lda-results",
    "href": "rmarkdown/UNGDC_topic_modeling_updated.html#reading-in-lda-results",
    "title": "Dynamic UNGDC (updated)",
    "section": "Reading in LDA results",
    "text": "Reading in LDA results\nAfter running the LDA model, I read in each LDA results as a separate element in a list form. Below code prins out top 10 terms associated with each topic in the LDA models for different span levels. Each row represents one semantic topic.\n\nread_lda_models &lt;- function(span_levels, output_dir = \"output/lda/decade_0120_replicate\") {\n  lda_models &lt;- list()\n\n  for (i in span_levels) {\n    lda_output_file &lt;- file.path(output_dir, paste0(\"lda_model_\", i, \".RDS\"))\n\n    if (file.exists(lda_output_file)) {\n      lda_model &lt;- readRDS(lda_output_file)\n      lda_models[[i]] &lt;- lda_model\n      cat(sprintf(\"LDA model for %s successfully loaded.\\n\", i))\n    } else {\n      cat(sprintf(\"LDA model file for %s not found.\\n\", i))\n    }\n  }\n\n  return(lda_models)\n}\n\n\n\nlda_models &lt;- read_lda_models(span_levels)\n\nLDA model for (1945,1955] successfully loaded.\nLDA model for (1955,1965] successfully loaded.\nLDA model for (1965,1975] successfully loaded.\nLDA model for (1975,1985] successfully loaded.\nLDA model for (1985,1995] successfully loaded.\nLDA model for (1995,2005] successfully loaded.\nLDA model for (2005,2015] successfully loaded.\nLDA model for (2015,2022] successfully loaded.\n\ntopic_tables &lt;- function(lda_models, span_levels) {\n  topic_tables &lt;- list()\n\n  for (i in span_levels) {\n    if (i %in% names(lda_models)) {\n      lda_model &lt;- lda_models[[i]]\n      terms &lt;- terms(lda_model, 10)\n      topic_table &lt;- data.frame(Terms = terms)\n      topic_tables[[i]] &lt;- topic_table\n    } else {\n      cat(sprintf(\"LDA model for %s not found.\\n\", i))\n    }\n  }\n\n  all_topics &lt;- do.call(rbind, topic_tables)\n  return(all_topics)\n}\n\n\ntopic_tables &lt;- topic_tables(lda_models, span_levels)\nprint(knitr::kable(topic_tables))\n\n\n\n|               |Terms.topic1  |Terms.topic2 |Terms.topic3 |Terms.topic4 |Terms.topic5 |Terms.topic6 |Terms.topic7 |Terms.topic8 |Terms.topic9  |Terms.topic10 |\n|:--------------|:-------------|:------------|:------------|:------------|:------------|:------------|:------------|:------------|:-------------|:-------------|\n|(1945,1955].1  |ussr          |arab         |german       |argentin     |bolivia      |hyderabad    |netherland   |resumpt      |communist     |india         |\n|(1945,1955].2  |soviet        |israel       |czechoslovak |latin        |cuba         |egypt        |bandung      |korea        |soviet        |australian    |\n|(1945,1955].3  |yugoslav      |palestin     |polish       |trade        |greek        |india        |african      |collect      |chines        |commiss       |\n|(1945,1955].4  |atom          |jerusalem    |soviet       |chile        |greec        |sudan        |south        |recommend    |communism     |council       |\n|(1945,1955].5  |yugoslavia    |morocco      |germani      |uruguay      |dominican    |egyptian     |geneva       |independ     |china         |think         |\n|(1945,1955].6  |armament      |tunisia      |people’      |veto         |guatemala    |pakistan     |africa       |leader       |korea         |say           |\n|(1945,1955].7  |union         |jew          |poland       |american     |colombia     |el           |indonesia    |europ        |union         |veto          |\n|(1945,1955].8  |prohibit      |refuge       |weapon       |panama       |bolivian     |salvador     |thailand     |veto         |imprison      |soviet        |\n|(1945,1955].9  |weapon        |jewish       |hydrogen     |venezuela    |guatemalan   |sudanes      |zealand      |revis        |costa         |china         |\n|(1945,1955].10 |american      |franc        |european     |per          |cuban        |british      |asia         |collabor     |mainland      |arbitr        |\n|(1955,1965].1  |particip      |bantu        |malaysia     |cambodia     |netherland   |pakistan     |american     |african      |german        |arab          |\n|(1955,1965].2  |moscow        |iceland      |zealand      |lao          |congo        |cyprus       |cuba         |africa       |socialist     |israel        |\n|(1955,1965].3  |industri      |south        |australia    |spain        |indonesia    |turkish      |cuban        |portug       |soviet        |palestin      |\n|(1955,1965].4  |coexist       |indian       |philippin    |communist    |irian        |kashmir      |panama       |mali         |czechoslovak  |egypt         |\n|(1955,1965].5  |fund          |canada       |malaya       |viet         |nigeria      |india        |guatemala    |portugues    |albania       |algerian      |\n|(1955,1965].6  |cent          |canadian     |australian   |spanish      |berlin       |turkey       |dominican    |somali       |romanian      |libya         |\n|(1955,1965].7  |trade         |danish       |feder        |chines       |belgian      |greek        |venezuela    |congo        |germani       |franc         |\n|(1955,1965].8  |scienc        |goa          |india        |cambodian    |indonesian   |greec        |latin        |austrian     |byelorussian  |libyan        |\n|(1955,1965].9  |concept       |africa       |indonesia    |pathet       |west         |nepal        |america      |cameroon     |nato          |canal         |\n|(1955,1965].10 |invest        |chairman     |manila       |royal        |want         |jammu        |paraguay     |malagasi     |albanian      |jordan        |\n|(1965,1975].1  |like          |pakistan     |african      |imperialist  |like         |israel       |austria      |cuba         |turkey        |haiti         |\n|(1965,1975].2  |programm      |india        |ghana        |khmer        |socialist    |arab         |spain        |iceland      |cyprus        |oil           |\n|(1965,1975].3  |nuclear       |zealand      |rwanda       |aggress      |soviet       |isra         |salvador     |venezuela    |turkish       |australia     |\n|(1965,1975].4  |big           |ireland      |portug       |imperi       |german       |palestin     |italian      |cuban        |argentina     |haitian       |\n|(1965,1975].5  |neighbour     |netherland   |uganda       |revisionist  |mongolian    |zionist      |el           |panama       |greec         |volta         |\n|(1965,1975].6  |space         |japan        |burundi      |albania      |byelorussian |palestinian  |itali        |bolivia      |argentin      |philippin     |\n|(1965,1975].7  |strategi      |burma        |africa       |albanian     |ssr          |yemen        |gibraltar    |zair         |peru          |price         |\n|(1965,1975].8  |franc         |kashmir      |portugues    |viet         |czechoslovak |israel’      |rica         |chile        |greek         |upper         |\n|(1965,1975].9  |youth         |fiji         |kenya        |cambodia     |ukrainian    |aggress      |hondura      |latin        |brazil        |food          |\n|(1965,1975].10 |madam         |pacif        |oau          |chines       |europ        |iraq         |uruguay      |dominican    |dahomey       |australian    |\n|(1975,1985].1  |malta         |soviet       |ireland      |imperialist  |turkey       |benin        |guinea       |pleasur      |guatemala     |¬             |\n|(1975,1985].2  |zionist       |japan        |panama       |vietnames    |yemen        |burundi      |papua        |dialog       |uganda        |barbado       |\n|(1975,1985].3  |bahama        |europ        |ecuador      |kampuchea    |egypt        |mali         |zealand      |cooper       |timor         |paraguay      |\n|(1975,1985].4  |itali         |german       |latin        |chines       |morocco      |rwanda       |pacif        |program      |nicaragua     |ghana         |\n|(1975,1985].5  |iranian       |union        |bolivia      |lao          |turkish      |seneg        |chad         |per          |guinea        |tion          |\n|(1975,1985].6  |iraqi         |socialist    |dominican    |thailand     |pakistan     |zair         |bangladesh   |refuge       |hondura       |guyana        |\n|(1975,1985].7  |mediterranean |mongolian    |rica         |nam          |sudan        |oau          |australia    |india        |salvador      |ment          |\n|(1975,1985].8  |tobago        |poland       |costa        |viet         |arab         |kenya        |surinam      |fortieth     |revolutionari |con           |\n|(1975,1985].9  |libyan        |austria      |spain        |ethiopia     |islam        |chad         |equatori     |sea          |guatemalan    |venezuela     |\n|(1975,1985].10 |islam         |detent       |american     |romania      |isra         |mauritania   |canada       |indian       |angola        |caribbean     |\n|(1985,1995].1  |wish          |wish         |wish         |panama       |wish         |wish         |wish         |wish         |wish          |wish          |\n|(1985,1995].2  |paraguay      |co           |islam        |burundi      |guinea       |canada       |european     |saint        |cooper        |malawi        |\n|(1985,1995].3  |american      |organis      |arab         |myanmar      |pacif        |netherland   |europ        |bahama       |boutro        |african       |\n|(1985,1995].4  |latin         |program      |sri          |rwanda       |viet         |philippin    |ukrain       |nepal        |eighth        |chad          |\n|(1985,1995].5  |bolivia       |dialog       |iranian      |romania      |nam          |want         |albania      |caribbean    |bosnia        |niger         |\n|(1985,1995].6  |dominican     |twelv        |lebanon      |zair         |japan        |revolut      |belarus      |pakistan     |herzegovina   |swaziland     |\n|(1985,1995].7  |ecuador       |align        |lanka        |panamanian   |equatori     |canadian     |poland       |barbado      |somalia       |uganda        |\n|(1985,1995].8  |hondura       |namibia      |iraqi        |belgium      |solomon      |let          |csce         |haiti        |l993          |kenya         |\n|(1985,1995].9  |chile         |disarma      |ireland      |canal        |zealand      |enemi        |austria      |surinam      |fiftieth      |benin         |\n|(1985,1995].10 |costa         |drug         |tunisia      |rwandes      |papua        |children     |croatia      |india        |npt           |angola        |\n|(1995,2005].1  |outset        |outset       |outset       |outset       |outset       |outset       |outset       |outset       |outset        |outset        |\n|(1995,2005].2  |african       |azerbaijan   |island       |korea        |croatia      |marino       |trinidad     |afghanistan  |arab          |sri           |\n|(1995,2005].3  |africa        |cyprus       |caribbean    |korean       |european     |san          |tobago       |taliban      |iraq          |ethiopia      |\n|(1995,2005].4  |guinea        |tajikistan   |pacif        |nepal        |herzegovina  |women        |belarus      |swaziland    |israel        |lanka         |\n|(1995,2005].5  |congo         |armenia      |saint        |pakistan     |mongolia     |sixtieth     |slovakia     |ecuador      |palestinian   |eritrea       |\n|(1995,2005].6  |malawi        |turkmenistan |papua        |ireland      |kosovo       |iraq         |panama       |bolivia      |isra          |andorra       |\n|(1995,2005].7  |chad          |turkey       |bahama       |thailand     |€            |outcom       |haiti        |myanmar      |lebanon       |eritrean      |\n|(1995,2005].8  |burundi       |kazakhstan   |barbado      |asean        |latvia       |weapon       |mexico       |estonia      |malta         |cuba          |\n|(1995,2005].9  |liberia       |georgia      |solomon      |monaco       |bosnia       |document     |guatemala    |chile        |kuwait        |truth         |\n|(1995,2005].10 |uganda        |turkish      |small        |india        |bulgaria     |uruguay      |dominican    |paraguay     |iraqi         |muslim        |\n|(2005,2015].1  |everi         |everi        |everi        |everi        |everi        |everi        |everi        |everi        |everi         |everi         |\n|(2005,2015].2  |nepal         |pakistan     |serbia       |japan        |mdgs         |guinea       |island       |arab         |ecuador       |azerbaijan    |\n|(2005,2015].3  |iceland       |iran         |fiji         |timor        |treati       |african      |sid          |yemen        |panama        |georgia       |\n|(2005,2015].4  |trinidad      |muslim       |european     |mongolia     |g            |korea        |pacif        |kuwait       |paraguay      |asean         |\n|(2005,2015].5  |burundi       |islam        |kosovo       |ireland      |nuclear      |mali         |solomon      |syrian       |marino        |kazakhstan    |\n|(2005,2015].6  |sri           |god          |bosnia       |lest         |mediat       |somalia      |saint        |iraq         |peru          |ukrain        |\n|(2005,2015].7  |tobago        |war          |herzegovina  |bangladesh   |disput       |korean       |bahama       |lebanon      |america       |afghanistan   |\n|(2005,2015].8  |canada        |nuclear      |cyprus       |latvia       |disarma      |sudan        |caribbean    |palestinian  |american      |moldova       |\n|(2005,2015].9  |malawi        |want         |malta        |cambodia     |migrat       |philippin    |grenada      |egypt        |latin         |thailand      |\n|(2005,2015].10 |zambia        |israel       |croatia      |australia    |multilater   |bissau       |small        |libya        |bolivia       |turkmenistan  |\n|(2015,2022].1  |distinct      |african      |israel       |distinct     |ukrain       |india        |pacif        |bosnia       |pandem        |korea         |\n|(2015,2022].2  |peacekeep     |mali         |syrian       |azerbaijan   |european     |pakistan     |island       |herzegovina  |covid         |malaysia      |\n|(2015,2022].3  |andorra       |sudan        |iran         |armenia      |russian      |sri          |ocean        |saint        |un            |asean         |\n|(2015,2022].4  |trade         |sahel        |brazil       |trinidad     |russia       |lanka        |solomon      |caribbean    |vaccin        |mongolia      |\n|(2015,2022].5  |weapon        |congo        |colombia     |tobago       |eu           |costa        |tonga        |beliz        |75th          |thailand      |\n|(2015,2022].6  |migrant       |chad         |spain        |burundi      |ireland      |bangladesh   |papua        |mauritius    |marino        |kazakhstan    |\n|(2015,2022].7  |educ          |guinea       |venezuela    |kingdom      |georgia      |canada       |australia    |nepal        |bhutan        |turkmenistan  |\n|(2015,2022].8  |energi        |africa       |iraq         |morocco      |serbia       |rica         |tanzania     |guatemala    |kenya         |japan         |\n|(2015,2022].9  |refuge        |madagascar   |palestinian  |arab         |europ        |kashmir      |micronesia   |moldova      |botswana      |kyrgyzstan    |\n|(2015,2022].10 |sdgs          |burkina      |lebanon      |yemeni       |montenegro   |muslim       |tuvalu       |bahama       |somalia       |tajikistan    |\n\n\n\nEach column in the dataset corresponds to a vector of terms representing a specific topic. However, extracting substantively meaningful topics poses challenges due to several issues. One notable challenge is the variability in the set of terms used to represent the same topic across different time periods. For instance, the topic of international security may be discussed in relation to the Soviet Union and North Korea in earlier time periods, whereas in more recent times, it may be associated with Russia and Ukraine.\nAnother important problem is identifying related topics over time. There is a difficulty of establishing connections between topics and understanding their evolution across different temporal contexts. Some topics and terms disappear abruptly, while new topics emerge. Identifying the connection between vectors poses a challenge.",
    "crumbs": [
      "Topic Modeling",
      "Decadal LDA"
    ]
  },
  {
    "objectID": "rmarkdown/UNGDC_topic_modeling_updated.html#dynamic-topic-modeling",
    "href": "rmarkdown/UNGDC_topic_modeling_updated.html#dynamic-topic-modeling",
    "title": "Dynamic UNGDC (updated)",
    "section": "Dynamic Topic Modeling",
    "text": "Dynamic Topic Modeling\n\nTo address the above mentioned challenges, we refered to existing papers.\n\"BERTopic Dynamic Topic Modeling\"(https://maartengr.github.io/BERTopic/getting_started/topicsovertime/topicsovertime.html)\nGreene and cross, 2017 (https://doi.org/10.1017/pan.2016.7)\n\n\nThis generates output for a single pair of time frames\n\nmodel1&lt;-lda_models[[1]]\nmodel2&lt;-lda_models[[2]]\n\n# phi value is a topic probability of every word\nphi1 &lt;- model1$phi\n\n#phi1$topic &lt;- sequence(nrow(phi1))\n\nphi2 &lt;- model2$phi\n#phi2$topic &lt;- sequence(nrow(phi2))\n\n\n# Convert matrices to data frames\nphi1_df &lt;- as.data.frame(phi1)\nphi2_df &lt;- as.data.frame(phi2)\n\norder_phi1 &lt;- order(colMeans(phi1_df), decreasing = TRUE)\norder_phi2 &lt;- order(colMeans(phi2_df), decreasing = TRUE)\n\n# Reorder columns based on the mean\nphi1_df &lt;- phi1_df[, order_phi1]\nphi2_df &lt;- phi2_df[, order_phi2]\n\n# Identify columns to drop based on colMeans\n## Try without dropping\ncolumns_to_drop_phi1 &lt;- colMeans(phi1_df) &lt; 0.00001\ncolumns_to_drop_phi2 &lt;- colMeans(phi2_df) &lt; 0.00001\n\n# Drop identified columns\nphi1_df &lt;- phi1_df[, !columns_to_drop_phi1, drop = FALSE]\nphi2_df &lt;- phi2_df[, !columns_to_drop_phi2, drop = FALSE]\n\n\n# Get the union of column names\nall_terms &lt;- union(colnames(phi1_df), colnames(phi2_df))\n\n#fill missing values with zeros\nphi1_union &lt;- bind_cols(phi1_df, setNames(data.frame(matrix(0, nrow = nrow(phi1_df), ncol = length(setdiff(all_terms, colnames(phi1_df))))), setdiff(all_terms, colnames(phi1_df))))\nphi2_union &lt;- bind_cols(phi2_df, setNames(data.frame(matrix(0, nrow = nrow(phi2_df), ncol = length(setdiff(all_terms, colnames(phi2_df))))), setdiff(all_terms, colnames(phi2_df))))\n\n# Reorder columns alphabetically\nphi1_union &lt;- phi1_union[, order(colnames(phi1_union))]\nphi2_union &lt;- phi2_union[, order(colnames(phi2_union))]\n\n\ndim(phi1_union)\ndim(phi2_union)\n\n\ncor&lt;-cor(t(phi1_union), t(phi2_union))\n\n\nheatmap.2(cor,\n          Rowv = FALSE, Colv = FALSE,\n          col = heat.colors(256),\n          trace = \"none\", # no row/column names\n          key = TRUE, keysize = 1.5,\n          density.info = \"none\", margins = c(5, 5),\n          cexCol = 1, cexRow = 1, # adjust text size\n          notecol = \"black\", notecex = 0.7,\n          main = \"Correlation Matrix\",\n          xlab = \"Period 2\", ylab = \"Period 1\",\n          symkey = FALSE)\n\norder_phi1_union &lt;- order(colMeans(phi1_union), decreasing = TRUE)\nphi1_result &lt;- phi1_union[, order_phi1_union]\n\norder_phi2_union &lt;- order(colMeans(phi2_union), decreasing = TRUE)\nphi2_result &lt;- phi2_union[, order_phi2_union]\n\n\nphi1_result_row &lt;- orderBasedOnRow(phi1_union, 1)\nphi1_result_long&lt;-phi1_result_row%&gt;%\n  tidyr::pivot_longer(everything(), names_to=\"term_1\", values_to=\"probability_1\")\n\nphi2_result_row &lt;- orderBasedOnRow(phi2_union, 6)\nphi2_result_long&lt;-phi2_result_row%&gt;%\n  tidyr::pivot_longer(everything(), names_to=\"term_2\", values_to=\"probability_2\")\n\npair&lt;-bind_cols(phi1_result_long, phi2_result_long)\n\n#Function to print out the words\n\norderBasedOnRow &lt;- function(df, I) {\n  # Order columns based on the Ith row values\n  ordered_cols &lt;- order(apply(df, 2, function(x) x[I]), decreasing = TRUE)\n\n  # Reorder the data frame columns\n  ordered_df &lt;- df[, ordered_cols]\n\n  ordered_row &lt;- ordered_df[I, 1:10]\n\n  return(ordered_row)\n}",
    "crumbs": [
      "Topic Modeling",
      "Decadal LDA"
    ]
  },
  {
    "objectID": "rmarkdown/UNGDC_topic_modeling_updated.html#below-function-generates-heatmaps-for-a-pair-of-models.",
    "href": "rmarkdown/UNGDC_topic_modeling_updated.html#below-function-generates-heatmaps-for-a-pair-of-models.",
    "title": "Dynamic UNGDC (updated)",
    "section": "Below function generates heatmaps for a pair of models.",
    "text": "Below function generates heatmaps for a pair of models.\n\ngenerate_heatmap &lt;- function(model1, model2, correlation_threshold = 0.9) {\n  phi1 &lt;- model1$phi\n  phi2 &lt;- model2$phi\n\n  phi1_df &lt;- as.data.frame(phi1)\n  phi2_df &lt;- as.data.frame(phi2)\n  \n  all_terms &lt;- union(colnames(phi1_df), colnames(phi2_df))\n\n  phi1_union &lt;- bind_cols(phi1_df, setNames(data.frame(matrix(0, nrow = nrow(phi1_df), ncol = length(setdiff(all_terms, colnames(phi1_df))))), setdiff(all_terms, colnames(phi1_df))))\n  phi2_union &lt;- bind_cols(phi2_df, setNames(data.frame(matrix(0, nrow = nrow(phi2_df), ncol = length(setdiff(all_terms, colnames(phi2_df))))), setdiff(all_terms, colnames(phi2_df))))\n\n  phi1_union &lt;- phi1_union[, order(colnames(phi1_union))]\n  phi2_union &lt;- phi2_union[, order(colnames(phi2_union))]\n\n  dim(phi1_union)\n  dim(phi2_union)\n\n  cor_matrix &lt;- cor(t(phi1_union), t(phi2_union))\n\n  # Heatmap for correlation matrix\n  heatmap.2(cor_matrix,\n            Rowv = FALSE, Colv = FALSE,\n            col = heat.colors(16),\n            trace = \"none\", # no row/column names\n            key = TRUE, keysize = 1.5,\n            density.info = \"none\", margins = c(5, 5),\n            cexCol = 1, cexRow = 1, # adjust text size\n            notecol = \"black\", notecex = 0.7,\n            xlab = \"Time 2\",\n            ylab = \"Time 1\",\n            symkey = FALSE)\n\n  return(list(phi1_union = phi1_union, phi2_union = phi2_union, cor_matrix = cor_matrix))\n}",
    "crumbs": [
      "Topic Modeling",
      "Decadal LDA"
    ]
  },
  {
    "objectID": "rmarkdown/UNGDC_topic_modeling_updated.html#rows-with-high-correlation",
    "href": "rmarkdown/UNGDC_topic_modeling_updated.html#rows-with-high-correlation",
    "title": "Dynamic UNGDC (updated)",
    "section": "Rows with high correlation",
    "text": "Rows with high correlation\n\n# Function to print the ordered rows for each topic with high correlation\nprint_ordered_rows &lt;- function(phi1_union, phi2_union, cor_matrix, high_corr_indices, correlation_threshold = 0.9) {\n  # Find indices where correlation is higher than the threshold\n  high_corr_indices &lt;- which(cor_matrix &gt; correlation_threshold & !is.na(cor_matrix), arr.ind = TRUE)\n\n  # Create an empty list to store results\n  result_list &lt;- list()\n\n  # Print the ordered rows for each topic with high correlation\n  for (i in seq_len(nrow(high_corr_indices))) {\n    model1_topic &lt;- high_corr_indices[i, 1]\n    model2_topic &lt;- high_corr_indices[i, 2]\n\n    # Print the ordered rows for each model's topic\n    cat(paste(\"Model 1 - Topic\", model1_topic), \"\\n\")\n    phi1_result_row &lt;- orderBasedOnRow(phi1_union, model1_topic)\n\n    cat(paste(\"Model 2 - Topic\", model2_topic), \"\\n\")\n    phi2_result_row &lt;- orderBasedOnRow(phi2_union, model2_topic)\n\n    # Convert result rows to long format\n    phi1_result_long &lt;- phi1_result_row %&gt;%\n      tidyr::pivot_longer(everything(), names_to = \"term_1\", values_to = \"probability_1\")\n\n    phi2_result_long &lt;- phi2_result_row %&gt;%\n      tidyr::pivot_longer(everything(), names_to = \"term_2\", values_to = \"probability_2\")\n\n    # Combine phi1 and phi2 results\n    pair &lt;- bind_cols(phi1_result_long, phi2_result_long)\n\n    # Append the result to the list\n    result_list[[i]] &lt;- pair\n  }\n\n  # Combine all results into a single dataframe\n  final_result &lt;- do.call(bind_rows, result_list)\n\n  return(final_result)\n}",
    "crumbs": [
      "Topic Modeling",
      "Decadal LDA"
    ]
  },
  {
    "objectID": "rmarkdown/UNGDC_topic_modeling_updated.html#execute-functions-over-pairs",
    "href": "rmarkdown/UNGDC_topic_modeling_updated.html#execute-functions-over-pairs",
    "title": "Dynamic UNGDC (updated)",
    "section": "Execute functions over pairs",
    "text": "Execute functions over pairs\n\n# Loop through pairs of models to generate heatmaps and print results\nfor (i in 1:(length(lda_models) - 1)) {\n  model1 &lt;- lda_models[[i]]\n  model2 &lt;- lda_models[[i + 1]]\n\n  result &lt;- generate_heatmap(model1, model2, correlation_threshold = 0.5)\n  \n  phi1_union &lt;- result$phi1_union\n  phi2_union &lt;- result$phi2_union\n  cor_matrix &lt;- result$cor_matrix\n\n  # Print ordered rows only if there are high correlations\n  if (any(cor_matrix &gt; 0.5, na.rm = TRUE)) {\n    phi1_result &lt;- phi1_union[, order(colMeans(phi1_union), decreasing = TRUE)]\n    phi2_result &lt;- phi2_union[, order(colMeans(phi2_union), decreasing = TRUE)]\n\n    # Call the modified function and pass high_corr_indices as an argument\n    final_result &lt;- print_ordered_rows(phi1_result, phi2_result, cor_matrix, high_corr_indices, correlation_threshold = 0.5)\n    print(final_result)\n  }\n}\n\n\n\n\n\n\n\n\nModel 1 - Topic 3 \nModel 2 - Topic 9 \nModel 1 - Topic 2 \nModel 2 - Topic 10 \n# A tibble: 20 × 4\n   term_1       probability_1 term_2       probability_2\n   &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;                &lt;dbl&gt;\n 1 german             0.0150  german             0.0138 \n 2 czechoslovak       0.0119  socialist          0.0102 \n 3 polish             0.0113  soviet             0.00986\n 4 soviet             0.0108  czechoslovak       0.00816\n 5 germani            0.0101  albania            0.00793\n 6 people’            0.00766 romanian           0.00732\n 7 poland             0.00693 germani            0.00728\n 8 weapon             0.00632 byelorussian       0.00726\n 9 hydrogen           0.00619 nato               0.00629\n10 geneva             0.00595 albanian           0.00548\n11 arab               0.0271  arab               0.0249 \n12 israel             0.0228  israel             0.0231 \n13 palestin           0.0129  palestin           0.0155 \n14 jerusalem          0.0104  egypt              0.0105 \n15 morocco            0.00949 algerian           0.0101 \n16 tunisia            0.00899 libya              0.00916\n17 jew                0.00821 franc              0.00826\n18 refuge             0.00728 libyan             0.00782\n19 jewish             0.00635 canal              0.00776\n20 franc              0.00500 jordan             0.00729\n\n\n\n\n\n\n\n\n\nModel 1 - Topic 8 \nModel 2 - Topic 3 \nModel 1 - Topic 10 \nModel 2 - Topic 6 \nModel 1 - Topic 7 \nModel 2 - Topic 8 \n# A tibble: 30 × 4\n   term_1    probability_1 term_2    probability_2\n   &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;             &lt;dbl&gt;\n 1 african         0.0150  african         0.00885\n 2 africa          0.00815 ghana           0.00692\n 3 portug          0.00735 rwanda          0.00661\n 4 mali            0.00729 portug          0.00620\n 5 portugues       0.00670 uganda          0.00618\n 6 somali          0.00661 burundi         0.00593\n 7 congo           0.00627 africa          0.00530\n 8 austrian        0.00601 portugues       0.00462\n 9 cameroon        0.00564 kenya           0.00460\n10 malagasi        0.00553 oau             0.00452\n# ℹ 20 more rows\n\n\n\n\n\n\n\n\n\nModel 1 - Topic 4 \nModel 2 - Topic 4 \n# A tibble: 10 × 4\n   term_1      probability_1 term_2      probability_2\n   &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;\n 1 imperialist       0.0162  imperialist       0.0108 \n 2 khmer             0.00847 vietnames         0.0106 \n 3 aggress           0.00749 kampuchea         0.00971\n 4 imperi            0.00718 chines            0.00956\n 5 revisionist       0.00666 lao               0.00954\n 6 albania           0.00659 thailand          0.00947\n 7 albanian          0.00594 nam               0.00870\n 8 viet              0.00576 viet              0.00863\n 9 cambodia          0.00553 ethiopia          0.00833\n10 chines            0.00545 romania           0.00801",
    "crumbs": [
      "Topic Modeling",
      "Decadal LDA"
    ]
  },
  {
    "objectID": "rmarkdown/liwc_analysis.html",
    "href": "rmarkdown/liwc_analysis.html",
    "title": "liwc_modeling",
    "section": "",
    "text": "In this project, I use linguistic features of state representatives’ speech transcripts from the United Nations General Debate Corpus (UNGDC) to predict the regime type. The goal is twofold. First, we aim at running a hard test for a hypothesis that countries identified with distinct regime types show different linguistic styles. If I can predict the speaker’s regime type based on linguistic features, it is a strong indication of the difference in linguistic features across regime types. Second, this project analyzes key linguistic features that act as a strong signal of the state’s regime type. I further interpret substantive implication of strong coefficients and check how consistent their degrees of significance are across the models.\nThis script uses the scores of LIWC features and merges with country-year level meta data. \"data/raw/controls/controls.csv\" has a battery of country-year level variables that might potentially confound the statistical modeling. With liwc_meta dataset, at the country-year level, I run a series of statistical models that probe the relationship between linguistic features and sentiment scores of that speech. To preview, LIWC features alone have a strong predictive power on regime types, even without the help of meta data.\nI test whether there is a correlation between a country’s invocation of international legal norms and the regime type. Among many, I generate three key legal principles that are prominent throughout the history of international politics. These are principle of sovereignty, principle of non-intervention, and the principle of human rights. Binary variables capture whether each principle was invoked, and count variables measure the number of time it was mentioned within one speech.",
    "crumbs": [
      "Linguistic Analysis",
      "LIWC"
    ]
  },
  {
    "objectID": "rmarkdown/liwc_analysis.html#separate-test-data-from-validation-set.",
    "href": "rmarkdown/liwc_analysis.html#separate-test-data-from-validation-set.",
    "title": "liwc_modeling",
    "section": "Separate test data from validation set.",
    "text": "Separate test data from validation set.\nTake out the test data set (just a few years) and then split for th e validation data. In my dataset, I carve out observations from two years (2021 and 2022) as my test data.\nWithin the test data, I split the data in to two groups: pre and post Cold War with a threshold of 1990. I create several models based on the pre-Cold War era and generate model evaluation metrics by applying the models to the post Cold War era.",
    "crumbs": [
      "Linguistic Analysis",
      "LIWC"
    ]
  },
  {
    "objectID": "rmarkdown/liwc_analysis.html#interpretation-of-the-model",
    "href": "rmarkdown/liwc_analysis.html#interpretation-of-the-model",
    "title": "liwc_modeling",
    "section": "Interpretation of the model",
    "text": "Interpretation of the model\nSummary table of the estimation results highlight features that play important role in predicting the regime type. Below plot displays the fitted model of how a linguistic feature of “focuspast” affects an outcome of regime type. It seems that there is a weak but consistent positive correlation between the linguistic tendency to focus on the past and the regime type. This pattern is consistent regardless of a country’s history of being a former colony.\n\nmodel_summary2&lt;-modelsummary(model0, \n                             stars = TRUE, \n                             output = \"kableExtra\", \n                             escape = FALSE)\n\nmodel_summary2%&gt;%kable_classic(full_width=F, html_font = \"Cambria\")%&gt;%\n    scroll_box(width = \"100%\", height = \"600px\")\n\n\n\n\n\n\n (1)\n\n\n\n\n(Intercept)\n56.129**\n\n\n\n(19.600)\n\n\nWC\n0.000\n\n\n\n(0.000)\n\n\nAnalytic\n−0.177*\n\n\n\n(0.082)\n\n\nClout\n0.073\n\n\n\n(0.102)\n\n\nAuthentic\n0.208\n\n\n\n(0.146)\n\n\nTone\n0.048\n\n\n\n(0.073)\n\n\nWPS\n0.032\n\n\n\n(0.021)\n\n\nBigWords\n0.002\n\n\n\n(0.136)\n\n\nDic\n−0.356+\n\n\n\n(0.214)\n\n\nLinguistic\n−0.383\n\n\n\n(0.467)\n\n\nfunction_feature\n0.212\n\n\n\n(0.541)\n\n\npronoun\n−23.295\n\n\n\n(25.957)\n\n\nppron\n20.785\n\n\n\n(25.931)\n\n\ni\n1.727\n\n\n\n(1.848)\n\n\nwe\n0.977\n\n\n\n(1.540)\n\n\nyou\n1.116\n\n\n\n(1.819)\n\n\nshehe\n4.889*\n\n\n\n(2.388)\n\n\nthey\n0.385\n\n\n\n(1.558)\n\n\nipron\n23.246\n\n\n\n(25.984)\n\n\ndet\n0.856*\n\n\n\n(0.410)\n\n\narticle\n−0.558\n\n\n\n(0.531)\n\n\nnumber\n−0.578\n\n\n\n(0.383)\n\n\nprep\n0.188\n\n\n\n(0.436)\n\n\nauxverb\n−0.518\n\n\n\n(0.674)\n\n\nadverb\n−0.545\n\n\n\n(0.454)\n\n\nconj\n0.038\n\n\n\n(0.435)\n\n\nnegate\n−0.553\n\n\n\n(0.945)\n\n\nverb\n0.287\n\n\n\n(0.540)\n\n\nadj\n0.015\n\n\n\n(0.447)\n\n\nquantity\n−0.104\n\n\n\n(0.436)\n\n\nDrives\n0.142\n\n\n\n(1.353)\n\n\naffiliation\n−0.450\n\n\n\n(1.378)\n\n\nachieve\n0.702\n\n\n\n(1.336)\n\n\npower\n0.369\n\n\n\n(1.361)\n\n\nCognition\n5.500*\n\n\n\n(2.315)\n\n\nallnone\n−6.289**\n\n\n\n(2.383)\n\n\ncogproc\n−4.793*\n\n\n\n(2.373)\n\n\ninsight\n−1.021\n\n\n\n(0.985)\n\n\ncause\n−1.302*\n\n\n\n(0.630)\n\n\ndiscrep\n1.417\n\n\n\n(1.001)\n\n\ntentat\n−0.535\n\n\n\n(0.667)\n\n\ncertitude\n−1.121\n\n\n\n(0.703)\n\n\ndiffer\n−0.609\n\n\n\n(1.165)\n\n\nmemory\n−6.128*\n\n\n\n(2.688)\n\n\nAffect\n−0.022\n\n\n\n(5.690)\n\n\ntone_pos\n−0.041\n\n\n\n(5.839)\n\n\ntone_neg\n0.831\n\n\n\n(5.769)\n\n\nemotion\n−0.774\n\n\n\n(5.514)\n\n\nemo_pos\n0.844\n\n\n\n(5.602)\n\n\nemo_neg\n0.821\n\n\n\n(5.795)\n\n\nemo_anx\n1.537\n\n\n\n(2.562)\n\n\nemo_anger\n−1.882\n\n\n\n(2.438)\n\n\nemo_sad\n0.102\n\n\n\n(2.483)\n\n\nswear\n−5.161\n\n\n\n(7.616)\n\n\nSocial\n0.380\n\n\n\n(0.576)\n\n\nsocbehav\n−0.103\n\n\n\n(0.707)\n\n\nprosocial\n−1.245*\n\n\n\n(0.578)\n\n\npolite\n−0.159\n\n\n\n(0.885)\n\n\nconflict\n−0.067\n\n\n\n(0.969)\n\n\nmoral\n−0.400\n\n\n\n(0.737)\n\n\ncomm\n−0.899\n\n\n\n(0.674)\n\n\nsocrefs\n0.513\n\n\n\n(0.883)\n\n\nfamily\n1.600\n\n\n\n(1.729)\n\n\nfriend\n−1.118\n\n\n\n(4.068)\n\n\nfemale\n−3.629***\n\n\n\n(0.893)\n\n\nmale\n−2.186\n\n\n\n(1.438)\n\n\nCulture\n−13.922\n\n\n\n(12.687)\n\n\npolitic\n13.677\n\n\n\n(12.684)\n\n\nethnicity\n13.891\n\n\n\n(12.669)\n\n\ntech\n14.631\n\n\n\n(12.729)\n\n\nLifestyle\n−0.439\n\n\n\n(1.383)\n\n\nleisure\n−0.848\n\n\n\n(1.967)\n\n\nhome\n1.860\n\n\n\n(2.424)\n\n\nwork\n0.167\n\n\n\n(1.329)\n\n\nmoney\n1.549\n\n\n\n(1.183)\n\n\nrelig\n0.291\n\n\n\n(1.483)\n\n\nPhysical\n−0.310\n\n\n\n(1.005)\n\n\nhealth\n1.032\n\n\n\n(1.550)\n\n\nillness\n−1.617\n\n\n\n(1.698)\n\n\nwellness\n2.602\n\n\n\n(2.940)\n\n\nmental\n−7.307\n\n\n\n(6.068)\n\n\nsubstances\n7.125\n\n\n\n(4.889)\n\n\nsexual\n0.010\n\n\n\n(1.714)\n\n\nfood\n1.069\n\n\n\n(1.163)\n\n\ndeath\n2.108\n\n\n\n(1.767)\n\n\nneed\n0.204\n\n\n\n(0.543)\n\n\nwant\n0.082\n\n\n\n(1.283)\n\n\nacquire\n−0.196\n\n\n\n(1.053)\n\n\nlack\n−2.447*\n\n\n\n(0.981)\n\n\nfulfill\n3.340**\n\n\n\n(1.235)\n\n\nfatigue\n5.842\n\n\n\n(9.757)\n\n\nreward\n−1.613\n\n\n\n(0.991)\n\n\nrisk\n−0.493\n\n\n\n(0.529)\n\n\ncuriosity\n−0.879\n\n\n\n(1.112)\n\n\nallure\n0.618*\n\n\n\n(0.305)\n\n\nPerception\n−1.966\n\n\n\n(1.222)\n\n\nattention\n2.146\n\n\n\n(1.483)\n\n\nmotion\n0.450\n\n\n\n(1.414)\n\n\nspace\n0.839\n\n\n\n(1.507)\n\n\nvisual\n2.029\n\n\n\n(1.462)\n\n\nauditory\n−0.259\n\n\n\n(2.508)\n\n\nfeeling\n1.492\n\n\n\n(2.047)\n\n\ntime\n−0.885\n\n\n\n(0.846)\n\n\nfocuspast\n0.479\n\n\n\n(0.399)\n\n\nfocuspresent\n0.187\n\n\n\n(0.395)\n\n\nfocusfuture\n0.205\n\n\n\n(0.534)\n\n\nConversation\n5.188\n\n\n\n(22.259)\n\n\nnetspeak\n4.449\n\n\n\n(20.407)\n\n\nassent\n−6.620\n\n\n\n(21.828)\n\n\nnonflu\n32.286\n\n\n\n(48.233)\n\n\nfiller\n−236.128\n\n\n\n(13385.385)\n\n\nAllPunc\n14.746\n\n\n\n(20.193)\n\n\nPeriod\n−13.898\n\n\n\n(20.179)\n\n\nComma\n−14.805\n\n\n\n(20.192)\n\n\nQMark\n−13.590\n\n\n\n(20.066)\n\n\nExclam\n−30.759\n\n\n\n(22.656)\n\n\nApostro\n−12.302\n\n\n\n(20.174)\n\n\nOtherP\n−14.791\n\n\n\n(20.203)\n\n\nmid_dispute\n0.021\n\n\n\n(0.159)\n\n\nwdi_gdpcapcon2015\n0.000***\n\n\n\n(0.000)\n\n\nwdi_gdpcapgr\n0.012\n\n\n\n(0.031)\n\n\nwdi_pop\n0.000\n\n\n\n(0.000)\n\n\npts_ptss\n−0.285\n\n\n\n(0.212)\n\n\nbmr_dem\n3.787***\n\n\n\n(0.473)\n\n\nkofgi_dr_eg\n−0.156\n\n\n\n(0.307)\n\n\nkofgi_dr_ig\n0.285\n\n\n\n(0.911)\n\n\nkofgi_dr_pg\n0.010\n\n\n\n(0.309)\n\n\nkofgi_dr_sg\n−0.206\n\n\n\n(0.300)\n\n\nwdi_log_gdpcapcon2015\n−0.931*\n\n\n\n(0.373)\n\n\nwdi_log_pop\n−1.365***\n\n\n\n(0.284)\n\n\npolity\n0.396\n\n\n\n(0.358)\n\n\npolity2\n0.109\n\n\n\n(0.287)\n\n\nplty_xrcomp\n1.619***\n\n\n\n(0.403)\n\n\nplty_xropen\n−0.274\n\n\n\n(0.210)\n\n\nplty_xconst\n−0.989***\n\n\n\n(0.261)\n\n\nplty_parreg\n0.297\n\n\n\n(0.279)\n\n\nplty_parcomp\n−0.994***\n\n\n\n(0.219)\n\n\nnavco_num_campaign\n0.646\n\n\n\n(0.472)\n\n\nnavco_campaign\n−1.011\n\n\n\n(0.658)\n\n\nup_num_conflict\n0.144+\n\n\n\n(0.079)\n\n\nup_conflict\n0.090\n\n\n\n(0.383)\n\n\nup_num_war\n−0.205\n\n\n\n(0.188)\n\n\nup_war\n0.589\n\n\n\n(0.542)\n\n\nv2x_polyarchy\n−8.736\n\n\n\n(6.993)\n\n\nv2x_libdem\n17.852+\n\n\n\n(9.112)\n\n\nv2x_freexp_altinf\n−10.215\n\n\n\n(22.267)\n\n\nv2x_frassoc_thick\n20.023***\n\n\n\n(5.353)\n\n\nv2xel_locelec\n−2.467***\n\n\n\n(0.678)\n\n\nv2xel_regelec\n2.273***\n\n\n\n(0.636)\n\n\nv2mecenefm\n3.073***\n\n\n\n(0.535)\n\n\nv2mecrit\n−0.454\n\n\n\n(0.498)\n\n\nv2mefemjrn\n0.092***\n\n\n\n(0.023)\n\n\nv2meharjrn\n0.944**\n\n\n\n(0.361)\n\n\nv2mebias\n0.374\n\n\n\n(0.460)\n\n\nv2mecorrpt\n−0.272\n\n\n\n(0.261)\n\n\nv2meslfcen\n−0.201\n\n\n\n(0.369)\n\n\nv2x_accountability\n4.663**\n\n\n\n(1.714)\n\n\nv2x_horacc\n−0.724\n\n\n\n(0.681)\n\n\nv2x_diagacc\n−6.909**\n\n\n\n(2.274)\n\n\nv2xnp_regcorr\n−10.914**\n\n\n\n(3.705)\n\n\nv2x_civlib\n25.843\n\n\n\n(83.332)\n\n\nv2x_clphy\n−8.202\n\n\n\n(27.502)\n\n\nv2x_clpol\n−42.879\n\n\n\n(28.508)\n\n\nv2x_clpriv\n−4.228\n\n\n\n(27.149)\n\n\nv2x_corr\n31.146***\n\n\n\n(6.097)\n\n\nv2x_pubcorr\n−11.666***\n\n\n\n(2.679)\n\n\nv2jucorrdc\n1.927***\n\n\n\n(0.471)\n\n\nv2x_rule\n−7.827*\n\n\n\n(3.936)\n\n\nv2xcl_acjst\n−2.272\n\n\n\n(1.535)\n\n\nv2xcs_ccsi\n1.947\n\n\n\n(3.536)\n\n\nv2x_freexp\n23.233+\n\n\n\n(13.869)\n\n\nv2xme_altinf\n9.918\n\n\n\n(10.429)\n\n\nv2xedvd_me_cent\n9.479**\n\n\n\n(3.408)\n\n\nht_colonial\n−1.653**\n\n\n\n(0.518)\n\n\nsovereignty\n1.113*\n\n\n\n(0.461)\n\n\nintervention\n0.373\n\n\n\n(0.496)\n\n\nhuman_rights\n0.545\n\n\n\n(0.352)\n\n\nsovereignty_count\n−0.300+\n\n\n\n(0.178)\n\n\nintervention_count\n0.201\n\n\n\n(0.212)\n\n\nhuman_rights_count\n0.086\n\n\n\n(0.091)\n\n\nNum.Obs.\n2828\n\n\nAIC\n909.2\n\n\nBIC\n1979.7\n\n\nLog.Lik.\n−274.593\n\n\nRMSE\n0.16\n\n\n\n + p\n\n\n\n\n\n\n\n\nvisreg(model0, xvar = \"focusfuture\", by = \"ht_colonial\", scale = \"linear\")",
    "crumbs": [
      "Linguistic Analysis",
      "LIWC"
    ]
  },
  {
    "objectID": "rmarkdown/liwc_analysis.html#trial-1-including-wc-wps-period",
    "href": "rmarkdown/liwc_analysis.html#trial-1-including-wc-wps-period",
    "title": "liwc_modeling",
    "section": "Trial 1: Including WC, WPS, Period",
    "text": "Trial 1: Including WC, WPS, Period\n           Type of random forest: classification\n                 Number of trees: 500\nNo. of variables tried at each split: 118\n    OOB estimate of  error rate: 24.28%\nConfusion matrix: 0 1 class.error 0 2563 859 0.2510228 1 784 2561 0.2343797\nConfusion Matrix and Statistics\n     Prediction\nReference 0 1 0 1081 380 1 341 1077\n           Accuracy : 0.7496          \n             95% CI : (0.7333, 0.7653)\nNo Information Rate : 0.5061          \nP-Value [Acc &gt; NIR] : &lt;2e-16          \n                                      \n              Kappa : 0.4992          \n                                      \nMcnemar’s Test P-Value : 0.157\n        Sensitivity : 0.7392          \n        Specificity : 0.7602          \n     Pos Pred Value : 0.7595          \n     Neg Pred Value : 0.7399          \n         Prevalence : 0.5061          \n     Detection Rate : 0.3741          \nDetection Prevalence : 0.4925\nBalanced Accuracy : 0.7497\n   'Positive' Class : 1   \n\nrequire(randomForest) || install.packages(\"randomForest\", dependencies = T)\n\nLoading required package: randomForest\n\n\nrandomForest 4.7-1.1\n\n\nType rfNews() to see new features/changes/bug fixes.\n\n\n\nAttaching package: 'randomForest'\n\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n\n\nThe following object is masked from 'package:ggplot2':\n\n    margin\n\n\n[1] TRUE\n\nlibrary(randomForest)\nlibrary(randomForestExplainer)\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\nset.seed(3)\n\nsplit &lt;- rsample::initial_split(data, prop=0.7, strata=\"dd_democracy\")\ntrainN &lt;- rsample::training(split)\ntrainN$dd_democracy&lt;-factor(trainN$dd_democracy)\ntestN &lt;- rsample::testing(split)\n\ntrainN &lt;- trainN[, !(names(trainN) %in% c(\"ccode_iso\", \"year\", \"session\", \"dd_regime\"))]\ntestN &lt;- testN[, !(names(testN) %in% c(\"ccode_iso\", \"year\", \"session\", \"dd_regime\"))]\n\n# Remove rows with missing values\ntrainN &lt;- na.omit(trainN)\n\n# Fit random forest model after removing missing values\nbag.democracy &lt;- randomForest(dd_democracy ~ ., \n                               data = trainN, \n                               ntree = 500,\n                               mtry = ncol(trainN) - 1,\n                               importance = TRUE)\n\nvarImpPlot(bag.democracy, sort=T, n.var= 25, main= \"Democracy vs. Non-democracy\", pch=16)\n\n\n\n\n\n\n\nbag.RT.pred &lt;- predict(bag.democracy, newdata = testN) \nRT.pred &lt;- predict(bag.democracy, newdata=testN, type=\"class\")\nRT.evlau &lt;- caret::confusionMatrix(as.factor(testN$dd_democracy), \n                                   RT.pred, \n                                   positive = \"1\",\n                                   dnn = c(\"Reference\",\"Prediction\"))\nRT.evlau\n\nConfusion Matrix and Statistics\n\n         Prediction\nReference   0   1\n        0 605  61\n        1 156 247\n                                          \n               Accuracy : 0.797           \n                 95% CI : (0.7716, 0.8207)\n    No Information Rate : 0.7119          \n    P-Value [Acc &gt; NIR] : 1.300e-10       \n                                          \n                  Kappa : 0.5468          \n                                          \n Mcnemar's Test P-Value : 1.758e-10       \n                                          \n            Sensitivity : 0.8019          \n            Specificity : 0.7950          \n         Pos Pred Value : 0.6129          \n         Neg Pred Value : 0.9084          \n             Prevalence : 0.2881          \n         Detection Rate : 0.2311          \n   Detection Prevalence : 0.3770          \n      Balanced Accuracy : 0.7985          \n                                          \n       'Positive' Class : 1               \n                                          \n\n# ROC curve and AUC\n\nRT.pred2 &lt;- predict(bag.democracy, newdata=testN, type=\"prob\")\nroc_RT.tree1 &lt;- roc(as.factor(testN$dd_democracy), RT.pred2[,\"1\"])\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls &lt; cases\n\npar(mfrow=c(1,1))\nplot(roc_RT.tree1, main=\"ROC curve for Random Forest\", \n     col=\"blue\", lwd=2, legacy.axes=FALSE)\ntitle(main = paste('Area under the curve: ',auc(roc_RT.tree1)))\n\n\n\n\n\n\n\n# Generating cross table\nlibrary(gmodels)\n\n\nAttaching package: 'gmodels'\n\n\nThe following object is masked from 'package:pROC':\n\n    ci\n\nCrossTable(testN$dd_democracy, bag.RT.pred,\n           prop.chisq = FALSE, prop.c = FALSE, prop.r = TRUE, prop.t = FALSE,\n           dnn = c('actual default', 'predicted default'))\n\n\n \n   Cell Contents\n|-------------------------|\n|                       N |\n|           N / Row Total |\n|-------------------------|\n\n \nTotal Observations in Table:  1069 \n\n \n               | predicted default \nactual default |         0 |         1 | Row Total | \n---------------|-----------|-----------|-----------|\n             0 |       605 |        61 |       666 | \n               |     0.908 |     0.092 |     0.623 | \n---------------|-----------|-----------|-----------|\n             1 |       155 |       248 |       403 | \n               |     0.385 |     0.615 |     0.377 | \n---------------|-----------|-----------|-----------|\n  Column Total |       760 |       309 |      1069 | \n---------------|-----------|-----------|-----------|\n\n \n\n# Importance matrix\nimportance(bag.democracy) %&gt;%\n  as.data.frame() %&gt;%\n  arrange(desc(MeanDecreaseAccuracy))\n\n                          0            1 MeanDecreaseAccuracy MeanDecreaseGini\nethnicity        34.7917064 23.618035566           42.4607777       78.5595161\nWPS              25.0513744 29.222967389           38.8244931      117.4787371\ni                17.7773110 16.763166849           23.0363131       34.2443257\nwe               10.4580859 21.562038217           22.9052531       56.0279456\nmale             14.6246798 14.626987803           20.7063804       31.0602387\nthey             15.6642350 10.153928165           19.0165016       22.8176096\nverb             16.3543853  6.103892196           18.3657906       20.3678290\nneed              7.8979002 12.815960776           14.3350231       22.6719288\nfocusfuture      12.9661608  4.926417514           13.4641823       13.8453813\narticle           3.7016314 11.295233771           13.3744966       14.1767403\nPeriod            5.8058291  8.224561316           13.2850213       10.2449527\ntime             10.7610679  6.450889491           12.9864994       14.9982175\nadverb           11.8119650  4.057380894           12.2128997       10.4455185\npower             9.8877718  5.746905509           12.1194850       15.5038397\npolite            9.9394488  5.968916733           12.0759685       14.1011288\ndet              11.7385870  1.761796145           11.8952817       13.9155554\nallnone           9.1397656  6.805587687           11.8927098       14.0981042\nDic               7.8441038  7.903836227           11.7986583       11.3248538\ntone_neg          8.2356755  7.507229195           11.3187710       15.9034099\nrelig             8.6550210  6.931306005           11.2550045       10.2823865\nAffect            8.0505054  7.515952151           11.1487771       17.7089834\nmoral             9.8936143  5.131441578           10.7289005       18.2468436\nquantity          4.1339637  9.814907058           10.5975447       11.1673587\nLinguistic        9.6506199  1.688727304           10.0802306        6.6368208\nmemory           10.4417159  1.919303776            9.7751282        6.2300798\ncogproc          10.3161851 -0.667145652            9.6092024        4.9050156\naffiliation       4.4912383  6.828806212            9.6015289        8.2282585\nauxverb           6.9611808  4.310504989            9.3137782        7.3447650\nemotion           8.1194907  5.069811598            9.1835818       13.0418080\nSocial            1.7668213  8.477919617            8.9593438        7.8916596\nadj               9.1760330  1.482117493            8.7683565       11.0102128\nppron             5.8000500  3.900051457            8.6279699        7.0887451\nmoney             7.5070097  3.828540641            8.3860555       11.2077072\nfocuspresent      7.6763060  2.495802702            8.2238433        7.4686195\nshehe             6.6060433  2.226818143            7.9228829        8.3084627\nsocrefs           4.4876674  4.055217624            7.7316702        5.4845267\nAnalytic          4.1558022  5.616154768            7.7245519        6.9337469\nyou               5.0560519  5.594087193            7.6493823        7.3548780\nPhysical          7.6789895  1.217084527            7.6265959        8.4588355\nComma            10.3868493 -1.244156229            7.6115915       10.1706593\nDrives            5.5529927  3.016655630            7.6056900        5.9698507\ndiscrep           6.6025553  3.476979295            7.5823739        7.7018426\nemo_anger        -0.2926704  9.314705998            7.4780064        6.5934105\nachieve           6.3062926  3.334530795            7.4675269        9.7947944\nfocuspast         7.5656308  1.548415930            7.4670572        8.9060059\npronoun           5.0280817  4.177617177            7.4103494        7.4991043\nWC                3.9677281  4.934554412            7.1795621        8.9467025\nprep              1.1226700  7.227390519            7.0711942        7.8558023\ncomm              4.5946916  4.975932656            6.8761279        8.8810005\nAuthentic         5.5478525  3.959199007            6.8135246        8.9817442\nlack              5.2552912  4.232632046            6.7488711        7.9664449\nnegate            5.3253283  3.194597321            6.5077044        7.3548928\nemo_pos           7.0816055 -0.149888347            6.4162339        7.9119182\nconj              4.6526934  3.844373480            6.1870311       10.4237781\nassent            5.3326558  1.974356158            5.7712462        2.4079482\nCulture           6.2456131 -0.845290518            5.6361105        5.4824504\ntentat            4.5598099  2.778578110            5.6145569        6.2785400\nBigWords          4.8777215  1.709329538            5.5573084        7.7804794\nPerception        5.9827290  0.734798824            5.5493532        7.1093676\nfatigue           6.5806132 -0.459459822            5.5133761        2.4909702\nfunction_feature  5.3446783  0.873196339            5.3949762        3.9520920\nwork              3.5411092  3.614123115            5.3839138        8.4399187\nClout             3.6942506  2.715491859            5.3788207        6.9773502\nconflict          5.6970725  0.457689830            5.3015578        8.2917547\nspace             5.3885974  1.360422316            5.2424190        6.3508962\nemo_neg           5.2085596  1.110133696            5.2240502        5.8085978\nAllPunc           2.3017443  4.614465550            5.2064664        7.7559629\nfulfill           3.9052700  3.363080555            5.1813554        8.1022650\nsocbehav          5.2897832  0.268555676            5.1544692        7.8104123\nLifestyle         2.8445573  3.747697743            5.1454165        7.0241750\ncertitude         5.4993802  0.509925444            5.0207650        7.5444985\nsubstances        6.7509674 -1.454953478            4.9414764        2.0978530\nnumber            3.7766611  3.048806809            4.7509247        9.4734336\ndiffer            5.6052182 -1.276059262            4.7166807        5.1548234\nTone              4.3113107  0.989480713            4.4300287        4.7327871\nCognition         4.8541621 -0.639641997            4.4297645        3.1972256\nallure            4.0190676  1.189958570            4.3664821        5.2778676\nfamily            2.1233308  3.975888872            4.3493918        4.7710521\nprosocial         4.8702376  0.608784902            4.2854649        7.2152224\ntech              5.1215107  0.624686639            4.2400159        6.1135640\ncause             2.7100457  2.936882282            4.1560196        8.1021793\nrisk              4.8666301 -0.001134316            4.0798209        7.9597237\nfemale            3.7171955  2.074053839            4.0294940        4.7608567\nattention         5.0083440  0.039162187            4.0179439        8.0800120\nreward            3.9650809  1.161701926            3.9660790        7.1360887\ntone_pos          4.6475167 -0.453545642            3.6328402        4.6269069\nswear             0.3323587  4.540937044            3.5871125        1.5734179\nQMark             4.1170003  0.576364020            3.5834906        3.8860569\ninsight           4.1416737  0.320521472            3.5011144        6.2768947\ncuriosity         4.2838757 -0.015463978            3.4098458        6.6147032\nipron             4.1794850 -0.470158199            3.3787793        6.0519787\nApostro           4.6278368 -0.695027099            3.3041372        6.5205722\nsexual            3.9286442 -1.069091038            3.2362826        2.5247480\nemo_sad           1.9627492  2.321104810            2.9256984        4.2676382\nacquire           6.2587081 -2.643251890            2.8634293        6.8700335\ndeath             3.2372160  0.293236185            2.6304455        4.4899465\nfeeling           2.2506747  1.256292790            2.6159428        5.6306169\nleisure           1.4128770  2.030624099            2.3871769        5.7087389\npolitic           1.6593818  1.044108708            2.0477589        5.3803381\nauditory          4.2325000 -2.069902432            1.9969011        4.5313082\nmotion            2.5446680 -0.112615189            1.9225667        9.0447016\nnetspeak          0.5143218  2.267037162            1.9212336        1.2843718\nillness           2.2470956  0.234508604            1.9002646        4.9034410\nwellness          1.3252300  1.298076199            1.8821601        5.9490753\nwant              1.9925829  0.422594166            1.8792330        5.7850034\nemo_anx           2.3102533 -0.056727202            1.8378978        4.6765666\nhome              2.4988622 -0.303814821            1.7980510        5.0908091\neng               2.0622645 -0.385792893            1.6466003        0.2915386\nExclam            0.8360326  0.698493534            1.0715373        0.9604781\nhealth            2.7149871 -2.448789652            0.6875601        5.7948462\nOtherP            0.9750182 -0.254275057            0.5326019        7.6909613\nfood              0.8238992 -0.204139389            0.4308842        3.2985736\nvisual            2.0912580 -1.872104164            0.4068045        7.0096613\nSegment           0.0000000  0.000000000            0.0000000        0.0000000\nfiller            0.0000000  0.000000000            0.0000000        0.0000000\nfriend           -1.2073207  0.813946011           -0.3296354        2.5932736\nmental            1.9918694 -2.392774520           -0.3691540        1.8812977\nConversation      0.5686409 -1.548446297           -0.5412107        1.7671086\nnonflu           -0.9805003  0.328623786           -0.6017976        0.7875402",
    "crumbs": [
      "Linguistic Analysis",
      "LIWC"
    ]
  },
  {
    "objectID": "rmarkdown/liwc_analysis.html#trial-2-excluding-wc-wps-and-period",
    "href": "rmarkdown/liwc_analysis.html#trial-2-excluding-wc-wps-and-period",
    "title": "liwc_modeling",
    "section": "Trial 2: excluding WC, WPS, and Period",
    "text": "Trial 2: excluding WC, WPS, and Period\nOOB estimate of error rate slightly increased around 0.5 percentage point(%p) after removing WC, WPS, and Period. Prediction accuracy against testN slightly dropped to 0.74 accordingly.\nType of random forest: classification Number of trees: 500 No. of variables tried at each split: 115\n    OOB estimate of  error rate: 24.78%\n    \n    \nConfusion Matrix and Statistics\n     Prediction\nReference 0 1 0 1050 411 1 335 1083\n           Accuracy : 0.7409          \n             95% CI : (0.7245, 0.7568)\nNo Information Rate : 0.5189          \nP-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                      \n              Kappa : 0.4821          \n                                      \nMcnemar’s Test P-Value : 0.006034\n        Sensitivity : 0.7249          \n        Specificity : 0.7581          \n     Pos Pred Value : 0.7638          \n     Neg Pred Value : 0.7187          \n         Prevalence : 0.5189          \n     Detection Rate : 0.3762          \nDetection Prevalence : 0.4925\nBalanced Accuracy : 0.7415\n   'Positive' Class : 1   \n   \n\ntrainN &lt;- trainN[, !(names(trainN) %in% c(\"ccode_iso\", \"year\", \"session\", \"dd_regime\", \"WC\", \"WPS\", \"Period\"))]\ntestN &lt;- testN[, !(names(testN) %in% c(\"ccode_iso\", \"year\", \"session\", \"dd_regime\", \"WC\", \"WPS\", \"Period\"))]\n\n\n# Remove rows with missing values\ntrainN &lt;- na.omit(trainN)\n\n# Fit random forest model after removing missing values\nbag.democracy2 &lt;- randomForest(dd_democracy ~ ., \n                               data = trainN, \n                               ntree = 500,\n                               mtry = ncol(trainN) - 1,\n                               importance = TRUE)\n\nvarImpPlot(bag.democracy2, sort=T, n.var= 25, main= \"Democracy vs. Non-democracy\", pch=16)\n\n\n\n\n\n\n\nbag.RT.pred2 &lt;- predict(bag.democracy2, newdata = testN) \n\nRT.pred2 &lt;- predict(bag.democracy2, newdata=testN, type=\"class\")\n\nRT.evlau2 &lt;- caret::confusionMatrix(as.factor(testN$dd_democracy), \n                                   RT.pred2, \n                                   positive = \"1\",\n                                   dnn = c(\"Reference\",\"Prediction\"))\nRT.evlau2\n\nConfusion Matrix and Statistics\n\n         Prediction\nReference   0   1\n        0 597  69\n        1 163 240\n                                         \n               Accuracy : 0.783          \n                 95% CI : (0.757, 0.8073)\n    No Information Rate : 0.7109         \n    P-Value [Acc &gt; NIR] : 5.677e-08      \n                                         \n                  Kappa : 0.5157         \n                                         \n Mcnemar's Test P-Value : 1.023e-09      \n                                         \n            Sensitivity : 0.7767         \n            Specificity : 0.7855         \n         Pos Pred Value : 0.5955         \n         Neg Pred Value : 0.8964         \n             Prevalence : 0.2891         \n         Detection Rate : 0.2245         \n   Detection Prevalence : 0.3770         \n      Balanced Accuracy : 0.7811         \n                                         \n       'Positive' Class : 1              \n                                         \n\n# Generating cross table\nlibrary(gmodels)\nCrossTable(testN$dd_democracy, bag.RT.pred2,\n           prop.chisq = FALSE, prop.c = FALSE, prop.r = TRUE, prop.t = FALSE,\n           dnn = c('actual default', 'predicted default'))\n\n\n \n   Cell Contents\n|-------------------------|\n|                       N |\n|           N / Row Total |\n|-------------------------|\n\n \nTotal Observations in Table:  1069 \n\n \n               | predicted default \nactual default |         0 |         1 | Row Total | \n---------------|-----------|-----------|-----------|\n             0 |       597 |        69 |       666 | \n               |     0.896 |     0.104 |     0.623 | \n---------------|-----------|-----------|-----------|\n             1 |       163 |       240 |       403 | \n               |     0.404 |     0.596 |     0.377 | \n---------------|-----------|-----------|-----------|\n  Column Total |       760 |       309 |      1069 | \n---------------|-----------|-----------|-----------|\n\n \n\n# Importance matrix\nimportance(bag.democracy2) %&gt;%\n  as.data.frame() %&gt;%\n  arrange(desc(MeanDecreaseAccuracy))\n\n                          0           1 MeanDecreaseAccuracy MeanDecreaseGini\nethnicity        28.3775932 20.56828058         34.023022781       83.9190944\nwe               17.0714428 28.99402449         30.330521888       94.3457069\ni                21.4029465 16.38010361         27.060335942       44.3377332\nmale             20.8928133 14.50835224         25.439376270       46.2619983\nverb             20.1130392  7.92515269         22.562869836       35.8703924\nthey             14.7850023 14.07924246         19.979545454       27.7090898\nneed              8.8997558 11.03021549         14.621440149       21.1588397\npower            11.5739747  9.58945555         14.613461634       18.0296814\ndet              12.4481302  6.90265615         14.021971242       22.5332930\nadverb           12.4662627  2.25190069         13.479398062        9.1722537\ntime             11.9698035  6.09082828         12.781995527       19.2901750\nquantity          7.6760765  8.21459946         12.169716295       12.9519681\narticle           1.9670480 12.29740172         12.110008510       17.0113462\nmoral             9.3075112  6.22906529         11.256133813       18.0195944\nDic               7.9051468  6.53745961         11.224844557       12.6663827\nauxverb          10.2410803  3.18245105         11.050330302       10.7039353\nemotion           8.5822079  5.99436477         11.049151621       16.7281577\nallnone           8.1461200  7.57880121         10.973686966       13.9370565\naffiliation       2.5406922  7.95778607         10.812157656        9.1128484\nmoney             9.2799018  4.82398292         10.706129572       12.5221106\npolite            9.3823126  3.47368287         10.309495009       12.4003053\nfocusfuture       9.7477094  3.97549958         10.161274585       13.8147287\nSocial            3.6581788  7.70468960         10.156276807        8.7120940\ncogproc          10.3565755 -1.62221310          9.882839854        5.1035025\nAffect            8.1256514  4.80296753          9.829455936       12.3493879\ntone_neg          6.6657509  5.79094444          9.646386908       11.3481851\nrelig             6.5940003  7.24851457          9.342372812        8.7788639\nfocuspresent      7.0212786  3.88340220          8.930637350        8.5212852\nachieve           7.6340704  4.34980622          8.863196037       11.0449621\nPhysical          7.6129487  4.35783226          8.778109277        9.7932935\nshehe             8.5276868 -0.95434232          8.754858222        7.9344222\nLinguistic        8.3617084  0.16065106          8.661609228        5.4995651\nAllPunc           4.1653176  7.13404568          8.352842706       10.1761305\nfocuspast         9.6853402 -1.19267296          8.229588698       10.7024027\nsocrefs           2.0468559  6.05462133          7.910039623        5.6532882\ndiscrep           5.2028270  3.64738425          7.235024378        9.5309549\nppron             4.3429900  2.68558083          7.214201650        6.9581831\nDrives            7.2004063 -0.38083394          6.904741565        6.2867233\nComma             9.4074862 -1.24949606          6.899001706       10.7522995\nadj               7.6458398  0.40382304          6.819750676        9.4879264\nprep              3.1328937  6.13900772          6.789093700       10.9403892\nemo_anger         0.2023965  8.89024295          6.516024677        8.1572183\nAnalytic          3.3742226  3.74964499          6.211893911        6.1094224\nfemale            5.9140645  3.47123062          6.161533951        6.6942781\nnumber            3.1523207  5.43394857          6.119024147       10.7010767\nmemory            7.0775681  0.54572561          6.107860442        6.2127003\nLifestyle         6.4852761  0.64886602          6.000664657        7.5151856\nprosocial         5.6285655  2.11391252          5.889576611        7.8749579\nconj              6.1814157  1.81212237          5.888018815       12.3011830\nyou               1.5621840  6.08441940          5.869830188        7.2722276\nwork              4.7969810  2.50996795          5.798397476        9.0873984\nnegate            5.1133841  1.78005878          5.794192058        6.1598662\nassent            6.2230789 -0.04543403          5.755463289        2.2239201\nAuthentic         4.7474217  2.74251954          5.749255661        8.9741607\nfatigue           6.6245238 -0.36812094          5.657748259        2.9246871\nfunction_feature  6.2140681 -0.40905015          5.611003991        5.4824916\nfamily            3.0724586  5.43214706          5.530799798        5.3507025\ntentat            7.4021366 -1.11019204          5.455634304        7.6724741\nhealth            3.4837654  3.35116013          5.409942808        7.0677093\nClout             1.2718666  4.52870459          5.305084857        6.3237453\npronoun           2.6606624  3.26765564          5.184891519        4.7929975\nlack              3.5091449  3.98373871          5.128034769        8.2500333\nCulture           5.7871211 -0.71417908          5.047361521        5.4038038\nconflict          4.6658908  0.47116835          4.811976512        6.0963223\nreward            4.8405817  1.15374265          4.709355344        7.1855914\nBigWords          2.6227624  2.95762995          4.629604154        7.1887683\nemo_pos           5.1165711 -0.44206142          4.473962987        7.2207572\nCognition         4.2197048  0.27750558          4.469726133        3.6252070\nsocbehav          4.3382351  1.17222328          4.117521614        9.1489537\nrisk              5.4244840  0.10406572          4.053000270        9.2407712\nattention         5.3789507 -0.86036516          3.871305881        9.9631317\ndiffer            5.3523251 -1.71354643          3.839495255        5.4959208\nipron             3.8792686  0.79994120          3.815146560        5.9806932\nTone              2.0625694  2.61617546          3.788826208        5.4990256\neng               3.4510904  1.28341984          3.718626568        0.3563554\nsexual            3.6480020  0.16162088          3.523308794        3.0169607\ncomm              3.5515756  1.16618554          3.478747848        9.5919055\nsubstances        4.9181353 -0.88861159          3.410048793        1.9609726\nillness           3.0724653  1.46136579          3.329267247        5.8536061\ncause             2.3368925  1.99786595          3.169480938        8.4488230\nemo_neg           2.1298918  1.89037365          3.168114788        5.7253984\nmotion            3.3911542  0.88930727          3.112146732        8.5987718\ncertitude         3.4079854  0.42061211          3.084806436        6.8084673\ntech              4.6004141 -1.00394417          3.049295850        6.6198452\nallure            3.1196568  0.15968936          2.909101124        6.0599257\ntone_pos          5.1625868 -2.34974148          2.861472966        5.1926282\ninsight           4.3581908 -0.59813696          2.858022337        6.6768228\nfulfill           1.2781543  2.98629648          2.840950552        8.8119188\nvisual            3.0316712  0.62504708          2.739836388        7.3886031\ndeath             2.4752948  1.05659293          2.514193293        5.4271897\nOtherP            1.7090517  1.60767312          2.396609603        8.5759981\nwellness          1.5360896  1.84831899          2.363486971        5.3710403\nExclam            1.7984139  1.14313419          2.355838146        1.1545984\ncuriosity         3.8285528 -1.36169409          2.212997048        7.1470784\nspace             2.5307158  0.19014917          2.154304892        6.5070929\nleisure           1.9887142  0.65355911          2.051410160        6.0493777\nPerception        2.7964590 -0.58604302          1.988270181        6.4134125\npolitic           3.4157055 -1.42844069          1.941206928        5.9185777\nswear            -0.1472099  2.27703744          1.724171786        1.7710997\nfriend            0.9377147  1.09635844          1.534737705        2.7548501\nemo_sad           0.5533801  1.68412081          1.532009559        5.0232946\nQMark             3.1321619 -1.58401225          1.424708243        3.4929639\nfeeling           1.2546076  0.40711091          1.307239144        6.2292329\nwant              3.6152487 -2.45305276          1.152822582        6.3553738\nemo_anx           1.6024555 -0.37070671          1.062829934        5.5725226\nhome             -0.3594807  1.65688824          0.961923977        4.5701217\nApostro           3.0144380 -1.67338763          0.958885996        6.8387319\nauditory          2.0236715 -1.32244583          0.884777034        4.4335526\nConversation      1.5949578 -0.71120783          0.858642617        2.0381360\nacquire           2.3865320 -1.59194995          0.652776936        7.4854121\nnetspeak          0.2761992  0.10168422          0.270342779        1.3274882\nfood              0.8131257 -1.02632356          0.004442805        3.9534837\nSegment           0.0000000  0.00000000          0.000000000        0.0000000\nfiller            0.0000000  0.00000000          0.000000000        0.0000000\nnonflu           -0.2685232  0.14825508         -0.124375824        0.8403310\nmental           -0.3300554 -0.83674471         -0.815727792        2.3471704",
    "crumbs": [
      "Linguistic Analysis",
      "LIWC"
    ]
  }
]