[
  {
    "objectID": "jupyter_notebook/functions_for_bert.html",
    "href": "jupyter_notebook/functions_for_bert.html",
    "title": "BERT Functions",
    "section": "",
    "text": "BERT Functions\nI define two functions to run Bert models. First part processes a single text document into a format that is recognizable by BERT. The second part uses the tokenized text to generate embedding values using pre-trained BERT models.\n\nfrom transformers import BertModel, BertTokenizer, AutoTokenizer\nimport numpy as np\nimport streamlit as st\nimport re\nimport pandas as pd\nfrom datetime import datetime\nimport nltk\nimport torch\n\n\nmodel = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\ntokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n\n\n#input is \"light.csv\" which does not include stop words. \ndf = pd.read_csv('../../../data/processed/paragraph.csv')\n# Filter\ntimestamps = df.year.to_list()\ntexts = df.text.to_list()\ntext = texts[1]\n\n\ndf.head(1)\n\n\n\n\n\n\n\n\nUnnamed: 0\nccode_iso\nsession\nyear\nparagraph_index\ntext\n\n\n\n\n0\n1\nAFG\n7\n1952\n1\nI consider it a great honour and privilege to ...\n\n\n\n\n\n\n\n\nprint(type(text))\n\n&lt;class 'str'&gt;\n\n\n\n\nDefine functions\n\ndef bert_preprocess(text):\n    \"\"\"\n    Preprocesses a document into a BERT-recognizable format \n    Input: text in a string format\n    output: three objects ready to be used for Bert modeling \n        marked_text (list)\n        indexed_tokens(list)\n        attention_mask(list)\n    \n    \"\"\"\n    # Tokenize the text\n    tokenized_text = tokenizer.tokenize(text)\n    truncate_length = len(tokenized_text) - 512 + 2  # +2 to account for [CLS] and [SEP]\n    \n    # Truncate the beginning and end of the text\n    truncated_text = tokenized_text[truncate_length//2 : -truncate_length//2]\n    \n    # Add padding\n    \n    # Add special tokens [CLS] and [SEP], convert tokens to ids, and create attention mask\n    marked_text = [\"[CLS] \"] + truncated_text + [\" [SEP]\"]\n    indexed_tokens = tokenizer.convert_tokens_to_ids(marked_text)\n    attention_mask = [1] * len(indexed_tokens)\n\n    # Pad sequences to max_seq_length\n    if len(indexed_tokens) &lt; 512:\n        indexed_tokens.append(0)\n        attention_mask.append(0)\n    \n    return marked_text, indexed_tokens, attention_mask\n\n\nmarked_text, indexed_tokens, attention_mask = bert_preprocess(text)\n\n\nhelp(get_bert_embeddings)\n\nHelp on function get_bert_embeddings in module __main__:\n\nget_bert_embeddings(marked_text, indexed_tokens, attention_mask)\n    input: processed text\n    output: dataframe of embedding weights for each token \n        ex) dimension of 512*768 where row represents token, column represents bert features\n\n\n\n\ndef get_bert_embeddings(marked_text, indexed_tokens, attention_mask):\n    \"\"\"\n    Generates embedding values for tokenized text \n    input: processed text, indexed_tokens and attention mask (all in list format)\n    output: dataframe of embedding weights for each token \n        ex) dimension of 512*768 where row represents token, column represents bert features\n    \n    \"\"\"\n    # Convert lists to PyTorch tensors\n    tokens_tensors = torch.tensor([indexed_tokens])\n    attention_masks = torch.tensor([attention_mask])\n    \n    with torch.no_grad():\n        #Run the embedding\n        outputs = model(input_ids=tokens_tensors.view(-1, tokens_tensors.size(-1)), \n                        attention_mask=attention_masks.view(-1, attention_masks.size(-1)))\n\n        # Extract the hidden states \n        hidden_states = outputs[2][0].squeeze().numpy()\n        \n        # Convert to data frame\n        pd_words = pd.Series(marked_text, name='term')\n        df_outputs = pd.DataFrame(hidden_states)\n        df_outputs['term'] = pd_words\n        \n        # Move 'term' column to the first position\n        df_outputs = df_outputs[['term'] + [col for col in df_outputs.columns if col != 'term']]\n        \n        # Remove duplicate tokens by averaging them out\n        df_outputs_embedding = df_outputs.groupby(['term']).mean()\n    return df_outputs_embedding\n\n\nget_bert_embeddings(marked_text, indexed_tokens, attention_mask)\n\n\n\n\n\n\n\n\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n...\n758\n759\n760\n761\n762\n763\n764\n765\n766\n767\n\n\nterm\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[SEP]\n-0.599731\n-0.287527\n0.995737\n-0.067600\n-0.116662\n-0.319243\n-0.035646\n-0.550722\n-0.154269\n0.226906\n...\n0.433558\n0.360281\n0.753348\n-1.155800\n0.198939\n0.126193\n0.058285\n0.035218\n-0.225301\n-0.376395\n\n\n##s\n-0.082928\n0.064610\n0.062934\n1.201868\n0.416490\n-0.351008\n-0.419693\n0.793464\n-0.682201\n-0.435875\n...\n-1.640653\n-0.082774\n1.440754\n0.477181\n0.555801\n0.517778\n0.029644\n0.167330\n-0.804072\n1.100950\n\n\n,\n0.238827\n-0.499530\n-0.229385\n-0.420359\n0.382101\n-0.133325\n-0.423249\n-0.133761\n0.079275\n-0.810453\n...\n-0.476354\n0.310680\n-0.071447\n-0.350534\n-0.166876\n-0.152760\n0.157087\n0.182910\n-0.305537\n0.119838\n\n\n-\n0.211686\n-0.337158\n-0.282966\n-0.379349\n0.213550\n-0.254544\n-0.361127\n-0.094978\n0.072562\n-0.825429\n...\n-0.457777\n0.271165\n0.238502\n-0.122299\n-0.090638\n-0.070707\n0.017792\n-0.049120\n-0.269647\n0.226714\n\n\n.\n0.117108\n-0.388444\n-0.088623\n0.064858\n0.523230\n-0.428734\n-0.267266\n-0.420127\n0.190312\n-0.766927\n...\n-0.490892\n0.354983\n-0.355035\n-0.418002\n0.253672\n0.086620\n0.108094\n-0.150912\n-0.198612\n0.161442\n\n\nIn\n1.179606\n0.055646\n0.182922\n1.080442\n0.191964\n-0.443555\n-0.347383\n0.757875\n-0.356111\n-1.096234\n...\n0.154227\n0.468894\n0.522242\n-0.500889\n0.947098\n1.150616\n-0.767531\n-0.148597\n-0.223548\n0.134304\n\n\nNations\n0.006905\n-0.580956\n0.575177\n-1.220215\n0.371888\n-0.279317\n0.700901\n-0.903072\n0.631587\n-0.739470\n...\n0.495864\n0.132003\n0.067810\n0.293461\n0.424441\n0.552663\n0.318386\n-0.620372\n-0.583365\n0.048380\n\n\nUnited\n-0.077556\n-0.105724\n1.057649\n-0.423865\n0.314821\n-0.185792\n-0.714371\n-0.607652\n-0.070977\n0.103325\n...\n-0.704180\n-1.008595\n-0.426895\n-0.018947\n0.567454\n0.483050\n-0.180623\n-0.287286\n-0.556010\n0.511452\n\n\n[CLS]\n-0.118897\n-0.518255\n0.159338\n-0.461482\n-0.003488\n-0.453042\n-0.212884\n-0.229699\n-0.063944\n-0.421272\n...\n0.242429\n0.009379\n0.467546\n-0.957577\n0.114305\n-0.369990\n0.035248\n0.089144\n-0.146707\n-0.127492\n\n\naccomplish\n-0.085958\n0.289747\n0.502433\n-0.699373\n-0.112547\n0.115439\n1.011047\n-0.570650\n-0.124616\n-0.372738\n...\n-1.153663\n-0.272904\n0.580479\n0.201596\n-0.194586\n-0.872371\n-0.358961\n0.039148\n0.101910\n-0.169740\n\n\nacts\n-0.178121\n0.666130\n0.413916\n0.099232\n-1.034455\n-0.040334\n-0.048890\n-0.098929\n-0.145200\n0.480938\n...\n-1.342113\n0.323047\n0.763901\n-1.770176\n0.986050\n-0.538208\n-0.744755\n0.057135\n-0.445161\n-0.774442\n\n\naid\n-0.427848\n0.147286\n0.013369\n0.471762\n0.168422\n0.895970\n0.872069\n1.716045\n0.837368\n0.494484\n...\n-0.787848\n-0.445969\n0.358512\n0.965379\n0.365942\n0.054571\n-0.555102\n-0.860554\n-0.171662\n-1.067538\n\n\naims\n1.024410\n-0.256186\n-0.053223\n0.638275\n-0.077131\n-0.311400\n-0.234701\n-0.026557\n0.915609\n-0.596711\n...\n-0.522890\n1.130598\n-0.809434\n-0.718155\n-0.150897\n-0.814818\n-0.124106\n-1.064612\n-0.574141\n-0.703143\n\n\nall\n-0.002165\n0.033546\n0.609011\n-0.239792\n-0.932221\n-1.037787\n0.136487\n-0.882456\n0.342895\n-0.798731\n...\n0.239174\n-0.662943\n0.205603\n0.161089\n-0.176249\n-0.105027\n0.036648\n0.276853\n0.527183\n-0.216994\n\n\nand\n0.685023\n0.240559\n-0.555069\n-0.011118\n0.690408\n0.024725\n-0.583992\n-0.181338\n-0.816213\n0.622959\n...\n-0.739703\n0.255513\n0.252658\n-0.401268\n0.020371\n0.737326\n0.633780\n-0.291272\n-0.483794\n-0.894787\n\n\nareas\n0.720950\n-0.746471\n0.160797\n-0.725814\n1.154829\n-0.101660\n-0.124824\n-0.682128\n-0.094830\n0.434859\n...\n-0.126514\n0.163580\n0.774643\n0.072612\n0.070189\n0.888373\n0.193730\n0.033260\n0.078655\n0.414108\n\n\nas\n-0.917634\n0.064711\n-0.368008\n0.218496\n1.246304\n-0.059035\n-1.098246\n0.450588\n-1.106012\n-1.061205\n...\n-0.457125\n-0.102798\n0.220228\n-0.558394\n-0.207785\n0.430128\n-1.262651\n0.324153\n-0.113458\n0.350910\n\n\nassistance\n-0.678422\n0.172338\n0.265142\n0.258749\n-0.105260\n-0.331368\n-0.350325\n0.263004\n-0.668104\n-0.555148\n...\n-0.475693\n0.409995\n0.346237\n0.555776\n0.440133\n-0.523475\n0.134694\n0.275381\n-0.253818\n0.210988\n\n\ncoincide\n-0.170578\n-0.268886\n-0.115447\n-0.694355\n0.483255\n-0.280104\n-0.640158\n0.034518\n-0.001312\n0.433044\n...\n-0.380226\n-0.208592\n-0.748574\n-0.197001\n0.404674\n-0.318124\n-0.521167\n0.667394\n-0.002012\n1.150480\n\n\ncollective\n0.151802\n0.762978\n-0.005754\n0.526812\n0.764982\n0.812513\n-0.570761\n-0.021987\n-1.306559\n-0.586478\n...\n-0.281096\n-1.654515\n-0.409773\n-0.740668\n0.533563\n-0.904656\n0.133838\n-0.766242\n0.390741\n-0.584280\n\n\nconscience\n0.158133\n-0.274482\n-0.492211\n-0.170320\n0.652437\n-0.445447\n0.168138\n-0.694122\n-0.364806\n-1.202534\n...\n-0.850401\n-0.854405\n0.362089\n0.396198\n0.172970\n-0.543768\n-1.138113\n0.421941\n1.142612\n1.083518\n\n\ncultural\n-1.082594\n-0.155604\n0.376953\n-0.332056\n-0.495655\n-1.082139\n0.782310\n-0.506714\n0.033708\n0.338000\n...\n0.613047\n0.565934\n-1.216563\n0.057687\n-0.932211\n-0.200133\n-0.734939\n0.179817\n-0.215364\n-0.216755\n\n\ndeveloped\n-0.195352\n0.150783\n0.080199\n-0.162700\n0.360601\n0.163544\n-0.581970\n0.052141\n0.185778\n-0.233883\n...\n-1.082397\n0.500910\n0.256611\n-0.607807\n-0.145842\n0.529889\n0.446537\n0.195365\n-0.643610\n-0.130024\n\n\ndevelopment\n0.298387\n0.496667\n-0.434238\n0.093009\n-1.293615\n0.209092\n-0.368899\n0.919280\n0.138753\n-0.650476\n...\n-0.645376\n1.387810\n0.642955\n0.327757\n-0.424770\n-0.255853\n0.202628\n0.501966\n-0.376638\n-0.267928\n\n\nduties\n-0.651811\n-0.242606\n0.490167\n-0.137662\n0.505857\n-0.002086\n1.298450\n0.396070\n1.254041\n-0.024695\n...\n0.302751\n-0.295479\n-0.401752\n-0.347428\n-0.645984\n-0.070883\n-1.304861\n-0.363276\n-0.646936\n-1.105535\n\n\neconomic\n0.327582\n0.387518\n-0.703620\n0.579996\n0.298967\n0.924665\n0.373069\n-0.637522\n0.973225\n0.572886\n...\n0.214301\n0.598506\n0.876789\n0.094422\n0.311424\n-0.415416\n-0.762125\n0.453513\n0.134451\n-0.050874\n\n\nends\n-0.546396\n-0.359361\n0.212410\n0.277001\n0.106774\n0.592411\n-0.247585\n-0.792451\n-0.884770\n0.545342\n...\n-0.271307\n-0.330248\n0.591369\n0.783333\n1.241485\n-0.296724\n0.078918\n0.412234\n0.387542\n0.192228\n\n\nfor\n-0.253029\n-0.404490\n-0.261728\n0.038780\n0.154741\n0.588547\n-1.170278\n-0.019293\n0.076067\n-1.264595\n...\n-0.787064\n-0.461386\n-0.638114\n-0.482141\n-0.344258\n-0.054569\n0.378593\n-0.465482\n-0.611659\n0.433159\n\n\nforward\n-0.207178\n0.236094\n-0.957996\n-0.357690\n0.334218\n-0.413327\n-0.956618\n-0.011278\n-0.408511\n-0.037497\n...\n-1.214147\n-0.303270\n0.135196\n0.555519\n0.122476\n0.240908\n-0.056521\n0.050130\n-0.211742\n0.378766\n\n\nguide\n-1.178150\n0.731618\n-0.593804\n0.415418\n1.651968\n-0.073628\n0.057820\n-0.396742\n-0.996873\n0.429075\n...\n0.614620\n-0.451440\n-1.288784\n-0.389848\n0.017629\n-0.483427\n-0.484336\n0.149367\n0.323914\n-1.239273\n\n\nhappily\n-0.552708\n0.431273\n-0.276702\n-0.626600\n1.248792\n-0.940124\n-0.367457\n-0.736995\n0.878078\n0.467198\n...\n0.395383\n-0.414090\n-0.134464\n-0.228733\n-0.090979\n0.121471\n0.091699\n-0.064050\n-0.222706\n0.177931\n\n\nin\n-0.825479\n-1.051559\n0.758063\n0.673075\n0.240419\n0.115155\n-0.920780\n0.137270\n1.564308\n-0.329897\n...\n-0.943635\n0.426585\n-0.385542\n-0.110009\n-1.135049\n-0.032381\n-0.399695\n0.427312\n0.118642\n0.217453\n\n\ninterest\n0.087404\n-0.640190\n-0.453728\n-0.850574\n-0.157392\n-0.533750\n0.637173\n-0.608730\n-0.633894\n0.933405\n...\n0.899409\n1.313719\n0.314493\n0.620090\n-0.622023\n0.070112\n-1.821788\n-0.131984\n-0.347964\n-0.195112\n\n\nits\n-0.217026\n0.894963\n-0.105397\n-0.401083\n-0.738265\n-0.480244\n-0.346089\n-0.352199\n1.088866\n-0.914263\n...\n-0.941486\n0.522719\n0.290851\n0.399336\n-0.462239\n-0.174071\n-0.092375\n0.078811\n0.854677\n-0.169473\n\n\nmoral\n0.619293\n0.499217\n0.249499\n-0.751159\n0.466876\n-0.062412\n-0.184458\n-0.660417\n0.652479\n-1.639679\n...\n-0.382880\n0.017941\n0.048614\n-0.491065\n0.557178\n1.361697\n0.181574\n-0.451610\n0.301997\n-0.267717\n\n\nmust\n-0.157701\n0.589252\n0.273769\n0.857760\n0.567033\n0.108004\n-1.062661\n-1.089537\n-0.240025\n-0.304565\n...\n0.769697\n-0.041358\n-0.410516\n0.544890\n-0.466517\n-1.122368\n0.304115\n0.411068\n0.301097\n0.433811\n\n\nobjectives\n-0.875071\n0.340940\n-0.162661\n0.404240\n0.205024\n-0.591867\n0.305278\n0.519380\n0.144190\n-0.521769\n...\n-0.237458\n-0.047777\n0.328942\n-1.136463\n0.665098\n0.725972\n0.299084\n-0.483213\n-0.158996\n-0.867711\n\n\nof\n-0.327949\n-0.544503\n-0.092067\n-1.195621\n0.039030\n-1.281222\n-0.414859\n0.070955\n-0.199553\n-1.428178\n...\n-0.035053\n0.183135\n0.080120\n-0.322540\n-0.468436\n0.623744\n0.315495\n0.084182\n0.077692\n0.203555\n\n\norder\n-0.067636\n-1.451491\n0.146754\n-0.419711\n0.023377\n-0.810850\n-0.734983\n-0.020393\n-0.560763\n0.204884\n...\n-0.109579\n0.385012\n-0.002484\n-0.126181\n-0.709134\n0.109215\n1.085052\n0.454821\n0.048261\n0.162490\n\n\npeoples\n-0.221793\n-0.247048\n-0.341812\n0.627216\n1.513762\n-0.743124\n-0.456467\n-1.155934\n0.653813\n-0.737646\n...\n0.766392\n-0.728573\n-0.624886\n0.481552\n0.536343\n-0.368652\n0.979576\n0.851340\n-0.597788\n0.720032\n\n\nphases\n-0.914526\n0.031760\n-0.057205\n-0.529099\n0.335894\n-0.689959\n-0.019860\n0.153372\n0.436006\n-0.038952\n...\n-0.668004\n0.173632\n-0.416013\n0.557431\n-0.360914\n-0.490024\n-0.671597\n0.189420\n0.384801\n-0.988437\n\n\npractical\n0.497227\n0.944226\n-0.767903\n-0.117738\n-0.066879\n0.199990\n0.709391\n0.005245\n0.146205\n-0.415131\n...\n0.073728\n-0.115236\n-0.118528\n0.329659\n-0.090454\n0.459422\n-1.281357\n-0.437196\n-0.268200\n0.232447\n\n\npush\n-0.184951\n0.711796\n0.721361\n-0.777537\n0.321118\n0.102113\n-0.503164\n0.589479\n1.586533\n0.306067\n...\n-0.007689\n-0.354350\n-0.783757\n0.479150\n0.510954\n0.808599\n-1.763679\n1.179172\n-0.048447\n-0.237922\n\n\nrealization\n0.680622\n0.343941\n0.359005\n-0.110402\n0.846315\n-1.126212\n0.410226\n-0.506499\n-0.529498\n-1.226504\n...\n0.534820\n0.661075\n0.972976\n0.132633\n0.495696\n-0.392315\n0.310346\n0.728478\n-0.813280\n0.737264\n\n\nself\n0.257648\n0.058829\n-0.417947\n0.250967\n0.102127\n-0.601216\n0.257821\n-0.101740\n-0.363018\n-0.105056\n...\n1.385324\n-0.540304\n-0.544518\n0.790096\n0.714771\n0.062684\n-0.041591\n0.477603\n0.045479\n0.348599\n\n\nsocial\n0.001411\n0.083508\n-0.384193\n0.038151\n0.828193\n-0.295133\n-0.131154\n-0.310905\n-0.194347\n-0.355901\n...\n-0.688219\n-0.004625\n-0.023948\n0.265741\n-0.029004\n-0.086471\n0.103009\n1.135597\n-0.636987\n-0.338693\n\n\nthe\n1.259149\n-0.390939\n-0.574276\n-0.651518\n0.975174\n-0.346215\n-0.203062\n0.069047\n-0.972633\n-0.484539\n...\n-0.177573\n0.605176\n-0.330061\n-0.963901\n0.492528\n0.279568\n-0.408966\n0.528585\n-1.137273\n0.370578\n\n\ntheir\n-0.141068\n-0.385690\n-0.610704\n-0.631536\n0.036775\n-0.008408\n0.058548\n0.447865\n-0.403555\n-0.706317\n...\n-0.900095\n0.260387\n-0.259527\n-0.011186\n0.366235\n-0.750171\n0.071075\n0.316691\n0.273126\n-1.098873\n\n\nthese\n-0.867060\n-0.423800\n-0.462822\n0.031337\n-0.921427\n0.606853\n-0.407772\n0.609299\n-0.070913\n0.411936\n...\n-0.375234\n-0.172975\n0.506652\n-0.142546\n0.120540\n-1.079829\n-0.097479\n-0.512669\n-0.959007\n0.081844\n\n\nthrough\n-0.806322\n0.435404\n-0.860480\n-0.352367\n-0.911619\n0.371939\n-0.302082\n-0.138660\n-0.286805\n0.741813\n...\n0.205986\n0.712598\n-0.843359\n0.651225\n0.107572\n0.096148\n-0.935132\n0.180383\n0.055736\n-0.279496\n\n\nto\n-0.467868\n-0.124578\n-0.321987\n0.056667\n-0.164021\n1.174730\n-0.633803\n0.867373\n-1.580327\n-0.784350\n...\n-0.367765\n-0.081297\n0.588999\n0.236422\n0.058517\n-0.139931\n0.747637\n-0.138854\n-0.143276\n-0.009610\n\n\nunder\n0.687285\n-0.849716\n0.345514\n-0.015210\n-0.001491\n0.095282\n-0.069619\n-0.023330\n-0.572866\n-1.167167\n...\n-0.920049\n0.214902\n0.161194\n-0.373119\n-0.300902\n-0.546927\n0.374067\n0.461742\n0.977844\n-0.106500\n\n\nwe\n0.493856\n-0.277951\n1.282449\n-0.818842\n-0.315630\n1.576497\n-0.768214\n-1.161283\n-1.137017\n0.787399\n...\n0.117417\n-0.324164\n-0.510348\n0.801145\n-0.253922\n0.568123\n0.851370\n-0.558899\n-0.064633\n-0.407102\n\n\nwhich\n-0.368462\n-0.361856\n0.409696\n0.587431\n0.708897\n0.291840\n-0.362036\n-0.530712\n-0.053614\n-0.711788\n...\n-1.084328\n-0.832080\n0.269114\n0.851772\n-0.942639\n-0.081171\n-1.273354\n-0.796438\n-0.260538\n0.355565\n\n\nwith\n-0.388580\n-0.219293\n-0.652044\n-1.386387\n-0.089682\n-0.403928\n-1.394354\n0.763693\n-0.379815\n-0.662670\n...\n-0.599527\n-0.076366\n0.786938\n-1.619844\n-0.512546\n-0.580194\n-0.000503\n-0.181073\n-1.548287\n0.417536\n\n\nworld\n0.737164\n-0.141081\n0.328124\n0.615530\n0.357371\n0.274039\n-0.563317\n0.040565\n-0.111780\n0.075683\n...\n-0.404257\n0.543159\n0.008046\n0.476506\n0.046138\n-0.633671\n-0.073570\n-0.446745\n-0.119588\n-0.238425\n\n\n\n\n56 rows × 768 columns",
    "crumbs": [
      "BERT",
      "BERT Functions"
    ]
  },
  {
    "objectID": "rmarkdown/UNGDC_topic_modeling_updated.html",
    "href": "rmarkdown/UNGDC_topic_modeling_updated.html",
    "title": "Dynamic UNGDC (updated)",
    "section": "",
    "text": "This version does use tf-idf for LDA analysis. For the older version, refer to UNGDC_topic_modeling.qmd. I created a separate version for two reasons. First, some of the functions and options deprecated from the quanteda R package. Earlier version might not be reproducible. Second, the inclusion of tf-idf to generate LDA analysis has a tradeoff. Since it gives less weights to terms that appear frequently across the documents, by definition, tf-idf lowers the correlation between terms over different time window. It is harder to notice a clear linkage between two topics represented by different terms. However, unlike the earlier version that excludes tf-idf, topics are more specific, and substantively meaningful.",
    "crumbs": [
      "Topic Modeling",
      "Topic Modeling 1"
    ]
  },
  {
    "objectID": "rmarkdown/UNGDC_topic_modeling_updated.html#dynamic-topic-modeling-for-ungdc",
    "href": "rmarkdown/UNGDC_topic_modeling_updated.html#dynamic-topic-modeling-for-ungdc",
    "title": "Dynamic UNGDC (updated)",
    "section": "Dynamic Topic Modeling for UNGDC",
    "text": "Dynamic Topic Modeling for UNGDC\nIn order to generate LDA topic modeling results for the corpus of UNGD, I split the corpus into different time frames. The entire time span of 1945 until 2022 is split into 8 intervals, with a duration of 10 years.\n\n# Load packages\nlibrary(plyr)\nlibrary(dplyr)\nlibrary(tm)\nlibrary(gplots)\nlibrary(ggplot2)\nlibrary(quanteda)\nlibrary(readr)\nlibrary(seededlda)\nlibrary(slam)\nlibrary(jsonlite)\nlibrary(tm)\nlibrary(tidyr)\nlibrary(knitr)\n\nlight &lt;- readRDS(\"data/processed/cleaned.RDS\")\n\n#Set up the parameters\nlight_interval &lt;- light %&gt;%\n  dplyr::mutate(span = as.factor(cut(year,\n                                     breaks = c(seq(from = 1945, to = 2022, by = 10), 2022)))) %&gt;%\n  dplyr::arrange(year)\n\n\n# I added two additional stop words that aren't captured in the generic stop words dictionary. \n\nmystopwords &lt;- c(\"will\", \"must\")\ncustom_stopwords &lt;- c(stopwords(\"english\"), mystopwords)",
    "crumbs": [
      "Topic Modeling",
      "Topic Modeling 1"
    ]
  },
  {
    "objectID": "rmarkdown/UNGDC_topic_modeling_updated.html#term-frequency-inverse-matrix-and-descriptive-data-visualization",
    "href": "rmarkdown/UNGDC_topic_modeling_updated.html#term-frequency-inverse-matrix-and-descriptive-data-visualization",
    "title": "Dynamic UNGDC (updated)",
    "section": "Term Frequency-Inverse Matrix and Descriptive Data Visualization",
    "text": "Term Frequency-Inverse Matrix and Descriptive Data Visualization\n\nTo inspect the data and frequent words across time intervals, below code generates top-20 terms based on the tf-idf scores.\nInput dataset: “data/processed/cleaned.RDS”.\n\n\n# Function for generating tf_idf and plots.\nsapply(levels(light_interval$span), function(i) {\n  subset_i &lt;- light_interval %&gt;% dplyr::filter(span %in% i)\n  corpus_subset &lt;- Corpus(VectorSource(subset_i$text))\n  tdm &lt;- TermDocumentMatrix(corpus_subset,\n                            control = list(weighting = weightTfIdf,\n                                           removePunctuation = TRUE,\n                                           stemming = TRUE,\n                                           removeNumbers = TRUE,\n                                           stopwords = TRUE,\n                                           removewords = mystopwords))\n  top_terms &lt;- slam::row_sums(as.matrix(tdm))\n  \n  # Create a data frame with terms and tfidf values\n  top_terms_df &lt;- data.frame(term = names(top_terms), tfidf = top_terms)\n  \n  # Order the terms by tfidf value\n  top_terms_df &lt;- top_terms_df[order(top_terms_df$tfidf, decreasing = TRUE), ]\n  \n  # Select the top 20 terms\n  top_terms_df &lt;- head(top_terms_df, 20)\n  \n  figure_i &lt;- ggplot(top_terms_df, aes(x = reorder(term, tfidf), y = tfidf)) +\n    geom_bar(stat = \"identity\", fill = \"skyblue\") +\n    theme_minimal() +\n    labs(title = \"Top 20 Terms by TF-IDF\",\n         x = \"Terms\",\n         y = \"TF-IDF Score\") +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1))\n  \n  output_file &lt;- file.path(\"figs/\", paste0(\"plot_\", i, \".png\"))\n  ggsave(output_file, figure_i, width = 8, height = 5, units = \"in\")\n})\n\n\ndfm function helps remove stop words and perform other preprocessing steps to create a more refined document-feature matrix. Additionally, the subsequent dfm_tfidf function is used to compute TF-IDF (Term Frequency-Inverse Document Frequency) scores, which down-weights terms that appear frequently across documents.",
    "crumbs": [
      "Topic Modeling",
      "Topic Modeling 1"
    ]
  },
  {
    "objectID": "rmarkdown/UNGDC_topic_modeling_updated.html#reading-in-lda-results",
    "href": "rmarkdown/UNGDC_topic_modeling_updated.html#reading-in-lda-results",
    "title": "Dynamic UNGDC (updated)",
    "section": "Reading in LDA results",
    "text": "Reading in LDA results\nAfter running the LDA model, I read in each LDA results as a separate element in a list form. Below code prins out top 10 terms associated with each topic in the LDA models for different span levels. Each row represents one semantic topic.\n\nread_lda_models &lt;- function(span_levels, output_dir = \"output/lda/decade_0120_replicate\") {\n  lda_models &lt;- list()\n\n  for (i in span_levels) {\n    lda_output_file &lt;- file.path(output_dir, paste0(\"lda_model_\", i, \".RDS\"))\n\n    if (file.exists(lda_output_file)) {\n      lda_model &lt;- readRDS(lda_output_file)\n      lda_models[[i]] &lt;- lda_model\n      cat(sprintf(\"LDA model for %s successfully loaded.\\n\", i))\n    } else {\n      cat(sprintf(\"LDA model file for %s not found.\\n\", i))\n    }\n  }\n\n  return(lda_models)\n}\n\n\n\nlda_models &lt;- read_lda_models(span_levels)\n\nLDA model for (1945,1955] successfully loaded.\nLDA model for (1955,1965] successfully loaded.\nLDA model for (1965,1975] successfully loaded.\nLDA model for (1975,1985] successfully loaded.\nLDA model for (1985,1995] successfully loaded.\nLDA model for (1995,2005] successfully loaded.\nLDA model for (2005,2015] successfully loaded.\nLDA model for (2015,2022] successfully loaded.\n\ntopic_tables &lt;- function(lda_models, span_levels) {\n  topic_tables &lt;- list()\n\n  for (i in span_levels) {\n    if (i %in% names(lda_models)) {\n      lda_model &lt;- lda_models[[i]]\n      terms &lt;- terms(lda_model, 10)\n      topic_table &lt;- data.frame(Terms = terms)\n      topic_tables[[i]] &lt;- topic_table\n    } else {\n      cat(sprintf(\"LDA model for %s not found.\\n\", i))\n    }\n  }\n\n  all_topics &lt;- do.call(rbind, topic_tables)\n  return(all_topics)\n}\n\n\ntopic_tables &lt;- topic_tables(lda_models, span_levels)\nprint(knitr::kable(topic_tables))\n\n\n\n|               |Terms.topic1  |Terms.topic2 |Terms.topic3 |Terms.topic4 |Terms.topic5 |Terms.topic6 |Terms.topic7 |Terms.topic8 |Terms.topic9  |Terms.topic10 |\n|:--------------|:-------------|:------------|:------------|:------------|:------------|:------------|:------------|:------------|:-------------|:-------------|\n|(1945,1955].1  |ussr          |arab         |german       |argentin     |bolivia      |hyderabad    |netherland   |resumpt      |communist     |india         |\n|(1945,1955].2  |soviet        |israel       |czechoslovak |latin        |cuba         |egypt        |bandung      |korea        |soviet        |australian    |\n|(1945,1955].3  |yugoslav      |palestin     |polish       |trade        |greek        |india        |african      |collect      |chines        |commiss       |\n|(1945,1955].4  |atom          |jerusalem    |soviet       |chile        |greec        |sudan        |south        |recommend    |communism     |council       |\n|(1945,1955].5  |yugoslavia    |morocco      |germani      |uruguay      |dominican    |egyptian     |geneva       |independ     |china         |think         |\n|(1945,1955].6  |armament      |tunisia      |people’      |veto         |guatemala    |pakistan     |africa       |leader       |korea         |say           |\n|(1945,1955].7  |union         |jew          |poland       |american     |colombia     |el           |indonesia    |europ        |union         |veto          |\n|(1945,1955].8  |prohibit      |refuge       |weapon       |panama       |bolivian     |salvador     |thailand     |veto         |imprison      |soviet        |\n|(1945,1955].9  |weapon        |jewish       |hydrogen     |venezuela    |guatemalan   |sudanes      |zealand      |revis        |costa         |china         |\n|(1945,1955].10 |american      |franc        |european     |per          |cuban        |british      |asia         |collabor     |mainland      |arbitr        |\n|(1955,1965].1  |particip      |bantu        |malaysia     |cambodia     |netherland   |pakistan     |american     |african      |german        |arab          |\n|(1955,1965].2  |moscow        |iceland      |zealand      |lao          |congo        |cyprus       |cuba         |africa       |socialist     |israel        |\n|(1955,1965].3  |industri      |south        |australia    |spain        |indonesia    |turkish      |cuban        |portug       |soviet        |palestin      |\n|(1955,1965].4  |coexist       |indian       |philippin    |communist    |irian        |kashmir      |panama       |mali         |czechoslovak  |egypt         |\n|(1955,1965].5  |fund          |canada       |malaya       |viet         |nigeria      |india        |guatemala    |portugues    |albania       |algerian      |\n|(1955,1965].6  |cent          |canadian     |australian   |spanish      |berlin       |turkey       |dominican    |somali       |romanian      |libya         |\n|(1955,1965].7  |trade         |danish       |feder        |chines       |belgian      |greek        |venezuela    |congo        |germani       |franc         |\n|(1955,1965].8  |scienc        |goa          |india        |cambodian    |indonesian   |greec        |latin        |austrian     |byelorussian  |libyan        |\n|(1955,1965].9  |concept       |africa       |indonesia    |pathet       |west         |nepal        |america      |cameroon     |nato          |canal         |\n|(1955,1965].10 |invest        |chairman     |manila       |royal        |want         |jammu        |paraguay     |malagasi     |albanian      |jordan        |\n|(1965,1975].1  |like          |pakistan     |african      |imperialist  |like         |israel       |austria      |cuba         |turkey        |haiti         |\n|(1965,1975].2  |programm      |india        |ghana        |khmer        |socialist    |arab         |spain        |iceland      |cyprus        |oil           |\n|(1965,1975].3  |nuclear       |zealand      |rwanda       |aggress      |soviet       |isra         |salvador     |venezuela    |turkish       |australia     |\n|(1965,1975].4  |big           |ireland      |portug       |imperi       |german       |palestin     |italian      |cuban        |argentina     |haitian       |\n|(1965,1975].5  |neighbour     |netherland   |uganda       |revisionist  |mongolian    |zionist      |el           |panama       |greec         |volta         |\n|(1965,1975].6  |space         |japan        |burundi      |albania      |byelorussian |palestinian  |itali        |bolivia      |argentin      |philippin     |\n|(1965,1975].7  |strategi      |burma        |africa       |albanian     |ssr          |yemen        |gibraltar    |zair         |peru          |price         |\n|(1965,1975].8  |franc         |kashmir      |portugues    |viet         |czechoslovak |israel’      |rica         |chile        |greek         |upper         |\n|(1965,1975].9  |youth         |fiji         |kenya        |cambodia     |ukrainian    |aggress      |hondura      |latin        |brazil        |food          |\n|(1965,1975].10 |madam         |pacif        |oau          |chines       |europ        |iraq         |uruguay      |dominican    |dahomey       |australian    |\n|(1975,1985].1  |malta         |soviet       |ireland      |imperialist  |turkey       |benin        |guinea       |pleasur      |guatemala     |¬             |\n|(1975,1985].2  |zionist       |japan        |panama       |vietnames    |yemen        |burundi      |papua        |dialog       |uganda        |barbado       |\n|(1975,1985].3  |bahama        |europ        |ecuador      |kampuchea    |egypt        |mali         |zealand      |cooper       |timor         |paraguay      |\n|(1975,1985].4  |itali         |german       |latin        |chines       |morocco      |rwanda       |pacif        |program      |nicaragua     |ghana         |\n|(1975,1985].5  |iranian       |union        |bolivia      |lao          |turkish      |seneg        |chad         |per          |guinea        |tion          |\n|(1975,1985].6  |iraqi         |socialist    |dominican    |thailand     |pakistan     |zair         |bangladesh   |refuge       |hondura       |guyana        |\n|(1975,1985].7  |mediterranean |mongolian    |rica         |nam          |sudan        |oau          |australia    |india        |salvador      |ment          |\n|(1975,1985].8  |tobago        |poland       |costa        |viet         |arab         |kenya        |surinam      |fortieth     |revolutionari |con           |\n|(1975,1985].9  |libyan        |austria      |spain        |ethiopia     |islam        |chad         |equatori     |sea          |guatemalan    |venezuela     |\n|(1975,1985].10 |islam         |detent       |american     |romania      |isra         |mauritania   |canada       |indian       |angola        |caribbean     |\n|(1985,1995].1  |wish          |wish         |wish         |panama       |wish         |wish         |wish         |wish         |wish          |wish          |\n|(1985,1995].2  |paraguay      |co           |islam        |burundi      |guinea       |canada       |european     |saint        |cooper        |malawi        |\n|(1985,1995].3  |american      |organis      |arab         |myanmar      |pacif        |netherland   |europ        |bahama       |boutro        |african       |\n|(1985,1995].4  |latin         |program      |sri          |rwanda       |viet         |philippin    |ukrain       |nepal        |eighth        |chad          |\n|(1985,1995].5  |bolivia       |dialog       |iranian      |romania      |nam          |want         |albania      |caribbean    |bosnia        |niger         |\n|(1985,1995].6  |dominican     |twelv        |lebanon      |zair         |japan        |revolut      |belarus      |pakistan     |herzegovina   |swaziland     |\n|(1985,1995].7  |ecuador       |align        |lanka        |panamanian   |equatori     |canadian     |poland       |barbado      |somalia       |uganda        |\n|(1985,1995].8  |hondura       |namibia      |iraqi        |belgium      |solomon      |let          |csce         |haiti        |l993          |kenya         |\n|(1985,1995].9  |chile         |disarma      |ireland      |canal        |zealand      |enemi        |austria      |surinam      |fiftieth      |benin         |\n|(1985,1995].10 |costa         |drug         |tunisia      |rwandes      |papua        |children     |croatia      |india        |npt           |angola        |\n|(1995,2005].1  |outset        |outset       |outset       |outset       |outset       |outset       |outset       |outset       |outset        |outset        |\n|(1995,2005].2  |african       |azerbaijan   |island       |korea        |croatia      |marino       |trinidad     |afghanistan  |arab          |sri           |\n|(1995,2005].3  |africa        |cyprus       |caribbean    |korean       |european     |san          |tobago       |taliban      |iraq          |ethiopia      |\n|(1995,2005].4  |guinea        |tajikistan   |pacif        |nepal        |herzegovina  |women        |belarus      |swaziland    |israel        |lanka         |\n|(1995,2005].5  |congo         |armenia      |saint        |pakistan     |mongolia     |sixtieth     |slovakia     |ecuador      |palestinian   |eritrea       |\n|(1995,2005].6  |malawi        |turkmenistan |papua        |ireland      |kosovo       |iraq         |panama       |bolivia      |isra          |andorra       |\n|(1995,2005].7  |chad          |turkey       |bahama       |thailand     |€            |outcom       |haiti        |myanmar      |lebanon       |eritrean      |\n|(1995,2005].8  |burundi       |kazakhstan   |barbado      |asean        |latvia       |weapon       |mexico       |estonia      |malta         |cuba          |\n|(1995,2005].9  |liberia       |georgia      |solomon      |monaco       |bosnia       |document     |guatemala    |chile        |kuwait        |truth         |\n|(1995,2005].10 |uganda        |turkish      |small        |india        |bulgaria     |uruguay      |dominican    |paraguay     |iraqi         |muslim        |\n|(2005,2015].1  |everi         |everi        |everi        |everi        |everi        |everi        |everi        |everi        |everi         |everi         |\n|(2005,2015].2  |nepal         |pakistan     |serbia       |japan        |mdgs         |guinea       |island       |arab         |ecuador       |azerbaijan    |\n|(2005,2015].3  |iceland       |iran         |fiji         |timor        |treati       |african      |sid          |yemen        |panama        |georgia       |\n|(2005,2015].4  |trinidad      |muslim       |european     |mongolia     |g            |korea        |pacif        |kuwait       |paraguay      |asean         |\n|(2005,2015].5  |burundi       |islam        |kosovo       |ireland      |nuclear      |mali         |solomon      |syrian       |marino        |kazakhstan    |\n|(2005,2015].6  |sri           |god          |bosnia       |lest         |mediat       |somalia      |saint        |iraq         |peru          |ukrain        |\n|(2005,2015].7  |tobago        |war          |herzegovina  |bangladesh   |disput       |korean       |bahama       |lebanon      |america       |afghanistan   |\n|(2005,2015].8  |canada        |nuclear      |cyprus       |latvia       |disarma      |sudan        |caribbean    |palestinian  |american      |moldova       |\n|(2005,2015].9  |malawi        |want         |malta        |cambodia     |migrat       |philippin    |grenada      |egypt        |latin         |thailand      |\n|(2005,2015].10 |zambia        |israel       |croatia      |australia    |multilater   |bissau       |small        |libya        |bolivia       |turkmenistan  |\n|(2015,2022].1  |distinct      |african      |israel       |distinct     |ukrain       |india        |pacif        |bosnia       |pandem        |korea         |\n|(2015,2022].2  |peacekeep     |mali         |syrian       |azerbaijan   |european     |pakistan     |island       |herzegovina  |covid         |malaysia      |\n|(2015,2022].3  |andorra       |sudan        |iran         |armenia      |russian      |sri          |ocean        |saint        |un            |asean         |\n|(2015,2022].4  |trade         |sahel        |brazil       |trinidad     |russia       |lanka        |solomon      |caribbean    |vaccin        |mongolia      |\n|(2015,2022].5  |weapon        |congo        |colombia     |tobago       |eu           |costa        |tonga        |beliz        |75th          |thailand      |\n|(2015,2022].6  |migrant       |chad         |spain        |burundi      |ireland      |bangladesh   |papua        |mauritius    |marino        |kazakhstan    |\n|(2015,2022].7  |educ          |guinea       |venezuela    |kingdom      |georgia      |canada       |australia    |nepal        |bhutan        |turkmenistan  |\n|(2015,2022].8  |energi        |africa       |iraq         |morocco      |serbia       |rica         |tanzania     |guatemala    |kenya         |japan         |\n|(2015,2022].9  |refuge        |madagascar   |palestinian  |arab         |europ        |kashmir      |micronesia   |moldova      |botswana      |kyrgyzstan    |\n|(2015,2022].10 |sdgs          |burkina      |lebanon      |yemeni       |montenegro   |muslim       |tuvalu       |bahama       |somalia       |tajikistan    |\n\n\n\nEach column in the dataset corresponds to a vector of terms representing a specific topic. However, extracting substantively meaningful topics poses challenges due to several issues. One notable challenge is the variability in the set of terms used to represent the same topic across different time periods. For instance, the topic of international security may be discussed in relation to the Soviet Union and North Korea in earlier time periods, whereas in more recent times, it may be associated with Russia and Ukraine.\nAnother important problem is identifying related topics over time. There is a difficulty of establishing connections between topics and understanding their evolution across different temporal contexts. Some topics and terms disappear abruptly, while new topics emerge. Identifying the connection between vectors poses a challenge.",
    "crumbs": [
      "Topic Modeling",
      "Topic Modeling 1"
    ]
  },
  {
    "objectID": "rmarkdown/UNGDC_topic_modeling_updated.html#dynamic-topic-modeling",
    "href": "rmarkdown/UNGDC_topic_modeling_updated.html#dynamic-topic-modeling",
    "title": "Dynamic UNGDC (updated)",
    "section": "Dynamic Topic Modeling",
    "text": "Dynamic Topic Modeling\n\nTo address the above mentioned challenges, we refered to existing papers.\n\"BERTopic Dynamic Topic Modeling\"(https://maartengr.github.io/BERTopic/getting_started/topicsovertime/topicsovertime.html)\nGreene and cross, 2017 (https://doi.org/10.1017/pan.2016.7)\n\n\nThis generates output for a single pair of time frames\n\nmodel1&lt;-lda_models[[1]]\nmodel2&lt;-lda_models[[2]]\n\n# phi value is a topic probability of every word\nphi1 &lt;- model1$phi\n\n#phi1$topic &lt;- sequence(nrow(phi1))\n\nphi2 &lt;- model2$phi\n#phi2$topic &lt;- sequence(nrow(phi2))\n\n\n# Convert matrices to data frames\nphi1_df &lt;- as.data.frame(phi1)\nphi2_df &lt;- as.data.frame(phi2)\n\norder_phi1 &lt;- order(colMeans(phi1_df), decreasing = TRUE)\norder_phi2 &lt;- order(colMeans(phi2_df), decreasing = TRUE)\n\n# Reorder columns based on the mean\nphi1_df &lt;- phi1_df[, order_phi1]\nphi2_df &lt;- phi2_df[, order_phi2]\n\n# Identify columns to drop based on colMeans\n## Try without dropping\ncolumns_to_drop_phi1 &lt;- colMeans(phi1_df) &lt; 0.00001\ncolumns_to_drop_phi2 &lt;- colMeans(phi2_df) &lt; 0.00001\n\n# Drop identified columns\nphi1_df &lt;- phi1_df[, !columns_to_drop_phi1, drop = FALSE]\nphi2_df &lt;- phi2_df[, !columns_to_drop_phi2, drop = FALSE]\n\n\n# Get the union of column names\nall_terms &lt;- union(colnames(phi1_df), colnames(phi2_df))\n\n#fill missing values with zeros\nphi1_union &lt;- bind_cols(phi1_df, setNames(data.frame(matrix(0, nrow = nrow(phi1_df), ncol = length(setdiff(all_terms, colnames(phi1_df))))), setdiff(all_terms, colnames(phi1_df))))\nphi2_union &lt;- bind_cols(phi2_df, setNames(data.frame(matrix(0, nrow = nrow(phi2_df), ncol = length(setdiff(all_terms, colnames(phi2_df))))), setdiff(all_terms, colnames(phi2_df))))\n\n# Reorder columns alphabetically\nphi1_union &lt;- phi1_union[, order(colnames(phi1_union))]\nphi2_union &lt;- phi2_union[, order(colnames(phi2_union))]\n\n\ndim(phi1_union)\ndim(phi2_union)\n\n\ncor&lt;-cor(t(phi1_union), t(phi2_union))\n\n\nheatmap.2(cor,\n          Rowv = FALSE, Colv = FALSE,\n          col = heat.colors(256),\n          trace = \"none\", # no row/column names\n          key = TRUE, keysize = 1.5,\n          density.info = \"none\", margins = c(5, 5),\n          cexCol = 1, cexRow = 1, # adjust text size\n          notecol = \"black\", notecex = 0.7,\n          main = \"Correlation Matrix\",\n          xlab = \"Period 2\", ylab = \"Period 1\",\n          symkey = FALSE)\n\norder_phi1_union &lt;- order(colMeans(phi1_union), decreasing = TRUE)\nphi1_result &lt;- phi1_union[, order_phi1_union]\n\norder_phi2_union &lt;- order(colMeans(phi2_union), decreasing = TRUE)\nphi2_result &lt;- phi2_union[, order_phi2_union]\n\n\nphi1_result_row &lt;- orderBasedOnRow(phi1_union, 1)\nphi1_result_long&lt;-phi1_result_row%&gt;%\n  tidyr::pivot_longer(everything(), names_to=\"term_1\", values_to=\"probability_1\")\n\nphi2_result_row &lt;- orderBasedOnRow(phi2_union, 6)\nphi2_result_long&lt;-phi2_result_row%&gt;%\n  tidyr::pivot_longer(everything(), names_to=\"term_2\", values_to=\"probability_2\")\n\npair&lt;-bind_cols(phi1_result_long, phi2_result_long)\n\n#Function to print out the words\n\norderBasedOnRow &lt;- function(df, I) {\n  # Order columns based on the Ith row values\n  ordered_cols &lt;- order(apply(df, 2, function(x) x[I]), decreasing = TRUE)\n\n  # Reorder the data frame columns\n  ordered_df &lt;- df[, ordered_cols]\n\n  ordered_row &lt;- ordered_df[I, 1:10]\n\n  return(ordered_row)\n}",
    "crumbs": [
      "Topic Modeling",
      "Topic Modeling 1"
    ]
  },
  {
    "objectID": "rmarkdown/UNGDC_topic_modeling_updated.html#below-function-generates-heatmaps-for-a-pair-of-models.",
    "href": "rmarkdown/UNGDC_topic_modeling_updated.html#below-function-generates-heatmaps-for-a-pair-of-models.",
    "title": "Dynamic UNGDC (updated)",
    "section": "Below function generates heatmaps for a pair of models.",
    "text": "Below function generates heatmaps for a pair of models.\n\ngenerate_heatmap &lt;- function(model1, model2, correlation_threshold = 0.9) {\n  phi1 &lt;- model1$phi\n  phi2 &lt;- model2$phi\n\n  phi1_df &lt;- as.data.frame(phi1)\n  phi2_df &lt;- as.data.frame(phi2)\n  \n  all_terms &lt;- union(colnames(phi1_df), colnames(phi2_df))\n\n  phi1_union &lt;- bind_cols(phi1_df, setNames(data.frame(matrix(0, nrow = nrow(phi1_df), ncol = length(setdiff(all_terms, colnames(phi1_df))))), setdiff(all_terms, colnames(phi1_df))))\n  phi2_union &lt;- bind_cols(phi2_df, setNames(data.frame(matrix(0, nrow = nrow(phi2_df), ncol = length(setdiff(all_terms, colnames(phi2_df))))), setdiff(all_terms, colnames(phi2_df))))\n\n  phi1_union &lt;- phi1_union[, order(colnames(phi1_union))]\n  phi2_union &lt;- phi2_union[, order(colnames(phi2_union))]\n\n  dim(phi1_union)\n  dim(phi2_union)\n\n  cor_matrix &lt;- cor(t(phi1_union), t(phi2_union))\n\n  # Heatmap for correlation matrix\n  heatmap.2(cor_matrix,\n            Rowv = FALSE, Colv = FALSE,\n            col = heat.colors(16),\n            trace = \"none\", # no row/column names\n            key = TRUE, keysize = 1.5,\n            density.info = \"none\", margins = c(5, 5),\n            cexCol = 1, cexRow = 1, # adjust text size\n            notecol = \"black\", notecex = 0.7,\n            xlab = \"Time 2\",\n            ylab = \"Time 1\",\n            symkey = FALSE)\n\n  return(list(phi1_union = phi1_union, phi2_union = phi2_union, cor_matrix = cor_matrix))\n}",
    "crumbs": [
      "Topic Modeling",
      "Topic Modeling 1"
    ]
  },
  {
    "objectID": "rmarkdown/UNGDC_topic_modeling_updated.html#rows-with-high-correlation",
    "href": "rmarkdown/UNGDC_topic_modeling_updated.html#rows-with-high-correlation",
    "title": "Dynamic UNGDC (updated)",
    "section": "Rows with high correlation",
    "text": "Rows with high correlation\n\n# Function to print the ordered rows for each topic with high correlation\nprint_ordered_rows &lt;- function(phi1_union, phi2_union, cor_matrix, high_corr_indices, correlation_threshold = 0.9) {\n  # Find indices where correlation is higher than the threshold\n  high_corr_indices &lt;- which(cor_matrix &gt; correlation_threshold & !is.na(cor_matrix), arr.ind = TRUE)\n\n  # Create an empty list to store results\n  result_list &lt;- list()\n\n  # Print the ordered rows for each topic with high correlation\n  for (i in seq_len(nrow(high_corr_indices))) {\n    model1_topic &lt;- high_corr_indices[i, 1]\n    model2_topic &lt;- high_corr_indices[i, 2]\n\n    # Print the ordered rows for each model's topic\n    cat(paste(\"Model 1 - Topic\", model1_topic), \"\\n\")\n    phi1_result_row &lt;- orderBasedOnRow(phi1_union, model1_topic)\n\n    cat(paste(\"Model 2 - Topic\", model2_topic), \"\\n\")\n    phi2_result_row &lt;- orderBasedOnRow(phi2_union, model2_topic)\n\n    # Convert result rows to long format\n    phi1_result_long &lt;- phi1_result_row %&gt;%\n      tidyr::pivot_longer(everything(), names_to = \"term_1\", values_to = \"probability_1\")\n\n    phi2_result_long &lt;- phi2_result_row %&gt;%\n      tidyr::pivot_longer(everything(), names_to = \"term_2\", values_to = \"probability_2\")\n\n    # Combine phi1 and phi2 results\n    pair &lt;- bind_cols(phi1_result_long, phi2_result_long)\n\n    # Append the result to the list\n    result_list[[i]] &lt;- pair\n  }\n\n  # Combine all results into a single dataframe\n  final_result &lt;- do.call(bind_rows, result_list)\n\n  return(final_result)\n}",
    "crumbs": [
      "Topic Modeling",
      "Topic Modeling 1"
    ]
  },
  {
    "objectID": "rmarkdown/UNGDC_topic_modeling_updated.html#execute-functions-over-pairs",
    "href": "rmarkdown/UNGDC_topic_modeling_updated.html#execute-functions-over-pairs",
    "title": "Dynamic UNGDC (updated)",
    "section": "Execute functions over pairs",
    "text": "Execute functions over pairs\n\n# Loop through pairs of models to generate heatmaps and print results\nfor (i in 1:(length(lda_models) - 1)) {\n  model1 &lt;- lda_models[[i]]\n  model2 &lt;- lda_models[[i + 1]]\n\n  result &lt;- generate_heatmap(model1, model2, correlation_threshold = 0.5)\n  \n  phi1_union &lt;- result$phi1_union\n  phi2_union &lt;- result$phi2_union\n  cor_matrix &lt;- result$cor_matrix\n\n  # Print ordered rows only if there are high correlations\n  if (any(cor_matrix &gt; 0.5, na.rm = TRUE)) {\n    phi1_result &lt;- phi1_union[, order(colMeans(phi1_union), decreasing = TRUE)]\n    phi2_result &lt;- phi2_union[, order(colMeans(phi2_union), decreasing = TRUE)]\n\n    # Call the modified function and pass high_corr_indices as an argument\n    final_result &lt;- print_ordered_rows(phi1_result, phi2_result, cor_matrix, high_corr_indices, correlation_threshold = 0.5)\n    print(final_result)\n  }\n}\n\n\n\n\n\n\n\n\nModel 1 - Topic 3 \nModel 2 - Topic 9 \nModel 1 - Topic 2 \nModel 2 - Topic 10 \n# A tibble: 20 × 4\n   term_1       probability_1 term_2       probability_2\n   &lt;chr&gt;                &lt;dbl&gt; &lt;chr&gt;                &lt;dbl&gt;\n 1 german             0.0150  german             0.0138 \n 2 czechoslovak       0.0119  socialist          0.0102 \n 3 polish             0.0113  soviet             0.00986\n 4 soviet             0.0108  czechoslovak       0.00816\n 5 germani            0.0101  albania            0.00793\n 6 people’            0.00766 romanian           0.00732\n 7 poland             0.00693 germani            0.00728\n 8 weapon             0.00632 byelorussian       0.00726\n 9 hydrogen           0.00619 nato               0.00629\n10 geneva             0.00595 albanian           0.00548\n11 arab               0.0271  arab               0.0249 \n12 israel             0.0228  israel             0.0231 \n13 palestin           0.0129  palestin           0.0155 \n14 jerusalem          0.0104  egypt              0.0105 \n15 morocco            0.00949 algerian           0.0101 \n16 tunisia            0.00899 libya              0.00916\n17 jew                0.00821 franc              0.00826\n18 refuge             0.00728 libyan             0.00782\n19 jewish             0.00635 canal              0.00776\n20 franc              0.00500 jordan             0.00729\n\n\n\n\n\n\n\n\n\nModel 1 - Topic 8 \nModel 2 - Topic 3 \nModel 1 - Topic 10 \nModel 2 - Topic 6 \nModel 1 - Topic 7 \nModel 2 - Topic 8 \n# A tibble: 30 × 4\n   term_1    probability_1 term_2    probability_2\n   &lt;chr&gt;             &lt;dbl&gt; &lt;chr&gt;             &lt;dbl&gt;\n 1 african         0.0150  african         0.00885\n 2 africa          0.00815 ghana           0.00692\n 3 portug          0.00735 rwanda          0.00661\n 4 mali            0.00729 portug          0.00620\n 5 portugues       0.00670 uganda          0.00618\n 6 somali          0.00661 burundi         0.00593\n 7 congo           0.00627 africa          0.00530\n 8 austrian        0.00601 portugues       0.00462\n 9 cameroon        0.00564 kenya           0.00460\n10 malagasi        0.00553 oau             0.00452\n# ℹ 20 more rows\n\n\n\n\n\n\n\n\n\nModel 1 - Topic 4 \nModel 2 - Topic 4 \n# A tibble: 10 × 4\n   term_1      probability_1 term_2      probability_2\n   &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;\n 1 imperialist       0.0162  imperialist       0.0108 \n 2 khmer             0.00847 vietnames         0.0106 \n 3 aggress           0.00749 kampuchea         0.00971\n 4 imperi            0.00718 chines            0.00956\n 5 revisionist       0.00666 lao               0.00954\n 6 albania           0.00659 thailand          0.00947\n 7 albanian          0.00594 nam               0.00870\n 8 viet              0.00576 viet              0.00863\n 9 cambodia          0.00553 ethiopia          0.00833\n10 chines            0.00545 romania           0.00801",
    "crumbs": [
      "Topic Modeling",
      "Topic Modeling 1"
    ]
  },
  {
    "objectID": "README.html",
    "href": "README.html",
    "title": "United Nations General Debate Corpus (UNGDC)",
    "section": "",
    "text": "This corpus contains 10568 English transcripts of speeches delivered by state representatives of the UN member states at the United Nations General Debate from 1946 until 2022. Text data was made available by Baturo et al. (2017). Original data is in a form of .txt file, each containing speech transcript from one member state in a given year. This RDS dataset was generated by executing “RDS_generator.R” file to read in all .txt files into a single dataframe. File size is 58.61 MB. Alternatively, run “json_convertor.R” file to transform plain texts into structured .json files.\nDatasets can be found here. Three identifying variables across all documents are: ccode_iso (ISO 3-letter character country code), session (session number of the given UNGD meeting), year (year of UNGD).\nRefer to the description.Rmd file for an overview of the dataset.\n\n\n\nFile\nDescription\n\n\n\n\ncleaned.csv\n10568 observations. “text” is cleaned after removing white spaces(multiple spaces and tab), digits followed by a dot. This does not exclude any stop words.\n\n\nlight.csv\n10568 observations. “text” does not have any stop words.\n\n\nmeta.csv\n10568 observations with 110 variables. This data contains country-year level information for each speaker country. Refer to codebook for more description on each feature.\n\n\nliwc_controls.csv\n10568 observations with 222 variables. This data contains country-year level information for each speaker country as well as psychological, linguistic constructs generated by LIWC.\n\n\n\n\n\n\n`UNGDC_topic_modeling_updated.qmd’ renders LDA results. This version replaced deprecated functions from the quanteda package. It also presents a workflow with the goal of handling dynamic nature of topic models. Using correlation, this script shows the overlap between topics, represented with different terms over time.\n\n\n\nSlava Jankin, Alexander Baturo, and Niheer Dasandi. “Words to Unite Nations: The Complete UN General Debate Corpus, 1946-Present.” OSF working paper, https://osf.io/6kty4\nAlexander Baturo, Niheer Dasandi, and Slava Mikhaylov, “Understanding State Preferences With Text As Data: Introducing the UN General Debate Corpus” Research & Politics, 2017.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "README.html#data-description",
    "href": "README.html#data-description",
    "title": "United Nations General Debate Corpus (UNGDC)",
    "section": "",
    "text": "This corpus contains 10568 English transcripts of speeches delivered by state representatives of the UN member states at the United Nations General Debate from 1946 until 2022. Text data was made available by Baturo et al. (2017). Original data is in a form of .txt file, each containing speech transcript from one member state in a given year. This RDS dataset was generated by executing “RDS_generator.R” file to read in all .txt files into a single dataframe. File size is 58.61 MB. Alternatively, run “json_convertor.R” file to transform plain texts into structured .json files.\nDatasets can be found here. Three identifying variables across all documents are: ccode_iso (ISO 3-letter character country code), session (session number of the given UNGD meeting), year (year of UNGD).\nRefer to the description.Rmd file for an overview of the dataset.\n\n\n\nFile\nDescription\n\n\n\n\ncleaned.csv\n10568 observations. “text” is cleaned after removing white spaces(multiple spaces and tab), digits followed by a dot. This does not exclude any stop words.\n\n\nlight.csv\n10568 observations. “text” does not have any stop words.\n\n\nmeta.csv\n10568 observations with 110 variables. This data contains country-year level information for each speaker country. Refer to codebook for more description on each feature.\n\n\nliwc_controls.csv\n10568 observations with 222 variables. This data contains country-year level information for each speaker country as well as psychological, linguistic constructs generated by LIWC.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "README.html#lda-analysis",
    "href": "README.html#lda-analysis",
    "title": "United Nations General Debate Corpus (UNGDC)",
    "section": "",
    "text": "`UNGDC_topic_modeling_updated.qmd’ renders LDA results. This version replaced deprecated functions from the quanteda package. It also presents a workflow with the goal of handling dynamic nature of topic models. Using correlation, this script shows the overlap between topics, represented with different terms over time.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "README.html#references",
    "href": "README.html#references",
    "title": "United Nations General Debate Corpus (UNGDC)",
    "section": "",
    "text": "Slava Jankin, Alexander Baturo, and Niheer Dasandi. “Words to Unite Nations: The Complete UN General Debate Corpus, 1946-Present.” OSF working paper, https://osf.io/6kty4\nAlexander Baturo, Niheer Dasandi, and Slava Mikhaylov, “Understanding State Preferences With Text As Data: Introducing the UN General Debate Corpus” Research & Politics, 2017.",
    "crumbs": [
      "Welcome"
    ]
  }
]