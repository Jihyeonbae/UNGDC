{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00de55bd-0bd3-4046-a18d-d36bb7fe3aa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import matplotlib.pyplot as plt\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "566e85ab-825f-4274-bded-db35ba434c39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('../../data/processed/light.csv')\n",
    "# Filter\n",
    "timestamps = df.year.to_list()\n",
    "texts = df.text.to_list()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3979516-4c7e-4170-a66c-c7c4a2ff17f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bert_text_preparation(texts, tokenizer, max_seq_length=612):\n",
    "    \"\"\"Preparing the input for BERT\n",
    "    \n",
    "    Takes a list of strings (texts) and performs\n",
    "    pre-processing like adding special tokens,\n",
    "    tokenization, tokens to ids, and tokens to\n",
    "    segment ids. Each sentence is treated as a separate segment.\n",
    "    \n",
    "    Args:\n",
    "        texts (list): List of strings (sentences/documents) to be converted\n",
    "        tokenizer (obj): Tokenizer object\n",
    "            to convert text into BERT-re-\n",
    "            adable tokens and ids\n",
    "        max_seq_length (int): Maximum sequence length supported by the BERT model\n",
    "        \n",
    "    Returns:\n",
    "        list: List of lists of BERT-readable tokens for each sentence\n",
    "        obj: Torch tensor with token ids\n",
    "        obj: Torch tensor segment ids\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    tokenized_texts = []\n",
    "    tokens_tensors = []\n",
    "    segments_tensors = []\n",
    "\n",
    "    for text in texts:\n",
    "        # Calculate how much to truncate from the beginning and end\n",
    "        truncate_length = len(text) - max_seq_length + 2  # +2 to account for [CLS] and [SEP]\n",
    "\n",
    "        # Truncate the beginning and end of the text\n",
    "        truncated_text = text[truncate_length//2 : -truncate_length//2]\n",
    "\n",
    "        marked_text = \"[CLS] \" + truncated_text + \" [SEP]\"\n",
    "        tokenized_text = tokenizer.tokenize(marked_text)\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        segments_ids = [1] * len(indexed_tokens)\n",
    "\n",
    "        tokenized_texts.append(tokenized_text)\n",
    "        tokens_tensors.append(indexed_tokens)\n",
    "        segments_tensors.append(segments_ids)\n",
    "\n",
    "    # Pad sequences to max_seq_length\n",
    "    tokens_tensors = torch.nn.utils.rnn.pad_sequence([torch.tensor(t) for t in tokens_tensors], batch_first=True)\n",
    "    segments_tensors = torch.nn.utils.rnn.pad_sequence([torch.tensor(s) for s in segments_tensors], batch_first=True)\n",
    "\n",
    "    return tokenized_texts, tokens_tensors, segments_tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bb1d46d-0f5b-4db0-b5e8-42c113ec2d18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased', \n",
    "                                  output_hidden_states = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1810ff0e-6f48-4f37-9d72-c8e92bf93a9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare input using the bert_text_preparation function\n",
    "tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(texts, tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9243ee-cf77-4b6e-9cdb-18e4655aee8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "    hidden_states = outputs[2]\n",
    "\n",
    "# Selecting the output embeddings from the last layer\n",
    "token_embeddings = hidden_states[-1]\n",
    "\n",
    "# Assuming you want the embeddings for the first word in the first sentence\n",
    "word_index = tokenized_texts[0].index(\"sovereignty\")\n",
    "word_embedding = token_embeddings[0, word_index].numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2868efef-50ed-4a17-88be-a9381d7aebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Assuming you have the BERT model loaded and the embeddings for each word\n",
    "# Example: word_embedding_sovereignty and word_embedding_territorial\n",
    "\n",
    "# Reshape embeddings to be 2D arrays\n",
    "embedding_sovereignty = word_embedding_sovereignty.reshape(1, -1)\n",
    "embedding_territorial = word_embedding_territorial.reshape(1, -1)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_sim = cosine_similarity(embedding_sovereignty, embedding_territorial)\n",
    "\n",
    "print(\"Cosine Similarity between 'sovereignty' and 'territorial integrity':\", cosine_sim[0][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a069ed-d2c2-4536-a156-730b843106b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Assuming you have the BERT model loaded and the embeddings for each word at different time points\n",
    "# Example: word_embedding_sovereignty_list and word_embedding_territorial_list\n",
    "\n",
    "# Placeholder lists to store distances and time points\n",
    "distances = []\n",
    "time_points = []\n",
    "\n",
    "# Collect embeddings at different time points\n",
    "for time_point in range(num_time_points):\n",
    "    # Example: Obtain word embeddings at different time points\n",
    "    word_embedding_sovereignty = get_word_embedding_at_time_point(\"sovereignty\", time_point)\n",
    "    word_embedding_territorial = get_word_embedding_at_time_point(\"territorial integrity\", time_point)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    cosine_sim = cosine_similarity(word_embedding_sovereignty.reshape(1, -1), word_embedding_territorial.reshape(1, -1))\n",
    "\n",
    "    # Append distance and time point\n",
    "    distances.append(cosine_sim[0][0])\n",
    "    time_points.append(time_point)\n",
    "\n",
    "# Create a Plotly figure\n",
    "fig = px.line(x=time_points, y=distances, markers=True, labels={'x': 'Time Points', 'y': 'Cosine Similarity'},\n",
    "              title='Cosine Similarity between \"sovereignty\" and \"territorial integrity\" over Time')\n",
    "\n",
    "# Show the interactive plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09a6c347-e5fa-4e0d-827b-7491117afd12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(44409) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55fd47b86da64d778eec162a86490579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc7de0378124da28fa83aaac5de26f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac7ad74498e4960b736ec23bfbc451a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c12b9bc8ce4ae6b731f404cf51f514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/597M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import LongformerTokenizer, LongformerModel\n",
    "\n",
    "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "model = LongformerModel.from_pretrained('allenai/longformer-base-4096')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a06a6c8-b732-4d94-a4ce-a2c56a6c55cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def longformer_text_preparation(texts, tokenizer, max_seq_length=4096):\n",
    "    tokenized_texts = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for text in texts:\n",
    "        # Truncate or pad text to fit within max_seq_length\n",
    "        truncated_text = text[:max_seq_length]\n",
    "        encoding = tokenizer(truncated_text, return_tensors='pt', truncation=True, padding='max_length', max_length=max_seq_length)\n",
    "\n",
    "        tokenized_texts.append(encoding['input_ids'])\n",
    "        attention_masks.append(encoding['attention_mask'])\n",
    "\n",
    "    # Convert lists to PyTorch tensors\n",
    "    tokenized_texts = torch.stack(tokenized_texts)\n",
    "    attention_masks = torch.stack(attention_masks)\n",
    "\n",
    "    return tokenized_texts, attention_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a852bce-bcb4-4734-9096-b6560871f210",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Prepare input using the longformer_text_preparation function\n",
    "tokenized_texts, attention_masks = longformer_text_preparation(texts, tokenizer)\n",
    "\n",
    "# Run the Longformer model\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=tokenized_texts, attention_mask=attention_masks)\n",
    "\n",
    "# Access the hidden states or pooler output as needed\n",
    "hidden_states = outputs.last_hidden_state\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
